1:
  title: "A 28nm 27.5TOPS/W Approximate-Computing-Based Transformer Processor with Asymptotic Sparsity Speculating and Out-of-Order Computing"
  year: 2022
  doi: https://doi.org/10.1109/ISSCC42614.2022.9731686
  url: https://doi.org/10.1109/ISSCC42614.2022.9731686
  pdf: no 
  publisher: IEEE
  pub: IEEE International Solid- State Circuits Conference (ISSCC)
  pubshort: ISSCC
  ignore: no
  silicon: yes
  
2:
  title: "A 40nm 5.6TOPS/W 239GOPS/mm2 Self-Attention Processor with Sign Random Projection-based Approximation"
  year: 2022
  doi: https://doi.org/10.1109/ESSCIRC55480.2022.9911343
  url: https://doi.org/10.1109/ESSCIRC55480.2022.9911343
  pdf: no 
  publisher: IEEE
  pub: ESSCIRC 2022- IEEE 48th European Solid State Circuits Conference (ESSCIRC)
  pubshort: IEEE-ESSCIRC
  ignore: no
  silicon: yes
  
3:
  title: "A Dual-Mode Similarity Search Accelerator based on Embedding Compression for Online Cross-Modal Image-Text Retrieval"
  year: 2022
  doi: https://doi.org/10.1109/FCCM53951.2022.9786159
  url: https://doi.org/10.1109/FCCM53951.2022.9786159
  pdf: no 
  publisher: IEEE
  pub: International Symposium on Field-Programmable Custom Computing Machines (FCCM)
  pubshort: IEEE-FCCM
  ignore: no
  silicon: yes
  
4:
  title: "A Fast and Flexible FPGA-based Accelerator for Natural Language Processing Neural Networks"
  year: 2022
  doi: https://doi.org/10.1145/3564606
  url: https://doi.org/10.1145/3564606
  pdf: no 
  publisher: ACM
  pub: ACM Transactions on Architecture and Code Optimization
  pubshort: ACM-TACO
  ignore: no
  
5:
  title: "A Fast Post-Training Pruning Framework for Transformers"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2204.09656
  url: https://doi.org/10.48550/arXiv.2204.09656
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: arXiv-CSCL
  ignore: check
  
6:
  title: "A Framework for Accelerating Transformer-Based Language Model on ReRAM-Based Architecture"
  year: 2022
  doi: https://doi.org/10.1109/TCAD.2021.3121264
  url: https://doi.org/10.1109/TCAD.2021.3121264
  pdf: no 
  publisher: IEEE
  pub: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems
  pubshort: TCAD
  ignore: no
  silicon: yes
  
7:
  title: "A Framework for Area-efficient Multi-task BERT Execution on ReRAM-based Accelerators"
  year: 2021
  doi: https://doi.org/10.1109/ICCAD51958.2021.9643471
  url: https://doi.org/10.1109/ICCAD51958.2021.9643471
  pdf: no 
  publisher: IEEE/ACM
  pub: IEEE/ACM International Conference On Computer Aided Design (ICCAD)
  pubshort: ICCAD
  ignore: no
  silicon: yes
  
8:
  title: "A Full-Stack Search Technique for Domain Optimized Deep Learning Accelerators"
  year: 2021
  doi: https://doi.org/10.1145/3503222.3507767
  url: https://doi.org/10.1145/3503222.3507767
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Machine Learning
  pubshort:
  ignore: no
  silicon: yes
  
9:
  title: "A length adaptive algorithm-hardware co-design of transformer on FPGA through sparse attention and dynamic pipelining"
  year: 2022
  doi: https://doi.org/10.1145/3489517.3530585
  url: https://doi.org/10.1145/3489517.3530585
  pdf: no 
  publisher: ACM/IEEE
  pub: ACM/IEEE Design Automation Conference
  pubshort: DAC
  ignore: no
  silicon: yes
  
10:
  title: "A Lite Romanian BERT: ALR-BERT"
  year: 2022
  doi: https://doi.org/10.3390/computers11040057
  url: https://doi.org/10.3390/computers11040057
  pdf: no 
  publisher: MDPI
  pub: Computers
  pubshort: null
  ignore: check
  silicon: no
  
11:
  title: "A Low-Cost Reconfigurable Nonlinear Core for Embedded DNN Applications"
  year: 2020
  doi: https://doi.org/10.1109/ICFPT51103.2020.00014
  url: https://doi.org/10.1109/ICFPT51103.2020.00014
  pdf: no 
  publisher: IEEE
  pub: International Conference on Field-Programmable Technology (ICFPT)
  pubshort: ICFPT
  ignore: no
  silicon: yes
  
12:
  title: "A Microcontroller is All You Need: Enabling Transformer Execution on Low-Power IoT Endnodes"
  year: 2021
  doi: https://doi.org/10.1109/COINS51742.2021.9524173
  url: https://doi.org/10.1109/COINS51742.2021.9524173
  pdf: no 
  publisher: IEEE
  pub: IEEE International Conference on Omni-Layer Intelligent Systems (COINS)
  pubshort: COINS
  ignore: no
  silicon: yes
  
13:
  title: "A Multi-Neural Network Acceleration Architecture"
  year: 2020
  doi: https://doi.org/10.1109/ISCA45697.2020.00081
  url: https://doi.org/10.1109/ISCA45697.2020.00081
  pdf: no 
  publisher: ACM/IEEE
  pub: Annual International Symposium on Computer Architecture (ISCA)
  pubshort: ISCA
  ignore: check
  silicon: yes
  
14:
  title: "A Power Efficient Neural Network Implementation on Heterogeneous FPGA and GPU Devices"
  year: 2019
  doi: https://doi.org/10.1109/IRI.2019.00040
  url: https://doi.org/10.1109/IRI.2019.00040
  pdf: no 
  publisher: IEEE
  pub: International Conference on Information Reuse and Integration for Data Science (IRI)
  pubshort: IRA
  ignore: check
  silicon: yes
  
15:
  title: "A Primer in BERTology: What We Know About How BERT Works"
  year: 2020
  doi: https://doi.org/10.1162/tacl_a_00349
  url: https://doi.org/10.1162/tacl_a_00349
  pdf: no 
  publisher: MIt%20Press
  pub: Transactions of the Association for Computational Linguistics
  pubshort: null
  ignore: check
  silicon: check
  
16:
  title: "A Quantitative Survey of Communication Optimizations in Distributed Deep Learning"
  year: 2021
  doi: https://doi.org/10.1109/MNET.011.2000530
  url: https://doi.org/10.1109/MNET.011.2000530
  pdf: no 
  publisher: IEEE
  pub: IEEE Network
  pubshort: null
  ignore: check
  silicon: check
  
17:
  title: "A Reconfigurable DNN Training Accelerator on FPGA"
  year: 2020
  doi: https://doi.org/10.1109/SiPS50750.2020.9195234
  url: https://doi.org/10.1109/SiPS50750.2020.9195234
  pdf: no 
  publisher: IEEE
  pub: IEEE Workshop on Signal Processing Systems (SiPS)
  pubshort: SiPS
  ignore: check
  silicon: check
  
18:
  title: "A Resource-Saving Energy-Efficient Reconfigurable Hardware Accelerator for BERT-based Deep Neural Network Language Models using FFT Multiplication"
  year: 2022
  doi: https://doi.org/10.1109/ISCAS48785.2022.9937531
  url: https://doi.org/10.1109/ISCAS48785.2022.9937531
  pdf: no 
  publisher: IEEE
  pub: International Symposium on Circuits and Systems (ISCAS)
  pubshort: ISCAS
  ignore: no
  silicon: yes
  
19:
  title: "A Self-Attention Network for Deep JSCCM: The Design and FPGA Implementation"
  year: 2022
  doi: https://doi.org/10.1109/GLOBECOM48099.2022.10001518
  url: https://doi.org/10.1109/GLOBECOM48099.2022.10001518
  pdf: no 
  publisher: IEEE
  pub: IEEE Global Communications Conference
  pubshort: null
  ignore: no
  silicon: yes
  
20:
  title: "A Simple and Effective Approach to Automatic Post-Editing with Transfer Learning"
  year: 2019
  doi: https://doi.org/10.48550/arXiv.1906.06253
  url: https://doi.org/10.48550/arXiv.1906.06253
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: null
  ignore: check
  silicon: check
  
21:
  title: "A Study on Token Pruning for ColBERT"
  year: 2021
  doi: https://doi.org/10.48550/arXiv.2112.06540
  url: https://doi.org/10.48550/arXiv.2112.06540
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Information Retrieval
  pubshort: null
  ignore: check
  silicon: check
  
22:
  title: "A White Paper on Neural Network Quantization"
  year: 2021
  doi: https://doi.org/10.48550/arXiv.2106.08295
  url: https://doi.org/10.48550/arXiv.2106.08295
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Machine Learning
  pubshort: null
  ignore: check
  silicon: check
  
23:
  title: "A^3: Accelerating Attention Mechanisms in Neural Networks with Approximation"
  year: 2020
  doi: https://doi.org/10.1109/HPCA47549.2020.00035
  url: https://doi.org/10.1109/HPCA47549.2020.00035
  pdf: no 
  publisher: IEEE
  pub: International Symposium on High Performance Computer Architecture (HPCA)
  pubshort: HPCA
  ignore: no
  silicon: yes
  
24:
  title: "Emerging Neural Workloads and Their Impact on Hardware"
  year: 2020
  doi: https://doi.org/10.23919/DATE48585.2020.9116435
  url: https://doi.org/10.23919/DATE48585.2020.9116435
  pdf: no 
  publisher: IEEE
  pub: Design, Automation & Test in Europe Conference & Exhibition (DATE)
  pubshort: DATE
  ignore: check
  silicon: check
  
25:
  title: "Accelerated Device Placement Optimization with Contrastive Learning"
  year: 2021
  doi: https://doi.org/10.1145/3472456.3472523
  url: https://doi.org/10.1145/3472456.3472523
  pdf: no 
  publisher: ACM
  pub: International Conference on Parallel Processing
  pubshort: ICCP
  ignore: no
  silicon: yes
  
26:
  title: "Accelerating attention mechanism on fpgas based on efficient reconfigurable systolic array"
  year: 2022
  doi: https://doi.org/10.1145/3549937
  url: https://doi.org/10.1145/3549937
  pdf: no 
  publisher: ACM
  pub: ACM Transactions on Embedded Computing Systems
  pubshort: TECS
  ignore: no
  silicon: yes
  
27:
  title: "Accelerating attention through gradient-based learned runtime pruning"
  year: 2022
  doi: https://doi.org/10.1145/3470496.3527423
  url: https://doi.org/10.1145/3470496.3527423
  pdf: no 
  publisher: ACM
  pub: International Symposium on Computer Architecture
  pubshort: ISCA
  ignore: no
  silicon: yes
  
28:
  title: "Accelerating bandwidth-bound deep learning inference with main-memory accelerators"
  year: 2021
  doi: https://doi.org/10.1145/3458817.3476146
  url: https://doi.org/10.1145/3458817.3476146
  pdf: no 
  publisher: ACM
  pub: International Conference for High Performance Computing, Networking, Storage and Analysis
  pubshort: SC
  ignore: no
  silicon: yes
  
29:
  title: "Accelerating Emerging Neural Workloads"
  year: 2021
  doi: https://doi.org/10.25394/pgs.17139038.v1
  url: https://doi.org/10.25394/pgs.17139038.v1
  pdf: no 
  publisher: Purdue%20University
  pub: Open Access Theses and Dissertations
  pubshort: null
  ignore: no
  silicon: yes
  
30:
  title: "Accelerating event detection with DGCNN and FPGAS"
  year: 2020
  doi: https://doi.org/10.3390/electronics9101666
  url: https://doi.org/10.3390/electronics9101666
  pdf: no 
  publisher: MDPI
  pub: Electronics
  pubshort: null
  ignore: no
  silicon: yes
  
31:
  title: "Accelerating Framework of Transformer by Hardware Design and Model Compression Co-Optimization"
  year: 2021
  doi: https://doi.org/10.1109/ICCAD51958.2021.9643586
  url: https://doi.org/10.1109/ICCAD51958.2021.9643586
  pdf: no 
  publisher: IEEE/ACM
  pub: International Conference On Computer Aided Design (ICCAD)
  pubshort: ICCAD
  ignore: no
  silicon: yes
  
32:
  title: "Accelerating NLP Tasks on FPGA with Compressed BERT and a Hardware-Oriented Early Exit Method"
  year: 2022
  doi: https://doi.org/10.1109/ISVLSI54635.2022.00092
  url: https://doi.org/10.1109/ISVLSI54635.2022.00092
  pdf: no 
  publisher: IEEE
  pub: IEEE Computer Society Annual Symposium on VLSI (ISVLSI)
  pubshort: ISVLSI
  ignore: no
  silicon: yes
  
33:
  title: "Accelerating Transformer Networks through Recomposing Softmax Layers"
  year: 2022
  doi: https://doi.org/10.1109/IISWC55918.2022.00018
  url: https://doi.org/10.1109/IISWC55918.2022.00018
  pdf: http://scale.snu.ac.kr/papers/2022-11-Conference-IISWC-Softmax-recomposition.pdf
  publisher: IEEE
  pub: International Symposium on Workload Characterization (IISWC)
  pubshort: IIWSC
  ignore: no
  silicon: yes

34:
  title: "Accelerating Transformer-based Deep Learning Models on FPGAs using Column Balanced Block Pruning"
  year: 2021
  doi: https://doi.org/10.1109/ISQED51717.2021.9424344
  url: https://doi.org/10.1109/ISQED51717.2021.9424344
  pdf: https://wangshusen.github.io/papers/ISQED2021.pdf
  publisher: IEEE
  pub: International Symposium on Quality Electronic Design (ISQED)
  pubshort: ISQED
  ignore: no
  silicon: yes

35:
  title: "Accommodating Transformer onto FPGA: Coupling the Balanced Model Compression and FPGA-Implementation Optimization"
  year: 2021
  doi: https://doi.org/10.1145/3453688.3461739
  url: https://doi.org/10.1145/3453688.3461739
  pdf: no
  publisher: ACM
  pub: Proceedings of the 2021 on Great Lakes Symposium on VLSI
  pubshort: GLSVLSI
  ignore: no
  silicon: yes
  
36:
  title: "Achieving the Performance of All-Bank In-DRAM PIM With Standard Memory Interface: Memory-Computation Decoupling"
  year: 2022
  doi: https://doi.org/10.1109/ACCESS.2022.3203051
  url: https://doi.org/10.1109/ACCESS.2022.3203051
  pdf: https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870805
  publisher: IEEE
  pub: IEEE Access
  pubshort: IEEE%20Access
  ignore: no
  silicon: yes
  
40:
  title: "Adaptable Butterfly Accelerator for Attention-based NNs via Hardware and Algorithm Co-design"
  year: 2022
  doi: https://doi.org/10.1109/MICRO56248.2022.00050
  url: https://doi.org/10.1109/MICRO56248.2022.00050
  pdf: https://arxiv.org/pdf/2209.09570.pdf
  publisher: IEEE
  pub: IEEE/ACM International Symposium on Microarchitecture (MICRO)
  pubshort: MICRO
  ignore: no
  silicon: yes
  
41:
  title: "Adapting by pruning: A case study on BERT"
  year: 2021
  doi: https://doi.org/10.48550/arXiv.2105.03343
  url: https://doi.org/10.48550/arXiv.2105.03343
  pdf: https://arxiv.org/pdf/2105.03343.pdf
  publisher: arXiv
  pub: Computer Science > Machine Learning
  pubshort: null
  ignore: check
  silicon: check
  
42:
  title: "Adaptive Inference through Early-Exit Networks: Design, Challenges and Directions"
  year: 2021
  doi: https://doi.org/10.1145/3469116.3470012
  url: https://doi.org/10.1145/3469116.3470012
  pdf: no 
  publisher: ACM
  pub: International Workshop on Embedded and Mobile Deep Learning
  pubshort: EMDL
  ignore: no
  
43:
  title: "Adaptive Spatio-Temporal Graph Enhanced Vision-Language Representation for Video QA"
  year: 2021
  doi: https://doi.org/10.1109/TIP.2021.3076556
  url: https://doi.org/10.1109/TIP.2021.3076556
  pdf: no 
  publisher: IEEE
  pub: IEEE Transactions on Image Processing
  pubshort: TIP
  ignore: no
  
44:
  title: "Algorithm-hardware Co-design of Attention Mechanism on FPGA Devices"
  year: 2021
  doi: https://doi.org/10.1145/3477002
  url: https://doi.org/10.1145/3477002
  pdf: no 
  publisher: ACM
  pub: Transactions on Embedded Computing System
  pubshort: TECS
  ignore: no
  
45:
  title: "Algorithm-Hardware Co-Design of Single Shot Detector for Fast Object Detection on FPGAs"
  year: 2018
  doi: https://doi.org/10.1145/3240765.3240775
  url: https://doi.org/10.1145/3240765.3240775
  pdf: no 
  publisher: IEEE/ACM
  pub: International Conference on Computer-Aided Design (ICCAD)
  pubshort: ICCAD
  ignore: no
  
46:
  title: "AlphaTuning: Quantization-Aware Parameter-Efficient Adaptation of Large-Scale Pre-Trained Language Models"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2210.03858
  url: https://doi.org/10.48550/arXiv.2210.03858
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Machine Learning
  pubshort: null
  ignore: no
  
47:
  title: "Alternative non-BERT model choices for the textual classification in low-resource languages and environments"
  year: 2022
  doi: http://dx.doi.org/10.18653/v1/2022.deeplo--1.20
  url: http://dx.doi.org/10.18653/v1/2022.deeplo--1.20
  pdf: no 
  publisher: ACL
  pub: Proceedings of the Third Workshop on Deep Learning for Low-Resource Natural Language Processing
  pubshort: null
  ignore: no
  
48:
  title: "An Algorithm-Hardware Co-Optimized Framework for Accelerating N:M Sparse Transformers"
  year: 2022
  doi: https://doi.org/10.1109/TVLSI.2022.3197282
  url: https://doi.org/10.1109/TVLSI.2022.3197282
  pdf: no 
  publisher: IEEE
  pub: IEEE Transactions on Very Large Scale Integration (VLSI) Systems (
  pubshort: TCAD
  ignore: no
  
49:
  title: "An Automatic and Efficient BERT Pruning for Edge AI Systems"
  year: 2022
  doi: https://doi.org/10.1109/ISQED54688.2022.9806197
  url: https://doi.org/10.1109/ISQED54688.2022.9806197
  pdf: no 
  publisher: IEEE
  pub: International Symposium on Quality Electronic Design (ISQED)
  pubshort: ISQED
  ignore: no
  
50:
  title: "An Efficient Hardware Accelerator for Sparse Transformer Neural Networks"
  year: 2022
  doi: https://doi.org/10.1109/ISCAS48785.2022.9937659
  url: https://doi.org/10.1109/ISCAS48785.2022.9937659
  pdf: no 
  publisher: IEEE
  pub: International Symposium on Circuits and Systems (ISCAS)
  pubshort: ISCAS
  ignore: no
  
51:
  title: "An Efficient Transformer Inference Engine on DSP"
  year: 2023
  doi: https://doi.org/10.1007/978--3--031--22677--9_29
  url: https://doi.org/10.1007/978-3-031-22677-9_29
  pdf: no 
  publisher: Springer
  pub: International Conference on Algorithms and Architectures for Parallel Processing
  pubshort: null
  ignore: no
  
52:
  title: "An Empirical Analysis of BERT Embedding for Automated Essay Scoring"
  year: 2020
  doi: https://doi.org/10.14569/ijacsa.2020.0111027
  url: https://doi.org/10.14569/ijacsa.2020.0111027
  pdf: no 
  publisher: TheSAI
  pub: International Journal of Advanced Computer Science and Applications
  pubshort: IJACSA
  ignore: no
  
53:
  title: "An Energy-Efficient Transformer Processor Exploiting Dynamic Weak Relevances in Global Attention"
  year: 2022
  doi: https://doi.org/10.1109/JSSC.2022.3213521
  url: https://doi.org/10.1109/JSSC.2022.3213521
  pdf: no 
  publisher: IEEE
  pub: Journal of Solid-State Circuits
  pubshort: JSSC
  ignore: no
  
54:
  title: "An Evaluation of Transfer Learning for Classifying Sales Engagement Emails at Large Scale"
  year: 2019
  doi: https://doi.org/10.1109/CCGRID.2019.00069
  url: https://doi.org/10.1109/CCGRID.2019.00069
  pdf: no 
  publisher: IEEE
  pub: IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)
  pubshort: CCGRID
  ignore: no
  
55:
  title: "An FPGA-Based Transformer Accelerator Using Output Block Stationary Dataflow for Object Recognition Applications"
  year: 2022
  doi: https://doi.org/10.1109/TCSII.2022.3196055
  url: https://doi.org/10.1109/TCSII.2022.3196055
  pdf: no 
  publisher: IEEE
  pub: 'Transactions on Circuits and Systems II: Express Briefs'
  pubshort: TCSII
  ignore: no
  
56:
  title: "An investigation on different underlying quantization schemes for pre-trained language models"
  year: 2020
  doi: https://doi.org/10.1007/978--3--030--60450--9_29
  url: https://doi.org/10.1007/978--3--030--60450--9_29
  pdf: no 
  publisher: Springer
  pub: International Conference on Natural Language Processing and Chinese Computing
  pubshort: null
  ignore: no
  url: https://doi.org/10.1007/978-3-030-60450-9_29
57:
  title: "Analog-memory-based 14nm Hardware Accelerator for Dense Deep Neural Networks including Transformers"
  year: 2022
  doi: https://doi.org/10.1109/ISCAS48785.2022.9937292
  url: https://doi.org/10.1109/ISCAS48785.2022.9937292
  pdf: no 
  publisher: IEEE
  pub: International Symposium on Circuits and Systems (ISCAS)
  pubshort: ISCAS
  ignore: no
  
58:
  title: "Answer Fast: Accelerating BERT on the Tensor Streaming Processor"
  year: 2022
  doi: https://doi.org/10.1109/ASAP54787.2022.00022
  url: https://doi.org/10.1109/ASAP54787.2022.00022
  pdf: no 
  publisher: IEEE
  pub: International Conference on Application-specific Systems, Architectures and Processors (ASAP)
  pubshort: ASAP
  ignore: no
  
59:
  title: "ANT: Exploiting Adaptive Numerical Data Type for Low-bit Deep Neural Network Quantization"
  year: 2022
  doi: https://doi.org/10.1109/MICRO56248.2022.00095
  url: https://doi.org/10.1109/MICRO56248.2022.00095
  pdf: no 
  publisher: IEEE
  pub: IEEE/ACM International Symposium on Microarchitecture (MICRO)
  pubshort: MICRO
  ignore: no
  
60:
  title: "APT: The master-copy-free training method for quantised neural network on edge devices"
  year: 2022
  doi: https://doi.org/10.1016/j.jpdc.2022.04.005
  url: https://doi.org/10.1016/j.jpdc.2022.04.005
  pdf: no 
  publisher: Elsevier
  pub: Journal of Parallel and Distributed Computing
  pubshort: JPDC
  ignore: no
  
61:
  title: "Aquabolt-XL: Samsung HBM2-PIM with in-memory processing for ML accelerators and beyond"
  year: 2021
  doi: https://doi.org/10.1109/HCS52781.2021.9567191
  url: https://doi.org/10.1109/HCS52781.2021.9567191
  pdf: no 
  publisher: IEEE
  pub: IEEE Hot Chips 33 Symposium (HCS)
  pubshort: HCS
  ignore: no


63:
  title: "ATT: A Fault-Tolerant ReRAM Accelerator for Attention-based Neural Networks"
  year: 2020
  doi: https://doi.org/10.1109/ICCD50377.2020.00047
  url: https://doi.org/10.1109/ICCD50377.2020.00047
  pdf: no 
  publisher: IEEE
  pub: International Conference on Computer Design (ICCD)
  pubshort: ICCD
  ignore: no

64:
  title: "AUBER: Automated BERT regularization"
  year: 2021
  doi: https://doi.org/10.1371/journal.pone.0253241
  url: https://doi.org/10.1371/journal.pone.0253241
  pdf: no 
  publisher: PlosOne
  pub: Plos one
  pubshort: 
  ignore: no

65:
  title: "Auto-ViT-Acc: An FPGA-Aware Automatic Acceleration Framework for Vision Transformer with Mixed-Scheme Quantization"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2208.05163
  url: https://doi.org/10.48550/arXiv.2208.05163
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computer Vision and Pattern Recognition
  pubshort: 
  ignore: no

66:
  title: "Automatic Mixed-Precision Quantization Search of BERT"
  year: 2021
  doi: https://doi.org/10.24963/ijcai.2021/472
  url: https://doi.org/10.24963/ijcai.2021/472
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no

69:
  title: "Balance Multi-Head Attention based on Software and Hardware Co-design"
  year: 2022
  doi: https://doi.org/10.1109/CSCloud--EdgeCom54986.2022.00018
  url: https://doi.org/10.1109/CSCloud-EdgeCom54986.2022.00018
  pdf: no 
  publisher: IEEE
  pub: International Conference on Edge Computing and Scalable Cloud (EdgeCom)
  pubshort: EdgeCom
  ignore: no

70:
  title: "BEBERT: Efficient and robust binary ensemble BERT"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2210.15976
  url: https://doi.org/10.48550/arXiv.2210.15976
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no

71:
  title: "BERMo: What can BERT learn from ELMo?"
  year: 2021
  doi: https://doi.org/10.48550/arXiv.2110.15802
  url: https://doi.org/10.48550/arXiv.2110.15802
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no


73:
  title: "BERT Model for Classification of Fake News using the Cloud Processing Capacity"
  year: 2021
  doi: https://doi.org/10.1109/R10--HTC53172.2021.9641632
  url: https://doi.org/10.1109/R10-HTC53172.2021.9641632
  pdf: no 
  publisher: IEEE
  pub: IEEE 9th Region 10 Humanitarian Technology Conference (R10-HTC)
  pubshort: 
  ignore: no

74:
  title: "BERT model optimization methods for inference: a comparative study of five alternative BERT-model implementations"
  year: 2022
  doi: https://urn.fi/URN:NBN:fi--fe2022121270782
  url: https://urn.fi/URN:NBN:fi-fe2022121270782
  pdf: no 
  publisher: LUT%20University
  pub: School of Engineering Science, Tuotantotalous
  pubshort: 
  ignore: no

75:
  title: "BERT on a Data Diet: Finding Important Examples by Gradient-Based Pruning"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2211.05610
  url: https://doi.org/10.48550/arXiv.2211.05610
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no

76:
  title: "Bertinho: Galician BERT representations"
  year: 2021
  doi: https://doi.org/10.48550/arXiv.2103.13799
  url: https://doi.org/10.48550/arXiv.2103.13799
  pdf: no 
  publisher: arXiv 
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no

77:
  title: "BERTPerf: Inference Latency Predictor for BERT on ARM big.LITTLE Multi-Core Processors"
  year: 2022
  doi: https://doi.org/10.1109/SiPS55645.2022.9919203
  url: https://doi.org/10.1109/SiPS55645.2022.9919203
  pdf: no 
  publisher: IEEE
  pub:  IEEE Workshop on Signal Processing Systems (SiPS)
  pubshort: SiPS
  ignore: no

78:
  title: "BERxiT: Early exiting for BERT with better fine-tuning and extension to regression"
  year: 2021
  doi: http://dx.doi.org/10.18653/v1/2021.--eacl--main.8
  url: http://dx.doi.org/10.18653/v1/2021.eacl-main.8
  pdf: no 
  publisher: ACL
  pub: Association%20for%20Computational%20Linguistics
  pubshort: 
  ignore: no

79:
  title: "Beyond preserved accuracy: Evaluating loyalty and robustness of BERT compression"
  year: 2021
  doi: https://doi.org/10.48550/arXiv.2109.03228
  url: https://doi.org/10.48550/arXiv.2109.03228
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no

80:
  title: "BiBERT: Accurate Fully Binarized BERT"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2203.06390
  url: https://doi.org/10.48550/arXiv.2203.06390
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no

81:
  title: "Bigger&Faster: Two-stage Neural Architecture Search for Quantized Transformer Models"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2209.12127
  url: https://doi.org/10.48550/arXiv.2209.12127
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: no

82:
  title: "Binary Complex Neural Network Acceleration on FPGA : (Invited Paper)"
  year: 2021
  doi: https://doi.org/10.1109/ASAP52443.2021.00021
  url: https://doi.org/10.1109/ASAP52443.2021.00021
  pdf: no 
  publisher: IEEE
  pub: International Conference on Application-specific Systems, Architectures and Processors (ASAP)
  pubshort: ASAP
  ignore: no

83:
  title: "Binarybert: Pushing the limit of bert quantization"
  year: 2020
  doi: https://doi.org/10.48550/arXiv.2012.15701
  url: https://doi.org/10.48550/arXiv.2012.15701
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no

84:
  title: "Biomedical Named Entity Recognition at Scale"
  year: 2021
  doi: https://doi.org/10.1007/978--3--030--68763--2_48
  url: https://doi.org/10.1007/978-3-030-68763-2_48
  pdf: no 
  publisher: Springer
  pub: International Conference on Pattern Recognition
  pubshort: ICPR
  ignore: no

86:
  title: "BiT: Robustly Binarized Multi-distilled Transformer"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2205.13016
  url: https://doi.org/10.48550/arXiv.2205.13016
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: no

87:
  title: "Block pruning for faster transformers"
  year: 2021
  doi: https://doi.org/10.48550/arXiv.2109.04838
  url: https://doi.org/10.48550/arXiv.2109.04838
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: no

88:
  title: "Boosting Distributed Training Performance of the Unpadded BERT Model"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2208.08124
  url: https://doi.org/10.48550/arXiv.2208.08124
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Distributed, Parallel, and Cluster Computing
  pubshort: 
  ignore: no

89:
  title: "Capuchin: Tensor-based GPU Memory Management for Deep Learning"
  year: 2020
  doi: https://doi.org/10.1145/3373376.3378505
  url: https://doi.org/10.1145/3373376.3378505
  pdf: no 
  publisher: ACM
  pub: International Conference on Architectural Support for Programming Languages and Operating Systems
  pubshort: ASPLOS
  ignore: no

90:
  title: "CATBERT: Context-Aware Tiny BERT for Detecting Social Engineering Emails"
  year: 2020
  doi: https://doi.org/10.48550/arXiv.2010.03484
  url: https://doi.org/10.48550/arXiv.2010.03484
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Cryptography and Security
  pubshort: 
  ignore: no

91:
  title: "CatBERT: Context-Aware Tiny BERT for Detecting Targeted Social Engineering Emails"
  year: 2020
  doi: https://doi.org/10.48550/arXiv.2010.03484
  url: https://doi.org/10.48550/arXiv.2010.03484
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Cryptography and Security
  pubshort: 
  ignore: no

93:
  title: "CHARM: Composing Heterogeneous Accelerators for Matrix Multiply on Versal ACAP Architecture"
  year: 2023
  doi: https://doi.org/10.48550/arXiv.2301.02359
  url: https://doi.org/10.48550/arXiv.2301.02359
  pdf: no 
  publisher: arXiv 
  pub: Computer Science > Hardware Architecture
  pubshort: 
  ignore: no

94:
  title: "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT"
  year: 2020
  doi: https://doi.org/10.1145/3397271.3401075
  url: https://doi.org/10.1145/3397271.3401075
  pdf: no 
  publisher: ACM
  pub: International ACM SIGIR Conference on Research and Development in Information Retrieval
  pubshort: SIGIR
  ignore: no

95:
  title: "Combining Feature Selection Methods with BERT: An In-depth Experimental Study of Long Text Classification"
  year: 2020
  doi: https://doi.org/10.1007/978--3--030--67537--0_34
  url: https://doi.org/10.1007/978-3-030-67537-0_34
  pdf: no 
  publisher: Springer
  pub: "International Conference on Collaborative Computing: Networking, Applications and Worksharing"
  pubshort: 
  ignore: no

96:
  title: "Compact Token Representations with Contextual Quantization for Efficient Document Re-ranking"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2203.15328
  url: https://doi.org/10.48550/arXiv.2203.15328
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Information Retrieval
  pubshort: 
  ignore: no

97:
  title: "Comparison of Deep Learning Models and Various Text Pre-Processing Techniques for the Toxic Comments Classification"
  year: 2020
  doi: https://doi.org/10.3390/app10238631
  url: https://doi.org/10.3390/app10238631
  pdf: no 
  publisher: MDPI
  pub: "Natural Language Processing: Emerging Neural Approaches and Applications"
  pubshort: 
  ignore: no

98:
  title: "Compressing BERT: Studying the Effects of Weight Pruning on Transfer Learning"
  year: 2020
  doi: https://doi.org/10.48550/arXiv.2002.08307
  url: https://doi.org/10.48550/arXiv.2002.08307
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no

99:
  title: "Compressing Large-Scale Transformer-Based Models: A Case Study on BERT"
  year: 2021
  doi: https://doi.org/10.1162/tacl_a_00413
  url: https://doi.org/10.1162/tacl_a_00413
  pdf: no 
  publisher: MIT%20Press
  pub: Transactions of the Association for Computational Linguistics
  pubshort: 
  ignore: no

100:
  title: "Compressing Pre-trained Transformers via Low-Bit NxM Sparsity for Natural Language Understanding"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2206.15014
  url: https://doi.org/10.48550/arXiv.2206.15014
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no

101:
  title: "Compression of deep learning models for NLP"
  year: 2020
  doi: https://doi.org/10.1145/3340531.3412171
  url: https://doi.org/10.1145/3340531.3412171
  pdf: no 
  publisher: ACM
  pub: ACM International Conference on Information & Knowledge Managemen
  pubshort: CIKM
  ignore: yes

102:
  title: "Compression of Generative Pre-trained Language Models via Quantization"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2203.10705
  url: https://doi.org/10.48550/arXiv.2203.10705
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no

103:
  title: "CONNA: Configurable Matrix Multiplication Engine for Neural Network Acceleration"
  year: 2022
  doi: https://doi.org/10.3390/electronics11152373
  url: https://doi.org/10.3390/electronics11152373
  pdf: no 
  publisher: MDPI 
  pub: Electronics
  pubshort: 
  ignore: yes

105:
  title: "CPSAA: Accelerating Sparse Attention using Crossbar-based Processing-In-Memory Architecture"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2210.06696
  url: https://doi.org/10.48550/arXiv.2210.06696
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Hardware Architecture
  pubshort: 
  ignore: no


107:
  title: "DAP-BERT: Differentiable Architecture Pruning of BERT"
  year: 2021
  doi: https://doi.org/10.1007/978--3--030--92185--9_30
  url: https://doi.org/10.1007/978-3-030-92185-9_30
  pdf: no 
  publisher: Springer 
  pub: International Conference on Neural Information Processing
  pubshort: 
  ignore: no

111:
  title: "Deep Learning Acceleration with Neuron-to-Memory Transformation"
  year: 2020
  doi: https://doi.org/10.1109/HPCA47549.2020.00011
  url: https://doi.org/10.1109/HPCA47549.2020.00011
  pdf: no 
  publisher: IEEE
  pub: International Symposium on High Performance Computer Architecture (HPCA)
  pubshort: HPCA
  ignore: no

114:
  title: "Demystifying BERT: Implications for Accelerator Design"
  year: 2021
  doi: https://doi.org/10.48550/arXiv.2104.08335
  url: https://doi.org/10.48550/arXiv.2104.08335
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Hardware Architecture
  pubshort: 
  ignore: no

115:
  title: "Demystifying BERT: System Design Implications"
  year: 2022
  doi: https://doi.org/10.1109/IISWC55918.2022.00033
  url: https://doi.org/10.1109/IISWC55918.2022.00033
  pdf: no 
  publisher: IEEE
  pub: International Symposium on Workload Characterization (IISWC)
  pubshort: 
  ignore: no

119:
  title: "DFX: A Low-latency Multi-FPGA Appliance for Accelerating Transformer-based Text Generation"
  year: 2022
  doi: https://doi.org/10.1109/MICRO56248.2022.00051
  url: https://doi.org/10.1109/MICRO56248.2022.00051
  pdf: no 
  publisher: IEEE
  pub: International Symposium on Microarchitecture (MICRO)
  pubshort: MICRO
  ignore: no

124:
  title: "DiVIT: Algorithm and architecture co-design of differential attention in vision transformer"
  year: 2022
  doi: https://doi.org/10.1016/j.sysarc.2022.102520
  url: https://doi.org/10.1016/j.sysarc.2022.102520
  pdf: no 
  publisher: Elsevier 
  pub: Journal of Systems Architecture
  pubshort: 
  ignore: no

125:
  title: "DOTA: Detect and Omit Weak Attentions for Scalable Transformer Acceleration"
  year: 2022
  doi: https://doi.org/10.1145/3503222.3507738
  url: https://doi.org/10.1145/3503222.3507738
  pdf: no 
  publisher: ACM
  pub: ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)
  pubshort: ASPLOS
  ignore: no

127:
  title: "DQ-BART: Efficient Sequence-to-Sequence Model via Joint Distillation and Quantization"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2203.11239
  url: https://doi.org/10.48550/arXiv.2203.11239
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no

128:
  title: "DTATrans: Leveraging Dynamic Token-Based Quantization With Accuracy Compensation Mechanism for Efficient Transformer Architecture"
  year: 2023
  doi: https://doi.org/10.1109/TCAD.2022.3181541
  url: https://doi.org/10.1109/TCAD.2022.3181541
  pdf: no 
  publisher: IEEE
  pub: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 
  pubshort: TCAD
  ignore: no

129:
  title: "DTQAtten: Leveraging Dynamic Token-based Quantization for Efficient Attention Architecture"
  year: 2022
  doi: https://doi.org/10.23919/DATE54114.2022.9774692
  url: https://doi.org/10.23919/DATE54114.2022.9774692
  pdf: no 
  publisher: IEEE
  pub: Design, Automation & Test in Europe Conference & Exhibition (DATE)
  pubshort: DATE
  ignore: no

130:
  title: "Dynamic Precision Analog Computing for Neural Networks"
  year: 2022
  doi: https://doi.org/10.1109/JSTQE.2022.3218019
  url: https://doi.org/10.1109/JSTQE.2022.3218019
  pdf: no 
  publisher: IEEE 
  pub: IEEE Journal of Selected Topics in Quantum Electronics
  pubshort: 
  ignore: no

131:
  title: "Dynamic-TinyBERT: Boost TinyBERT's Inference Efficiency by Dynamic Sequence Length"
  year: 2021
  doi: https://doi.org/10.48550/arXiv.2111.09645
  url: https://doi.org/10.48550/arXiv.2111.09645
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no

132:
  title: "EAGLE: Expedited Device Placement with Automatic Grouping for Large Models"
  year: 2021
  doi: https://doi.org/10.1109/IPDPS49936.2021.00068
  url: https://doi.org/10.1109/IPDPS49936.2021.00068
  pdf: no 
  publisher: IEEE
  pub: International Parallel and Distributed Processing Symposium (IPDPS)
  pubshort: IPDPS
  ignore: no

133:
  title: "Earlybert: Efficient bert training via early-bird lottery tickets"
  year: 2020
  doi: https://doi.org/10.48550/arXiv.2101.00063
  url: https://doi.org/10.48550/arXiv.2101.00063
  pdf: no 
  publisher: arXiv 
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: yes

134:
  title: "EBERT: Efficient BERT Inference with Dynamic Structured Pruning"
  year: 2021
  doi: http://dx.doi.org/10.18653/v1/2021.findings--acl.425
  url: http://dx.doi.org/10.18653/v1/2021.findings-acl.425
  pdf: no 
  publisher: ACL
  pub: ACL Findings
  pubshort: 
  ignore: no

135:
  title: "EdgeBERT: Sentence-Level Energy Optimizations for Latency-Aware Multi-Task NLP Inference"
  year: 2021
  doi: https://doi.org/10.1145/3466752.3480095
  url: https://doi.org/10.1145/3466752.3480095
  pdf: no 
  publisher: IEEE/ACM
  pub: IEEE/ACM International Symposium on Microarchitecture
  pubshort: MICRO
  ignore: no

136:
  title: "EFA-Trans: An Efficient and Flexible Acceleration Architecture for Transformers"
  year: 2022
  doi: https://doi.org/10.3390/electronics11213550
  url: https://doi.org/10.3390/electronics11213550
  pdf: no 
  publisher: MDPI
  pub: Electronics
  pubshort: 
  ignore: no

139:
  title: "Efficient algorithms and hardware for natural language processing"
  year: 2020
  doi: https://hdl.handle.net/1721.1/127440
  url: https://hdl.handle.net/1721.1/127440
  pdf: no 
  publisher: MIT
  pub: MIT Master's Thesis
  pubshort: 
  ignore: no


143:
  title: "Efficient Document Retrieval by End-to-End Refining and Quantizing BERT Embedding with Contrastive Product Quantization"
  year: 2022
  doi: https://arxiv.org/abs/2210.17170v1
  url: https://arxiv.org/abs/2210.17170v1
  pdf: no 
  publisher: arXiv 
  pub: Computer Science > Information Retrieval
  pubshort: 
  ignore: yes

144:
  title: "Efficient transformer-based large scale language representations using hardware-friendly block structured pruning"
  year: 2020
  doi: https://doi.org/10.48550/arXiv.2009.08065
  url: https://doi.org/10.48550/arXiv.2009.08065
  pdf: no 
  publisher:  arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no

146:
  title: "Elastic Processing and Hardware Architectures for Machine Learning"
  year: 2022
  doi: 3e9f91ca96ba3320587da2bbec561a2b/
  url: https://www.proquest.com/openview/3e9f91ca96ba3320587da2bbec561a2b/
  pdf: no 
  publisher: ProQuest
  pub: UC Santa Barbara Ph.D. Dissertation
  pubshort: 
  ignore: no



148:
  title: "ELSA: Hardware-Software co-design for efficient, lightweight self-attention mechanism in neural networks"
  year: 2021
  doi: https://doi.org/10.1109/ISCA52012.2021.00060
  url: https://doi.org/10.1109/ISCA52012.2021.00060
  pdf: no 
  publisher: IEEE
  pub: International Symposium on Computer Architecture (ISCA)
  pubshort: ISCA
  ignore: no

150:
  title: "Empirical Evaluation of Post-Training Quantization Methods for Language Tasks"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2210.16621
  url: https://doi.org/10.48550/arXiv.2210.16621
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: yes

151:
  title: "Enabling and Accelerating Dynamic Vision Transformer Inference for Real-Time Applications"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2212.02687
  url: https://doi.org/10.48550/arXiv.2212.02687
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computer Vision and Pattern Recognition
  pubshort: 
  ignore: no

152:
  title: "Enabling Efficient Large-Scale Deep Learning Training with Cache Coherent Disaggregated Memory Systems"
  year: 2022
  doi: https://doi.org/10.1109/HPCA53966.2022.00018
  url: https://doi.org/10.1109/HPCA53966.2022.00018
  pdf: no 
  publisher: IEEE
  pub: International Symposium on High-Performance Computer Architecture (HPCA)
  pubshort: HPCA
  ignore: no

153:
  title: "Enabling energy-efficient DNN training on hybrid GPU-FPGA accelerators"
  year: 2021
  doi: https://doi.org/10.1145/3447818.3460371
  url: https://doi.org/10.1145/3447818.3460371
  pdf: no 
  publisher: ACM
  pub: Proceedings of the ACM International Conference on Supercomputing
  pubshort: ICS
  ignore: no

155:
  title: "Enabling Energy-Efficient Inference for Self-Attention Mechanisms in Neural Networks"
  year: 2022
  doi: https://doi.org/10.1109/AICAS54282.2022.9869924
  url: https://doi.org/10.1109/AICAS54282.2022.9869924
  pdf: no 
  publisher: IEEE
  pub: International Conference on Artificial Intelligence Circuits and Systems (AICAS)
  pubshort: AICAS
  ignore: no

156:
  title: "Enabling fast uncertainty estimation: accelerating bayesian transformers via algorithmic and hardware optimizations"
  year: 2022
  doi: https://doi.org/10.1145/3489517.3530451
  url: https://doi.org/10.1145/3489517.3530451
  pdf: no 
  publisher: ACM
  pub: ACM/IEEE Design Automation Conference (DAC)
  pubshort: DAC
  ignore: no

157:
  title: "Enabling Fast Uncertainty Estimation: Exploiting Structured Sparsity in Bayesian Transformers"
  year: 2022
  doi: https://doi.org/10.1145/3489517.3530451
  url: https://spiral.imperial.ac.uk/bitstream/10044/1/96226/2/dac22hf3_final_bayesatt.pdf
  pdf: no 
  publisher: ACM
  pub: ACM/IEEE Design Automation Conference (DAC)
  pubshort: DAC
  ignore: no

158:
  title: "Enabling One-Size-Fits-All Compilation Optimization for Inference Across Machine Learning Computers"
  year: 2021
  doi: https://doi.org/10.1109/TC.2021.3128266
  url: https://doi.org/10.1109/TC.2021.3128266
  pdf: no 
  publisher: IEEE
  pub: IEEE Transactions on Computers
  pubshort: 
  ignore: check

159:
  title: "Energy efficiency boost in the AI-infused POWER10 processor"
  year: 2021
  doi: https://doi.org/10.1109/ISCA52012.2021.00012
  url: https://doi.org/10.1109/ISCA52012.2021.00012
  pdf: no 
  publisher: IEEE
  pub: International Symposium on Computer Architecture (ISCA)
  pubshort: ISCA
  ignore: no

160:
  title: "ENEX-FP: A BERT-Based Address Recognition Model"
  year: 2023
  doi: https://doi.org/10.3390/electronics12010209
  url: https://doi.org/10.3390/electronics12010209
  pdf: no 
  publisher: MDPI
  pub: Electronics
  pubshort: 
  ignore: yes

161:
  title: "Ensemble Model Compression for Fast and Energy-Efficient Ranking on FPGAs"
  year: 2022
  doi: https://doi.org/10.1007/978--3--030--99736--6_18
  url: https://doi.org/10.1007/978-3-030-99736-6_18
  pdf: no 
  publisher: Springer
  pub: European Conference on Information Retrieval (ECIR)
  pubshort: ECIR
  ignore: no

164:
  title: "Extending the ONNX Runtime Framework for the Processing-in-Memory Execution"
  year: 2022
  doi: https://doi.org/10.1109/ICEIC54506.2022.9748444
  url: https://doi.org/10.1109/ICEIC54506.2022.9748444
  pdf: no 
  publisher: IEEE
  pub: International Conference on Electronics, Information, and Communication (ICEIC)
  pubshort: ICEIC
  ignore: no

165:
  title: "Extreme Compression for Pre-trained Transformers Made Simple and Efficient"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2206.01859
  url: https://doi.org/10.48550/arXiv.2206.01859
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: check

166:
  title: "FARM: A flexible accelerator for recurrent and memory augmented neural networks"
  year: 2020
  doi: https://doi.org/10.1007/s11265--020--01555--w
  url: https://doi.org/10.1007/s11265-020-01555-w
  pdf: no 
  publisher: Springer
  pub: Journal of Signal Processing Systems
  pubshort: 
  ignore: no

170:
  title: "Fast Heterogeneous Task Mapping for Reducing Edge DNN Latency"
  year: 2022
  doi: https://doi.org/10.1109/ASAP54787.2022.00020
  url: https://doi.org/10.1109/ASAP54787.2022.00020
  pdf: no 
  publisher: 
  pub: International Conference on Application-specific Systems, Architectures and Processors (ASAP)
  pubshort: ASAP
  ignore: no

171:
  title: "Fastformers: Highly efficient transformer models for natural language understanding"
  year: 2020
  doi: https://doi.org/10.48550/arXiv.2010.13382
  url: https://doi.org/10.48550/arXiv.2010.13382
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no

175:
  title: "FILM-QNN: Efficient FPGA Acceleration of Deep Neural Networks with Intra-Layer, Mixed-Precision Quantization"
  year: 2022
  doi: https://doi.org/10.1145/3490422.3502364
  url: https://doi.org/10.1145/3490422.3502364
  pdf: no 
  publisher: ACM/SIGDA
  pub: International Symposium on Field-Programmable Gate Arrays
  pubshort: FPGA
  ignore: no

176:
  title: "Fine-and Coarse-Granularity Hybrid Self-Attention for Efficient BERT"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2203.09055
  url: https://doi.org/10.48550/arXiv.2203.09055
  pdf: no 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: check

178:
  title: "Fixed-point Quantization for Vision Transformer"
  year: 2021
  doi: https://doi.org/10.1109/CAC53003.2021.9728246
  url: https://doi.org/10.1109/CAC53003.2021.9728246
  pdf: no 
  publisher: IEEE 
  pub: China Automation Congress (CAC)
  pubshort: CAS
  ignore: no

179:
  title: "FlexACC: A Programmable Accelerator with Application-Specific ISA for Flexible Deep Neural Network Inference"
  year: 2021
  doi: https://doi.org/10.1109/ASAP52443.2021.00046
  url: https://doi.org/10.1109/ASAP52443.2021.00046
  pdf: no 
  publisher: IEEE
  pub: International Conference on Application-specific Systems, Architectures and Processors (ASAP)
  pubshort: ASAP
  ignore: no

181:
  title: "FPGA-aware automatic acceleration framework for vision transformer with mixed-scheme quantization: late breaking results"
  year: 2022
  doi: https://doi.org/10.1145/3489517.3530618
  url: https://doi.org/10.1145/3489517.3530618
  pdf: no 
  publisher: ACM/IEEE
  pub: ACM/IEEE Design Automation Conference
  pubshort: 
  ignore: no

184:
  title: "FPGA-based design and implementation of the location attention mechanism in neural networks"
  year: 2022
  doi: https://doi.org/10.3233/JIFS--212273
  url: https://doi.org/10.3233/JIFS-212273
  pdf: no 
  publisher: "IOS%20Press"
  pub: Journal of Intelligent & Fuzzy Systems
  pubshort: 
  ignore: no

187:
  title: "From dense to sparse: Contrastive pruning for better pre-trained language model compression"
  year: 2022
  doi: https://doi.org/10.1609/aaai.v36i10.21408
  url: https://doi.org/10.1609/aaai.v36i10.21408
  pdf: no 
  publisher: AAAI
  pub: AAAI Technical Track on Speech and Natural Language Processing
  pubshort: 
  ignore: check

188:
  title: "FTRANS: energy-efficient acceleration of transformers using FPGA"
  year: 2020
  doi: https://doi.org/10.1145/3370748.3406567
  url: https://doi.org/10.1145/3370748.3406567
  pdf: no 
  publisher: ACM/IEEE
  pub: ACM/IEEE International Symposium on Low Power Electronics and Design
  pubshort: ISLPED
  ignore: no

190:
  title: "Future Scaling of Memory Hierarchy for Tensor Cores and Eliminating Redundant Shared Memory Traffic Using Inter-Warp Multicastin"
  year: 2022
  doi: https://doi.org/10.1109/TC.2022.3207134
  url: https://doi.org/10.1109/TC.2022.3207134
  pdf: no 
  publisher: IEEE
  pub: IEEE Transactions on Computers
  pubshort: 
  ignore: no

191:
  title: "Gemmini: Enabling systematic deep-learning architecture evaluation via full-stack integration"
  year: 2021
  doi: https://doi.org/10.1109/DAC18074.2021.9586216
  url: https://doi.org/10.1109/DAC18074.2021.9586216
  pdf: no 
  publisher: IEEE
  pub: ACM/IEEE Design Automation Conference (DAC)
  pubshort: DAC
  ignore: no

194:
  title: "Gobo: Quantizing attention-based nlp models for low latency and energy efficient inference"
  year: 2021
  doi: https://doi.org/10.1109/MICRO50266.2020.00071
  url: https://doi.org/10.1109/MICRO50266.2020.00071
  pdf: no 
  publisher: IEEE/ACM
  pub: IEEE/ACM International Symposium on Microarchitecture (MICRO)
  pubshort: MICRO
  ignore: no

196:
  title: "Greedy-layer pruning: Speeding up transformer models for natural language processing"
  year: 2022
  doi: https://doi.org/10.1016/j.patrec.2022.03.023
  url: https://doi.org/10.1016/j.patrec.2022.03.023
  pdf: no 
  publisher: Elsevier 
  pub: Pattern Recognition Letters
  pubshort: 
  ignore: no

197:
  title: "GuardNN: secure accelerator architecture for privacy-preserving deep learning"
  year: 2022
  doi: https://doi.org/10.1145/3489517.3530439
  url: https://doi.org/10.1145/3489517.3530439
  pdf: no 
  publisher: ACM/IEEE
  pub: ACM/IEEE Design Automation Conference
  pubshort: DAC
  ignore: no

198:
  title: "HAMMER: Hardware-friendly Approximate Computing for Self-attention with Mean-redistribution and Linearization"
  year: 2023
  doi: https://doi.org/10.1109/LCA.2022.3233832
  url: https://doi.org/10.1109/LCA.2022.3233832
  pdf: no 
  publisher: IEEE
  pub: IEEE Computer Architecture Letters 
  pubshort: 
  ignore: no

199:
  title: "Handling heavy-tailed input of transformer inference on GPUs"
  year: 2022
  doi: https://doi.org/10.1145/3524059.3532372
  url: https://doi.org/10.1145/3524059.3532372
  pdf: no 
  publisher: ACM 
  pub: ACM International Conference on Supercomputing (ICS)
  pubshort: ICS
  ignore: no

200:
  title: "Hardware Acceleration of Fully Quantized BERT for Efficient Natural Language Processing"
  year: 2021
  doi: https://doi.org/10.23919/DATE51398.2021.9474043
  url: https://doi.org/10.23919/DATE51398.2021.9474043
  pdf: no 
  publisher: IEEE
  pub:  Design, Automation & Test in Europe Conference & Exhibition (DATE)
  pubshort: DATE
  ignore: no

201:
  title: "Hardware acceleration of sparse and irregular tensor computations of ml models: A survey and insights"
  year: 2021
  doi: https://doi.org/10.1109/JPROC.2021.3098483
  url: https://doi.org/10.1109/JPROC.2021.3098483
  pdf: no 
  publisher: IEEE 
  pub: Proceedings of the IEEE
  pubshort: 
  ignore: no

202:
  title: "Hardware Acceleration of Transformer Networks using FPGAs"
  year: 2022
  doi: https://doi.org/10.1109/PACET56979.2022.9976354
  url: https://doi.org/10.1109/PACET56979.2022.9976354
  pdf: no 
  publisher: IEEE
  pub: Panhellenic Conference on Electronics & Telecommunications (PACET)
  pubshort: 
  ignore: no

203:
  title: "Hardware accelerator for multi-head attention and position-wise feed-forward in the transformer"
  year: 2020
  doi: https://doi.org/10.1109/SOCC49529.2020.9524802
  url: https://doi.org/10.1109/SOCC49529.2020.9524802
  pdf: no 
  publisher: IEEE
  pub: International System-on-Chip Conference (SOCC)
  pubshort: DOCC
  ignore: no

204:
  title: "Hardware and Software Co-design for Soft Switch in ViT Variants Processing Unit"
  year: 2022
  doi: https://doi.org/10.1007/978--3--031--10989--8_55
  url: https://doi.org/10.1007/978-3-031-10989-8_55
  pdf: no 
  publisher: Springer
  pub: International Conference on Knowledge Science, Engineering and Management
  pubshort: KSEM
  ignore: no

205:
  title: "Hardware and Software Co-optimization for Windows Attention"
  year: 2022
  doi: https://doi.org/10.1007/978--3--031--10989--8_52
  url: https://doi.org/10.1007/978-3-031-10989-8_52
  pdf: no 
  publisher: 
  pub: International Conference on Knowledge Science, Engineering and Management
  pubshort: KSEM
  ignore: no

208:
  title: "HMC-TRAN: A Tensor-core Inspired Hierarchical Model Compression for Transformer-based DNNs on GPU"
  year: 2021
  doi: https://doi.org/10.1145/3453688.3461740
  url: https://doi.org/10.1145/3453688.3461740
  pdf: no
  publisher: ACM
  pub: Great Lakes Symposium on VLSI
  pubshort: GLSVLSI
  ignore: no
  silicon: yes

209:
  title: "HoloFormer: Deep Compression of Pre-Trained Transforms via Unified Optimization of N: M Sparsity and Integer Quantization"
  year: 2021
  doi:
  url: 
  pdf: https://openreview.net/pdf?id=eAEcdRkcMHh
  publisher: 
  pub: 
  pubshort: 
  ignore: check
  silicon: check

210:
  title: "How Deep Learning Model Architecture and Software Stack Impacts Training Performance in the Cloud"
  year: 2021
  doi: https://doi.org/978--3--030--89385--9
  url: https://doi.org/978-3-030-89385-9
  pdf: no 
  publisher: Springer
  pub: Engineering Artificially Intelligent Systems
  pubshort: 
  ignore: check
  silicon: no

211:
  title: "How to Train BERT with an Academic Budget"
  year: 2021
  doi: https://doi.org/10.48550/arXiv.2104.07705
  url: https://doi.org/10.48550/arXiv.2104.07705
  pdf: https://arxiv.org/pdf/2104.07705.pdf 
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: yes
  silicon: no

212:
  title: "I-BERT: Integer-only BERT Quantization"
  year: 2021
  doi: https://doi.org/10.48550/arXiv.2101.01321
  url: https://proceedings.mlr.press/v139/kim21d.html
  pdf: http://proceedings.mlr.press/v139/kim21d/kim21d.pdf 
  publisher: PMLR
  pub: Proceedings of Machine Learning Research
  pubshort: 
  ignore: no
  silicon: yes

213:
  title: "Improving Accuracy and Speeding Up Document Image Classification Through Parallel Systems"
  year: 2020
  doi: https://doi.org/10.1007/978--3--030--50417--5_29
  url: https://doi.org/10.1007/978-3-030-50417-5_29
  pdf: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7302855/pdf/978-3-030-50417-5_Chapter_29.pdf
  publisher: Springer
  pub: International Conference on Computational Science
  pubshort: 
  ignore: no
  silicon: yes

214:
  title: "Improving Oversubscribed GPU Memory Performance in the PyTorch Framework"
  year: 2022
  doi: https://doi.org/10.1007/s10586--022--03805--x
  url: https://doi.org/10.1007/s10586-022-03805-x
  pdf: no 
  publisher: Springer
  pub: Cluster Computing
  pubshort: 
  ignore: no
  silicon: yes

215:
  title: "Improving post training neural quantization: Layer-wise calibration and integer programming"
  year: 2020
  doi: https://arxiv.org/abs/2006.10518
  url: https://arxiv.org/abs/2006.10518
  pdf: https://arxiv.org/pdf/2006.10518.pdf
  publisher: arXiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: no
  silicon: yes

216:
  title: "Improving the efficiency of transformers for resource-constrained devices"
  year: 2021
  doi: https://doi.org/10.1109/DSD53832.2021.00074
  url: https://doi.org/10.1109/DSD53832.2021.00074
  pdf: https://arxiv.org/pdf/2106.16006.pdf
  publisher: IEEE 
  pub: Euromicro Conference on Digital System Design (DSD)
  pubshort: DSD
  ignore: no
  silicon: yes

219:
  title: "Integer Fine-tuning of Transformer-based Models"
  year: 2022 
  doi: https://doi.org/10.48550/arXiv.2209.09815
  url: https://doi.org/10.48550/arXiv.2209.09815
  pdf: https://arxiv.org/pdf/2209.09815.pdf
  publisher: arXiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: check
  silicon: no

220:
  title: "Integer quantization for deep learning inference: Principles and empirical evaluation"
  year: 2020
  doi: https://doi.org/10.48550/arXiv.2004.09602
  url: https://doi.org/10.48550/arXiv.2004.09602
  pdf: https://arxiv.org/pdf/2004.09602.pdf
  publisher: arXiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: no
  silicon: yes

221:
  title: "KAISA: An adaptive second-order optimizer framework for deep neural networks"
  year: 2021
  doi: https://doi.org/10.1145/3458817.3476152
  url: https://doi.org/10.1145/3458817.3476152
  pdf: https://arxiv.org/pdf/2107.01739.pdf
  publisher: ACM
  pub: International Conference for High Performance Computing, Networking, Storage and Analysis
  pubshort: SC21
  ignore: no
  silicon: check

222:
  title: "KDLSQ-BERT: A Quantized Bert Combining Knowledge Distillation with Learned Step Size Quantization"
  year: 2021
  doi: https://doi.org/10.48550/arXiv.2101.05938
  url: https://doi.org/10.48550/arXiv.2101.05938
  pdf: https://arxiv.org/pdf/2101.05938.pdf
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: check
  silicon: check

223:
  title: "Kunlun: A 14nm High-Performance AI Processor for Diversified Workloads"
  year: 2021
  doi: https://doi.org/10.1109/ISSCC42613.2021.9366056
  url: https://doi.org/10.1109/ISSCC42613.2021.9366056
  pdf: no 
  publisher: IEEE
  pub: IEEE International Solid- State Circuits Conference (ISSCC)
  pubshort: ISSCC
  ignore: no
  silicon: yes

224:
  title: "Ladabert: Lightweight adaptation of bert through hybrid model compression"
  year: 2020
  doi: https://doi.org/10.48550/arXiv.2004.04124
  url: https://doi.org/10.48550/arXiv.2004.04124
  pdf: https://arxiv.org/pdf/2004.04124.pdf
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: check
  silicon: check

226:
  title: "Layerweaver: Maximizing Resource Utilization of Neural Processing Units via Layer-Wise Scheduling"
  year: 2021
  doi: https://doi.org/10.1109/HPCA51647.2021.00056
  url: https://doi.org/10.1109/HPCA51647.2021.00056
  pdf: https://taejunham.github.io/data/layerweaver_hpca21.pdf
  publisher: IEEE
  pub: International Symposium on High-Performance Computer Architecture (HPCA)
  pubshort: HPCA
  ignore: No
  silicon: yes

227:
  title: "Learned Token Pruning in Contextualized Late Interaction over BERT (ColBERT)"
  year: 2022
  doi: https://doi.org/10.1145/3477495.3531835
  url: https://doi.org/10.1145/3477495.3531835
  pdf: https://web.Arxiv.org/web/20220713100651id_/https://dl.acm.org/doi/pdf/10.1145/3477495.3531835
  publisher: ACM
  pub: ACM SIGIR Conference on Research and Development in Information Retrieval
  pubshort: SIGIR
  ignore: yes
  silicon: no

228:
  title: "Learning Light-Weight Translation Models from Deep Transformer"
  year: 2021
  doi: https://doi.org/10.1609/aaai.v35i15.17561
  url: https://doi.org/10.1609/aaai.v35i15.17561
  pdf: https://ojs.aaai.org/index.php/AAAI/article/view/17561/17368
  publisher: AAAI
  pub: AAAI Technical Track on Speech and Natural Language Processing II
  pubshort: 
  ignore: check
  silicon: no

229:
  title: "Lightweight Composite Re-Ranking for Efficient Keyword Search with BERT"
  year: 2022
  doi: https://doi.org/10.1145/3488560.3498495
  url: https://doi.org/10.1145/3488560.3498495
  pdf: https://dl.acm.org/doi/pdf/10.1145/3488560.3498495
  publisher: ACM
  pub: ACM International Conference on Web Search and Data Mining
  pubshort: WSDM
  ignore: check
  silicon: no

230:
  title: "Lightweight Transformers for Conversational AI"
  year: 2022
  doi: http://dx.doi.org/10.18653/v1/2022.naacl--industry.25
  url: http://dx.doi.org/10.18653/v1/2022.naacl-industry.25
  pdf: https://aclanthology.org/2022.naacl-industry.25.pdf
  publisher: ACL
  pub:  Conference of the North American Chapter of the Association for Computational Linguistics
  pubshort: 
  ignore: check
  silicon: check

231:
  title: "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2208.07339
  url: https://doi.org/10.48550/arXiv.2208.07339
  pdf: https://arxiv.org/pdf/2208.07339
  publisher: arXiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: no
  silicon: yes

232:
  title: "Load What You Need: Smaller Versions of Multilingual BERT"
  year: 2020
  doi: https://doi.org/10.48550/arXiv.2010.05609
  url: https://doi.org/10.48550/arXiv.2010.05609
  pdf: https://arxiv.org/pdf/2010.05609.pdf
  publisher: arXiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: check
  silicon: check

233:
  title: "Look-Up Table based Energy Efficient Processing in Cache Support for Neural Network Acceleration"
  year: 2020
  doi: https://doi.org/10.1109/MICRO50266.2020.00020
  url: https://doi.org/10.1109/MICRO50266.2020.00020
  pdf: https://www.microarch.org/micro53/papers/738300a088.pdf
  publisher: IEEE/ACM
  pub: IEEE/ACM International Symposium on Microarchitecture (MICRO)
  pubshort: MICRO
  ignore: no
  silicon: yes

234:
  title: "Low-Bit Quantization of Transformer for Audio Speech Recognition"
  year: 2022
  doi: https://doi.org/10.1007/978--3--031--19032--2_12
  url: https://doi.org/10.1007/978-3-031-19032-2_12
  pdf: no 
  publisher: Springer
  pub: 
  pubshort: 
  ignore: check
  silicon: check

235:
  title: "Low-Precision Quantization Techniques for Hardware-Implementation-Friendly BERT Models"
  year: 2022
  doi: https://doi.org/10.1109/ISQED54688.2022.9806238
  url: https://doi.org/10.1109/ISQED54688.2022.9806238
  pdf: no 
  publisher: IEEE
  pub: International Symposium on Quality Electronic Design (ISQED)
  pubshort: ISQED
  ignore: no
  silicon: yes

236:
  title: "M2M: Learning to Enhance Low-Light Image from Model to Mobile FPGA"
  year: 2021 
  doi: https://doi.org/10.1007/978--3--030--89029--2_22
  url: https://doi.org/10.1007/978-3-030-89029-2_22
  pdf: no
  publisher: Springer
  pub: Computer Graphics International Conference
  pubshort: 
  ignore: no
  silicon: yes

237:
  title: "MAGNet: A Modular Accelerator Generator for Neural Networks"
  # not related to BERT
  year: 2019
  doi: https://doi.org/10.1109/ICCAD45719.2019.8942127
  url: https://doi.org/10.1109/ICCAD45719.2019.8942127
  pdf: https://people.eecs.berkeley.edu/~ysshao/assets/papers/magnet2019-iccad.pdf
  publisher: IEEE
  pub: IEEE/ACM International Conference on Computer-Aided Design (ICCAD)
  pubshort: ICCAD
  ignore: check
  silicon: check

240:
  title: "MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers"
  year: 2020
  doi: https://dl.acm.org/doi/abs/10.5555/3495724.3496209
  url: https://dl.acm.org/doi/abs/10.5555/3495724.3496209
  pdf: https://dl.acm.org/doi/pdf/10.5555/3495724.3496209
  publisher: ACM
  pub: International Conference on Neural Information Processing Systems
  pubshort: 
  ignore: check
  silicon: check

241:
  title: "MKQ-BERT: Quantized BERT with 4-bits Weights and Activations"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2203.13483
  url: https://doi.org/10.48550/arXiv.2203.13483
  pdf: https://arxiv.org/pdf/2203.13483.pdf
  publisher: arXiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: no
  silicon: yes

243:
  title: "Mokey: enabling narrow fixed-point inference for out-of-the-box floating-point transformer models"
  year: 2022
  doi: https://doi.org/10.1145/3470496.3527438
  url: https://doi.org/10.1145/3470496.3527438
  pdf: https://arxiv.org/pdf/2203.12758.pdf
  publisher: IEEE
  pub: International Symposium on Computer Architecture
  pubshort: ISCA
  ignore: no
  silicon: yes

244:
  title: "Movement Pruning: Adaptive Sparsity by Fine-Tuning"
  year: 2020
  doi: https://doi.org/10.48550/arXiv.2005.07683
  url: https://doi.org/10.48550/arXiv.2005.07683
  pdf: https://proceedings.neurips.cc/paper/2020/file/eae15aabaa768ae4a5993a8a4f4fa6e4-Paper.pdf
  publisher: NeurIPS
  pub: Advances in Neural Information Processing Systems
  pubshort: NeurIPS
  ignore: check
  silicon: no

245:
  title: "Mr. BiQ: Post-Training Non-Uniform Quantization Based on Minimizing the Reconstruction Error"
  year: 
  doi: 
  url: 
  pdf: https://openaccess.thecvf.com/content/CVPR2022/papers/Jeon_Mr.BiQ_Post-Training_Non-Uniform_Quantization_Based_on_Minimizing_the_Reconstruction_Error_CVPR_2022_paper.pdf
  publisher: IEEE/CVF
  pub: IEEE/CVF Conference on Computer Vision and Pattern Recognition
  pubshort: CVPR
  ignore: check
  silicon: check

246:
  title: "mRNA: Enabling Efficient Mapping Space Exploration for a Reconfiguration Neural Accelerator"
  year: 2019
  doi: https://doi.org/10.1109/ISPASS.2019.00040
  url: https://doi.org/10.1109/ISPASS.2019.00040
  pdf: https://bpb-us-w2.wpmucdn.com/sites.gatech.edu/dist/c/332/files/2019/02/mrna_ispass2019.pdf
  publisher: IEEE
  pub: IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)
  pubshort: ISPASS
  ignore: check
  silicon: yes

247:
  title: "MSP: an FPGA-specific mixed-scheme, multi-precision deep neural network quantization framework"
  year: 2020
  doi: https://doi.org/10.48550/arXiv.2009.07460
  url: https://doi.org/10.48550/arXiv.2009.07460
  pdf: https://arxiv.org/pdf/2009.07460.pdf
  publisher: arXiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: check
  silicon: yes

248:
  title: "NAS-BERT: Task-Agnostic and Adaptive-Size BERT Compression with Neural Architecture Search"
  year: 2021
  doi: https://doi.org/10.1145/3447548.3467262
  url: https://doi.org/10.1145/3447548.3467262
  pdf: https://arxiv.org/pdf/2105.14444.pdf
  publisher: ACM
  pub:  ACM SIGKDD Conference on Knowledge Discovery & Data Mining
  pubshort: KDD
  ignore: check
  silicon: check

249:
  title: "Near-Optimal Sparse Allreduce for Distributed Deep Learning"
  year: 2022
  doi: https://doi.org/10.1145/3503221.3508399
  url: https://doi.org/10.1145/3503221.3508399
  pdf: https://arxiv.org/pdf/2201.07598.pdf
  publisher: ACM
  pub: ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming
  pubshort: PPoPP
  ignore: no
  silicon: yes

250:
  title: "Nebula: A Scalable and Flexible Accelerator for DNN Multi-Branch Blocks on Embedded Systems"
  year: 2022
  doi: https://doi.org/10.3390/electronics11040505
  url: https://doi.org/10.3390/electronics11040505
  pdf: https://www.mdpi.com/2079-9292/11/4/505/pdf
  publisher: MDPI
  pub: Electronics
  pubshort: 
  ignore: yes
  silicon: yes

251:
  title: "NEEBS: Nonexpert large-scale environment building system for deep neural network"
  year: 2022
  doi: https://doi.org/10.1002/cpe.7499
  url: https://doi.org/10.1002/cpe.7499
  pdf: no
  publisher: Wiley
  pub: Concurrency and Computation Practice and Experience
  pubshort: 
  ignore: check
  silicon: no

252:
  title: "NeuralScale: A RISC-V Based Neural Processor Boosting AI Inference in Clouds"
  year: 2021
  doi: https://carrv.github.io/2021/
  url: https://carrv.github.io/2021/
  pdf: https://carrv.github.io/2021/papers/CARRV2021_paper_67_Zhan.pdf
  publisher: CARRV
  pub: Computer Architecture Research with RISC-V
  pubshort: 
  ignore: no
  silicon: yes

254:
  title: "NLP-Fast: A Fast, Scalable, and Flexible System to Accelerate Large-Scale Heterogeneous NLP Models"
  year: 2021
  doi: https://doi.org/10.1109/PACT52795.2021.00013
  url: https://doi.org/10.1109/PACT52795.2021.00013
  pdf: no 
  publisher: IEEE
  pub: International Conference on Parallel Architectures and Compilation Techniques (PACT)
  pubshort: PACCT
  ignore: no
  silicon: yes

255:
  title: "NPE: An FPGA-based Overlay Processor for Natural Language Processing"
  year: 2021
  doi: https://doi.org/10.1145/3431920.3439477
  url: https://doi.org/10.1145/3431920.3439477
  pdf: https://arxiv.org/pdf/2104.06535.pdf 
  publisher: ACM/SIGDA
  pub: ACM/SIGDA International Symposium on Field-Programmable Gate Arrays
  pubshort: FPGA
  ignore: no
  silicon: yes

257:
  title: "Optimal Brain Compression: A framework for accurate post-training quantization and pruning"
  year: 2022
  doi: https://doi.org/10.48550/arXiv.2208.11580
  url: https://doi.org/10.48550/arXiv.2208.11580
  pdf: https://arxiv.org/pdf/2208.11580.pdf
  publisher: NeurIPS
  pub: Conference on Neural Information Processing Systems
  pubshort: NeurIPS
  ignore: no
  silicon: no

261:
  title: "PipeBERT: High-throughput BERT Inference for ARM Big.LITTLE Multi-core Processors"
  year: 2022
  doi: https://doi.org/10.1007/s11265--022--01814--y
  url: https://doi.org/10.1007/s11265-022-01814-y
  pdf: no 
  publisher: Springer
  pub: Journal of Signal Processing Systems
  pubshort: 
  ignore: no
  silicon: yes

263:
  title: "Poor Man's BERT: Smaller and Faster Transformer Models"
  year: 2020
  doi: https://doi.org/10.48550/arXiv.2004.03844
  url: https://doi.org/10.48550/arXiv.2004.03844
  pdf: https://arxiv.org/pdf/2004.03844v1
  publisher: Arxiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no
  silicon: no

264:
  title: "Post-Training Quantization for Longformer with Chunkwise Quantization Granularity and Optimized Percentile"
  year: 2022
  doi: https://doi.org/10.1109/ICCCS55155.2022.9846198
  url: https://doi.org/10.1109/ICCCS55155.2022.9846198
  pdf: no 
  publisher: IEEE
  pub: International Conference on Computer and Communication Systems (ICCCS)
  pubshort: ICCCS
  ignore: no
  silion: no

266:
  title: "PoWER-BERT: Accelerating BERT Inference via Progressive Word-vector Elimination"
  year: 2020
  doi: https://proceedings.mlr.press/v119/goyal20a.html
  url: https://proceedings.mlr.press/v119/goyal20a.html
  pdf: http://proceedings.mlr.press/v119/goyal20a/goyal20a.pdf
  publisher: PMLR
  pub: Proceedings of Machine Learning Research
  pubshort: PMLR
  ignore: no
  silicon: no

268:
  title: "Pre-trained bert-gru model for relation extraction"
  year: 2019
  doi: https://doi.org/10.1145/3373509.3373533
  url: https://doi.org/10.1145/3373509.3373533
  pdf: no 
  publisher: ACM
  pub: International Conference on Computing and Pattern Recognition
  pubshort: ICCPR
  ignore: no
  silicon: no

269:
  title: "Pre-trained Language Model with Feature Reduction and No Fine-Tuning"
  year: 2022
  doi: https://doi.org/10.1007/978--981--19--3923--5_59
  url: https://doi.org/10.1007/978-981-19-3923-5_59
  pdf: no 
  publisher: Springer
  pub: "Control, Instrumentation and Mechatronics: Theory and Practice"
  pubshort: 
  ignore: no
  silicon: no


271:
  title: "Predicting Efficiency/Effectiveness Trade-offs for Dense vs. Sparse Retrieval Strategy Selection"
  year: 2021
  doi: https://doi.org/10.1145/3459637.3482159
  url: https://doi.org/10.1145/3459637.3482159
  pdf: no 
  publisher: ACM
  pub: ACM International Conference on Information & Knowledge Management
  pubshort: CIKM
  ignore: no
  silicon: no

272:
  title: "Privacy-Preserving Text Classification on BERT Embeddings with Homomorphic Encryption"
  year: 2022
  doi: https://arxiv.org/abs/2210.02574
  url: https://arxiv.org/abs/2210.02574
  pdf: https://arxiv.org/pdf/2210.02574.pdf
  publisher: Arxiv
  pub: Computation and Language
  pubshort: 
  ignore: no
  silicon: yes

274:
  title: "ProSE: the architecture and design of a protein discovery engine"
  year: 2022
  doi: https://doi.org/10.1145/3503222.3507722
  url: https://doi.org/10.1145/3503222.3507722
  pdf: https://par.nsf.gov/servlets/purl/10394954
  publisher: ACM
  pub: ACM International Conference on Architectural Support for Programming Languages and Operating Systems
  pubshort: ASPLOS
  ignore: no
  silicon: yes

277:
  title: "Pruning Redundant Mappings in Transformer Models via Spectral-Normalized Identity Prior"
  year: 2020
  doi: https://arxiv.org/abs/2010.01791
  url: https://arxiv.org/abs/2010.01791
  pdf: https://arxiv.org/pdf/2010.01791.pdf
  publisher: Arxiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no
  silicon: check

278:
  title: "PTQ4ViT: Post-Training Quantization Framework for Vision Transformers with Twin Uniform Quantization"
  year: 2021
  doi: https://arxiv.org/abs/2111.12293
  url: https://arxiv.org/abs/2111.12293
  pdf: https://arxiv.org/pdf/2111.12293
  publisher: Arxiv
  pub: Computer Science > Computer Vision and Pattern Recognition
  pubshort: 
  ignore: no
  silicon: yes

279:
  title: "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"
  year: 2020
  doi: https://doi.org/10.1609/aaai.v34i05.6409
  url: https://doi.org/10.1609/aaai.v34i05.6409
  pdf: https://ojs.aaai.org/index.php/AAAI/article/view/6409/6265
  publisher: AAAI
  pub: "AAAI Technical Track: Natural Language Processing"
  pubshort: 
  ignore: no
  silicon: check

280:
  title: "Q8BERT: Quantized 8Bit BERT"
  year: 2019
  doi: https://doi.org/10.1109/EMC2--NIPS53020.2019.00016
  url: https://doi.org/10.1109/EMC2-NIPS53020.2019.00016
  pdf: https://arxiv.org/pdf/1910.06188.pdf
  publisher: IEEE
  pub: Workshop on Energy Efficient Machine Learning and Cognitive Computing - NeurIPS Edition (EMC2-NIPS)
  pubshort: EMC2-NIPS
  ignore: no
  silicon: no

281:
  title: "QDrop: Randomly Dropping Quantization for Extremely Low-bit Post-Training Quantization"
  year: 2022
  doi: https://arxiv.org/abs/2203.05740
  url: https://arxiv.org/abs/2203.05740
  pdf: https://arxiv.org/pdf/2203.05740
  publisher: Arxiv
  pub: Computer Science > Computer Vision and Pattern Recognition
  pubshort: 
  ignore: no
  silicon: no

282:
  title: "QuaLA-MiniLM: a Quantized Length Adaptive MiniLM"
  year: 2022
  doi: https://arxiv.org/abs/2210.17114
  url: https://arxiv.org/abs/2210.17114
  pdf: https://arxiv.org/pdf/2210.17114
  publisher: Arxiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no
  silicon: no

283:
  title: "Randomly Wired Network Based on RoBERTa and Dialog History Attention for Response Selection"
  year: 2021
  doi: https://doi.org/10.1109/TASLP.2021.3077119
  url: https://doi.org/10.1109/TASLP.2021.3077119
  pdf: no 
  publisher: IEEE 
  pub: IEEE/ACM Transactions on Audio, Speech, and Language Processing 
  pubshort: 
  ignore: no
  silicon: no

284:
  title: "RCT: Resource Constrained Training for Edge AI"
  year: 2022
  doi: https://doi.org/10.1109/TNNLS.2022.3190451
  url: https://doi.org/10.1109/TNNLS.2022.3190451
  pdf: https://arxiv.org/pdf/2103.14493.pdf
  publisher: IEEE
  pub: IEEE Transactions on Neural Networks and Learning Systems 
  pubshort: 
  ignore: no
  silicon: check

285:
  title: "Re2PIM: A Reconfigurable ReRAM-Based PIM Design for Variable-Sized Vector-Matrix Multiplication"
  year: 2021
  doi: https://doi.org/10.1145/3453688.3461494
  url: https://doi.org/10.1145/3453688.3461494
  pdf: no 
  publisher: ACM
  pub:  Proceedings on Great Lakes Symposium on VLSI
  pubshort: GLVLSI
  ignore: no
  silicon: yes

286:
  title: "ReAAP: A Reconfigurable and Algorithm-Oriented Array Processor With Compiler-Architecture Co-Design"
  year: 2022
  doi: https://doi.org/10.1109/TC.2022.3213177
  url: https://doi.org/10.1109/TC.2022.3213177
  pdf: https://ieeexplore.ieee.org/iel7/12/4358213/09914609.pdf
  publisher: IEEE
  pub: IEEE Transactions on Computers 
  pubshort: TC
  ignore: no
  silicon: yes


292:
  title: "ReTransformer: ReRAM-based processing-in-memory architecture for transformer acceleration"
  year: 2020
  doi: https://doi.org/10.1145/3400302.3415640
  url: https://doi.org/10.1145/3400302.3415640
  pdf: https://dl.acm.org/doi/pdf/10.1145/3400302.3415640
  publisher: ACM
  pub: International Conference on Computer-Aided Design
  pubshort: ICCAD
  ignore: no
  silicon: yes

294:
  title: "RISC-VTF: RISC-V Based Extended Instruction Set for Transformer"
  year: 2021
  doi: https://doi.org/10.1109/SMC52423.2021.9658643
  url: https://doi.org/10.1109/SMC52423.2021.9658643
  pdf: no 
  publisher: IEEE
  pub: IEEE International Conference on Systems, Man, and Cybernetics
  pubshort: SMC
  ignore: no
  silicon: yes

295:
  title: "RMSMP: A Novel Deep Neural Network Quantization Framework with Row-wise Mixed Schemes and Multiple Precisions"
  year: 2021 
  doi: xx
  url: 
  pdf: https://openaccess.thecvf.com/content/ICCV2021/papers/Chang_RMSMP_A_Novel_Deep_Neural_Network_Quantization_Framework_With_Row-Wise_ICCV_2021_paper.pdf
  publisher: 
  pub: IEEE/CVF International Conference on Computer Vision 
  pubshort: ICCV
  ignore: no
  silicon: yes



297:
  title: "Row-wise Accelerator for Vision Transformer"
  year: 2022
  doi: https://doi.org/10.1109/AICAS54282.2022.9869928
  url: https://doi.org/10.1109/AICAS54282.2022.9869928
  pdf: https://arxiv.org/pdf/2205.03998.pdf
  publisher: IEEE
  pub: International Conference on Artificial Intelligence Circuits and Systems
  pubshort: AICAS
  ignore: no
  silicon: yes

298:
  title: "S4: a High-sparsity, High-performance AI Accelerator"
  year: 2022
  doi: https://arxiv.org/abs/2207.08006
  url: https://arxiv.org/abs/2207.08006
  pdf: https://arxiv.org/pdf/2207.08006
  publisher: Arxive
  pub: Computer Science > Hardware Architecture
  pubshort: 
  ignore: no
  silicon: yes

299:
  title: "SALO: an efficient spatial accelerator enabling hybrid sparse attention mechanisms for long sequences"
  year: 2022
  doi: https://doi.org/10.1145/3489517.3530504
  url: https://doi.org/10.1145/3489517.3530504
  pdf: https://arxiv.org/pdf/2206.14550.pdf
  publisher: ACM
  pub: ACM/IEEE Design Automation Conference
  pubshort: DAC
  ignore: no
  silicon: yes

300:
  title: "Sanger: A Co-Design Framework for Enabling Sparse Attention using Reconfigurable Architecture"
  year: 2021
  doi: https://doi.org/10.1145/3466752.3480125
  url: https://doi.org/10.1145/3466752.3480125
  pdf: https://dl.acm.org/doi/pdf/10.1145/3466752.3480125
  publisher: IEEE/ACM
  pub: IEEE/ACM International Symposium on Microarchitecture
  pubshort: MICRO
  ignore: no
  silicon: yes

302:
  title: "Searching for memory-lighter architectures for OCR-augmented image captioning"
  year: 2022
  doi: https://doi.org/10.3233/JIFS--219230
  url: https://doi.org/10.3233/JIFS-219230
  pdf: no 
  publisher: 
  pub: Journal of Intelligent & Fuzzy Systems
  pubshort: 
  ignore: no
  silicon: check

303:
  title: "SECDA-TFLite: A toolkit for efficient development of FPGA-based DNN accelerators for edge inference"
  year: 2023
  doi: https://doi.org/10.1016/j.jpdc.2022.11.005
  url: https://doi.org/10.1016/j.jpdc.2022.11.005
  pdf: https://www.sciencedirect.com/science/article/pii/S0743731522002301/pdfft?md5=444fdc7e73724f5d9881d162bed2a735&pid=1-s2.0-S0743731522002301-main.pdf
  publisher: Elsevier
  pub: Journal of Parallel and Distributed Computing
  pubshort: Elsevier
  ignore: no
  silicon: yes

306:
  title: "SensiMix: Sensitivity-Aware 8-bit index & 1-bit value mixed precision quantization for BERT compression"
  year: 2022
  doi: https://doi.org/10.1371/journal.pone.0265621
  url: https://doi.org/10.1371/journal.pone.0265621
  pdf: https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0265621&type=printable
  publisher: "PLOSONE"
  pub: 
  pubshort: 
  ignore: no
  silicon: check

308:
  title: "Sentiment Analysis Using Pre-Trained Language Model With No Fine-Tuning and Less Resource"
  year: 2022
  doi: https://doi.org/10.1109/ACCESS.2022.3212367
  url: https://doi.org/10.1109/ACCESS.2022.3212367
  pdf: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9912410
  publisher: IEEE
  pub: IEEE Access 
  pubshort: 
  ignore: no
  silicon: yes

311:
  title: "Simplified TinyBERT: Knowledge Distillation for Document Retrieval"
  year: 2021
  doi: https://doi.org/10.1007/978--3--030--72240--1_21
  url: https://doi.org/10.1007/978-3-030-72240-1_21
  pdf: https://arxiv.org/pdf/2009.07531.pdf
  publisher: Springer
  pub: Advances in Information Retrieval 
  pubshort: 
  ignore: no
  silicon: check

312:
  title: "SmaQ: Smart Quantization for DNN Training by Exploiting Value Clustering"
  year: 2021
  doi: https://doi.org/10.1109/LCA.2021.3108505
  url: https://doi.org/10.1109/LCA.2021.3108505
  pdf: https://hparch.gatech.edu/papers/nima_2021_cal.pdf
  publisher: IEEE
  pub: IEEE Computer Architecture Letters
  pubshort: 
  ignore: no
  silicon: yes

313:
  title: "SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models"
  year: 2023
  doi: https://arxiv.org/abs/2211.10438
  url: https://arxiv.org/abs/2211.10438
  pdf: https://arxiv.org/pdf/2211.10438.pdf
  publisher: Arxiv
  pub: Computer Science > Computation and Language'
  pubshort: 
  ignore: no
  silicon: yes

314:
  title: "Softermax: Hardware/Software Co-Design of an Efficient Softmax for Transformers"
  year: 2021
  doi: https://doi.org/10.1109/DAC18074.2021.9586134
  url: https://doi.org/10.1109/DAC18074.2021.9586134
  pdf: https://arxiv.org/pdf/2103.09301.pdf
  publisher: ACM/IEEE
  pub: ACM/IEEE Design Automation Conference
  pubshort: DAC
  ignore: no

315:
  title: "Software and Hardware Fusion Multi-Head Attention"
  year: 2022
  doi: http://dx.doi.org/10.1007/978--3--031--10989--8_51
  url: http://dx.doi.org/10.1007/978-3-031-10989-8_51
  pdf: no
  publisher: Springer
  pub: International Conference on Knowledge Science, Engineering and Management
  pubshort: 
  ignore: no
  silicon: yes

316:
  title: "Sparse Attention Acceleration with Synergistic In-Memory Pruning and On-Chip Recomputation"
  year: 2022
  doi: https://doi.org/10.1109/MICRO56248.2022.00059
  url: https://doi.org/10.1109/MICRO56248.2022.00059
  pdf: https://arxiv.org/pdf/2209.00606.pdf
  publisher: IEEE
  pub: IEEE/ACM International Symposium on Microarchitecture
  pubshort: MICRO
  ignore: no
  silicon: yes

317:
  title: "Sparse*BERT: Sparse Models Generalize To New tasks and Domains"
  year: 2023
  doi: https://arxiv.org/abs/2205.12452
  url: https://arxiv.org/abs/2205.12452
  pdf: https://arxiv.org/pdf/2205.12452
  publisher: Arxiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no
  silicon: check

318:
  title: "SparseNN: An energy-efficient neural network accelerator exploiting input and output sparsity"
  year: 2018
  doi: https://doi.org/10.23919/DATE.2018.8342010
  url: https://doi.org/10.23919/DATE.2018.8342010
  pdf: https://doi.org/10.23919/DATE.2018.8342010
  publisher:
  pub: Design, Automation & Test in Europe Conference & Exhibition
  pubshort: DATE
  ignore: yes
  silicon: yes

319:
  title: "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning"
  year: 2021
  doi: https://doi.org/10.1109/HPCA51647.2021.00018
  url: https://doi.org/10.1109/HPCA51647.2021.00018
  pdf: https://arxiv.org/pdf/2012.09852.pdf
  publisher: IEEE
  pub: International Symposium on High-Performance Computer Architecture
  pubshort: HPCA
  ignore: no
  silicon: yes

320:
  title: "SQuAT: Sharpness- and Quantization-Aware Training for BERT"
  year: 2021
  doi: https://arxiv.org/abs/2210.07171
  url: https://arxiv.org/abs/2210.07171
  pdf: https://arxiv.org/pdf/2210.07171.pdf
  publisher: Arxiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: no
  silicon: yes

321:
  title: "SqueezeBERT: What can computer vision teach NLP about efficient neural networks?"
  year: 2020
  doi: https://arxiv.org/abs/2006.11316
  url: https://arxiv.org/abs/2006.11316
  pdf: https://arxiv.org/pdf/2006.11316.pdf
  publisher: Arxiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no
  silicon: check

322:
  title: "Stochastic precision ensemble: self-knowledge distillation for quantized deep neural networks"
  year: 2021
  doi: https://doi.org/10.1609/aaai.v35i8.16839
  url: https://doi.org/10.1609/aaai.v35i8.16839
  pdf: https://ojs.aaai.org/index.php/AAAI/article/view/16839/16646
  publisher: AAAI
  pub: AAAI Technical Track on Machine Learning I
  pubshort: 
  ignore: no
  silicon: no

324:
  title: "Structured pruning of a BERT-based question answering model"
  year: 2019 
  doi: https://arxiv.org/abs/1910.06360
  url: https://arxiv.org/abs/1910.06360
  pdf: https://arxiv.org/pdf/1910.06360
  publisher: Arxiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no
  silicon: no

325:
  title: "Structured pruning of large language models"
  year: 2019
  doi: https://arxiv.org/abs/1910.04732
  url: https://arxiv.org/abs/1910.04732
  pdf: https://arxiv.org/pdf/1910.04732
  publisher: Arxiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no
  silicon: no

326:
  title: "SwiftPruner: Reinforced Evolutionary Pruning for Efficient Ad Relevance"
  year: 2022
  doi: https://doi.org/10.1145/3511808.3557139
  url: https://doi.org/10.1145/3511808.3557139
  pdf: https://arxiv.org/pdf/2209.00625.pdf
  publisher: ACM
  pub: ACM International Conference on Information & Knowledge Management
  pubshort: CIKM
  ignore: no
  silicon: no

327:
  title: "T-OPU: An FPGA-based Overlay Processor for Natural Language Processing"
  year: 2022
  doi: 
  url: 
  pdf: https://escholarship.org/content/qt9r46v693/qt9r46v693.pdf
  publisher: UCLA
  pub: Open Access Publications from the University of California
  pubshort: 
  ignore: no
  silicon: yes

328:
  title: "Talos: A Weighted Speedup-Aware Device Placement of Deep Learning Models"
  year: 2021
  doi: https://doi.org/10.1109/ASAP52443.2021.00023
  url: https://doi.org/10.1109/ASAP52443.2021.00023
  pdf: no 
  publisher: IEEE
  pub: International Conference on Application-specific Systems, Architectures and Processors
  pubshort: ASAP
  ignore: no
  silicon: yes

329:
  title: "Teacher Intervention: Improving Convergence of Quantization Aware Training for Ultra-Low Precision Transformers"
  year: 2023
  doi: https://arxiv.org/abs/2302.11812
  url: https://arxiv.org/abs/2302.11812
  pdf: https://arxiv.org/pdf/2302.11812
  publisher: Arxiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no
  silicon: yes

330:
  title: "TernaryBERT: Distillation-aware Ultra-low Bit BERT"
  year: 2020
  doi: https://arxiv.org/abs/2009.12812
  url: https://arxiv.org/abs/2009.12812
  pdf: https://arxiv.org/pdf/2009.12812
  publisher: Arxiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no
  silicon: check

333:
  title: "The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models"
  year: 2022
  doi: https://arxiv.org/abs/2203.07259
  url: https://arxiv.org/abs/2203.07259
  pdf: https://arxiv.org/pdf/2203.07259.pdf
  publisher: Arxiv 
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no
  silicon: check

335:
  title: "TiC-SAT: Tightly-Coupled Systolic Accelerator for Transformers"
  year: 2023
  doi: https://doi.org/10.1145/3566097.3567867
  url: https://doi.org/10.1145/3566097.3567867
  pdf: https://infoscience.epfl.ch/record/298067/files/TiC_SAT_ASPDAC-preprint.pdf
  publisher: ACM
  pub: Asia and South Pacific Design Automation Conference
  pubshort: ASDAC
  ignore: no
  silicon: yes

337:
  title: "Tinybert: Distilling bert for natural language understanding"
  year: 2019
  doi: https://arxiv.org/abs/1909.10351
  url: https://arxiv.org/abs/1909.10351
  pdf: https://arxiv.org/pdf/1909.10351
  publisher: Arxiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no
  silicon: check

342:
  title: "Towards efficient post-training quantization of pre-trained language models"
  year: 2022
  doi: link
  url: https://proceedings.neurips.cc/paper_files/paper/2022/hash/096347b4efc264ae7f07742fea34af1f-Abstract-Conference.html
  pdf: https://proceedings.neurips.cc/paper_files/paper/2022/file/096347b4efc264ae7f07742fea34af1f-Paper-Conference.pdf
  publisher: NeurIPS
  pub: Advances in Neural Information Processing Systems
  pubshort: 
  ignore: no
  silicon: no

343:
  title: "TR-BERT: Dynamic Token Reduction for Accelerating BERT Inference"
  year: 2021
  doi: https://arxiv.org/abs/2105.11618
  url: https://arxiv.org/abs/2105.11618
  pdf: https://arxiv.org/pdf/2105.11618.pdf
  publisher: Arxiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no
  silicon: yes

344:
  title: "Train Flat, Then Compress: Sharpness-Aware Minimization Learns More Compressible Models"
  year: 2022
  doi: https://arxiv.org/abs/2205.12694
  url: https://arxiv.org/abs/2205.12694
  pdf: https://arxiv.org/pdf/2205.12694.pdf
  publisher: Arxiv
  pub: Computer Science > Computation and Language
  pubshort: 
  ignore: no
  silicon: yes


345:
  title: "Training Large Neural Networks with Constant Memory using a New Execution Algorithm"
  year: 2020
  doi: https://arxiv.org/abs/2002.05645
  url: https://arxiv.org/abs/2002.05645
  pdf: https://arxiv.org/pdf/2002.05645.pdf
  publisher: Arxiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: no
  silicon: yes

346:
  title: "Training with Quantization Noise for Extreme Model Compression"
  year: 2021
  doi: https://arxiv.org/abs/2004.07320
  url: https://arxiv.org/abs/2004.07320
  pdf: https://arxiv.org/pdf/2004.07320.pdf
  publisher: Arxiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: no
  silicon: yes

347:
  title: "TranCIM: Full-Digital Bitline-Transpose CIM-based Sparse Transformer Accelerator With Pipeline/Parallel Reconfigurable Modes"
  year: 2022
  doi: https://doi.org/10.1109/JSSC.2022.3213542
  url: https://doi.org/10.1109/JSSC.2022.3213542
  pdf: no
  publisher: IEEE
  pub: IEEE Journal of Solid-State Circuits
  pubshort: SSC
  ignore: no
  silicon: yes

348:
  title: "Transformer Acceleration with Dynamic Sparse Attention"
  year: 2021
  doi: https://arxiv.org/abs/2110.11299
  url: https://arxiv.org/abs/2110.11299
  pdf: https://arxiv.org/pdf/2110.11299
  publisher: Arxiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: no
  silicon: yes

349:
  title: "TransPIM: A Memory-based Acceleration via Software-Hardware Co-Design for Transformer"
  year: 2022
  doi: https://doi.org/10.1109/HPCA53966.2022.00082
  url: https://doi.org/10.1109/HPCA53966.2022.00082
  pdf: https://par.nsf.gov/servlets/purl/10345536
  publisher: IEEE
  pub: IEEE International Symposium on High-Performance Computer Architecture (HPCA)
  pubshort: 
  ignore: no
  silicon: yes

351:
  title: "Ultron-AutoML: An open-source, distributed, scalable framework for efficient hyper-parameter optimization"
  year: 2020
  doi: https://doi.org/10.1109/BigData50022.2020.9378071
  url: https://doi.org/10.1109/BigData50022.2020.9378071
  pdf: https://ashish-gupta03.github.io/files/Ultron.pdf
  publisher: IEEE 
  pub: International Conference on Big Data (Big Data)
  pubshort: 
  ignore: no
  silicon: yes

353:
  title: "Understanding and Overcoming the Challenges of Efficient Transformer Quantization"
  year: 2021
  doi: https://arxiv.org/abs/2109.12948
  url: https://arxiv.org/abs/2109.12948
  pdf: https://arxiv.org/pdf/2109.12948.pdf
  publisher: Arxiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: no
  silicon: yes

356:
  title: "VAQF: Fully Automatic Software-Hardware Co-Design Framework for Low-Bit Vision Transformer"
  year: 2022
  doi: https://arxiv.org/abs/2201.06618
  url: https://arxiv.org/abs/2201.06618
  pdf: https://arxiv.org/pdf/2201.06618.pdf
  publisher: Arxiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: no
  silicon: yes

357:
  title: "Varuna: Scalable, Low-cost Training of Massive Deep Learning Models"
  year: 2022
  doi: https://doi.org/10.1145/3492321.3519584
  url: https://doi.org/10.1145/3492321.3519584
  pdf: no 
  publisher: ACM
  pub: Proceedings of the Seventeenth European Conference on Computer Systems
  pubshort: EuroSys
  ignore: no
  silicon: check

358:
  title: "ViA: A Novel Vision-Transformer Accelerator Based on FPGA"
  year: 2022
  doi: https://doi.org/10.1109/TCAD.2022.3197489
  url: https://doi.org/10.1109/TCAD.2022.3197489
  pdf: 
  publisher: IEEE
  pub: IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems
  pubshort: TCAD
  ignore: no
  silicon: yes


360:
  title: "Vis-TOP: Visual Transformer Overlay Processor"
  year: 2021
  doi: https://arxiv.org/abs/2110.10957
  url: https://arxiv.org/abs/2110.10957
  pdf: https://arxiv.org/pdf/2110.10957.pdf
  publisher: Arxiv
  pub: Computer Science > Computer Vision and Pattern Recognition
  pubshort: 
  ignore: no
  silicon: yes

361:
  title: "ViTALiTy: Unifying Low-rank and Sparse Approximation for Vision Transformer Acceleration with a Linear Taylor Attention"
  year: 2023
  doi: https://doi.org/10.1109/HPCA56546.2023.10071081
  url: https://doi.org/10.1109/HPCA56546.2023.10071081
  pdf: https://arxiv.org/pdf/2211.05109.pdf
  publisher: IEEE
  pub: International Symposium on High-Performance Computer Architecture (HPCA)
  pubshort: 
  ignore: no
  silicon: yes

367:
  title: "Work-in-Progress: Utilizing latency and accuracy predictors for efficient hardware-aware NAS"
  year: 
  doi: https://doi.org/10.1109/CODES-ISSS55005.2022.00014
  url: https://doi.org/10.1109/CODES-ISSS55005.2022.00014
  pdf: no 
  publisher: IEEE
  pub: International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS)
  pubshort: 
  ignore: no
  silicon: yes

370:
  title: "XTC: Extreme Compression for Pre-trained Transformers Made Simple and Efficient"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no

371:
  title: "ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no

372:
  title: "Fully Unsupervised Machine Translation Using Context-Aware Word Translation and Denoising Autoencoder"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no

121:
  title: "DistilHuBERT: Speech representation learning by layer-wise distillation of hidden-unit BERT"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: yes

122:
  title: "Distilling knowledge from BERT into simple fully connected neural networks for efficient vertical retrieval"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: yes
108:
  title: "Data Movement Reduction for DNN Accelerators: Enabling Dynamic Quantization Through an eFPGA"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: yes
  147:
  title: "Elbert: Fast albert with confidence-window based early exit"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no

192:
  title: "Ghostbert: Generate more features with cheap operations for BERT"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: 
206:
  title: "Hardware-friendly compression and hardware acceleration for transformer: A survey"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no


207:
  title: "Hardware/Software Co-Design of Edge DNN Accelerators with TFLite"
  year: 2022
  doi: https://doi.org/10.1007/978--3--030--87208--8_5
  url: https://https://eprints.gla.ac.uk/280378/
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: todo

2008:
  title: "Towards Fully 8-bit Integer Inference for the Transformer Model"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: todo

217:
  title: "Int-Monitor: a model triggered hardware trojan in deep learning accelerators"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: never
  silicon: no

218:
  title: "INT8 Transformers for Inference Acceleration"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no

300: 
  title: "ViTA: A Vision Transformer Inference Accelerator for Edge Applications"
  year: 2023
  doi: https://doi.org/10.48550/arXiv.2302.09108
  url: https://doi.org/10.48550/arXiv.2302.09108
  pdf: https://arxiv.org/pdf/2302.09108.pdf
  publisher: Arxiv
  pub: Computer Science > Hardware Architecture
  pubshort: 
  ignore: no
  silicon: yes

301: 
  title: "Trends in AI inference energy consumption: Beyond the performance-vs-parameter laws of deep learning"
  year: 2023
  doi: https://doi.org/10.1016/j.suscom.2023.100857
  url: https://doi.org/10.1016/j.suscom.2023.100857
  pdf: https://www.sciencedirect.com/science/article/pii/S2210537923000124/pdfft?md5=4bec2735c1586b935287e6afea9e63a2&pid=1-s2.0-S2210537923000124-main.pdf
  publisher: Elsevier
  pub: "Sustainable Computing: Informatics and Systems"
  pubshort: 
  ignore: no
  silicon: yes

302:
  title: "Algorithm-Accelerator Co-design for High-Performance and Secure Deep Learning"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: check

303:
  title: "TRON: Transformer Neural Network Acceleration with Non-Coherent Silicon Photonics"
  year: 2023
  doi: https://doi.org/10.48550/arXiv.2303.12914
  url: https://doi.org/10.48550/arXiv.2303.12914
  pdf: https://arxiv.org/pdf/2303.12914.pdf
  publisher: Arxiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: no
  silicon: yes

304:
  title: "TransCODE: Co-design of Transformers and Accelerators for Efficient Training and Inference"
  year: 2023
  doi: https://doi.org/10.48550/arXiv.2303.14882
  url: https://doi.org/10.48550/arXiv.2303.14882
  pdf: https://arxiv.org/pdf/2303.14882
  publisher: Arxiv
  pub: Computer Science > Machine Learning
  pubshort: 
  ignore: no 
  silicon: yes

270:
  title: "Predicting CRISPR-Cas9 Off-target with Self-supervised Neural Networks"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no
275:
  title: "ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no

276:
  title: "Prune once for all: Sparse pre-trained language models"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no
289:
  title: "Research on Application of Named Entity Recognition of Electronic Medical Records Based on BERT-IDCNN-CRF Model"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no

288:
  title: "Relation Extraction using Multiple Pre-Training Models in Biomedical Domain"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no

290:
  title: "Rethinking co-design of neural architectures and hardware accelerators"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no

296:
  title: "ROSITA: Refined BERT cOmpreSsion with InTegrAted techniques"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no
338:
  title: "TinyVers: A 0.8-17 TOPS/W, 1.7 W-20 mW, Tiny Versatile System-on-chip with State-Retentive eMRAM for Machine Learning Inference"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no


339:
  title: "TinyVers: A Tiny Versatile System-on-chip with State-Retentive eMRAM for ML Inference at the Extreme Edge"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no
341:
  title: "TopicBERT for energy efficient document classification"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no

  359:
  title: "Vicuna: A Timing-Predictable RISC-V Vector Coprocessor for Scalable Parallel Computation"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no

363:
  title: "Vs-quant: Per-vector scaled quantization for accurate low-precision neural network inference"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no
368:
  title: "Workload-Balanced Graph Attention Network Accelerator with Top-K Aggregation Candidates"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no

369:
  title: "XBERT: Xilinx Logical-Level Bitstream Embedded RAM Transfusion"
  year: 
  doi: 
  url: 
  pdf: no 
  publisher: 
  pub: 
  pubshort: 
  ignore: no


# 
369:
  title: "Architecting High Performance Silicon Systems for Accurate and Efficient On-Chip Deep Learning"
  year: 2023
  doi: https://nrs.harvard.edu/URN--3:HUL.INSTREPOS:37375806
  url: https://nrs.harvard.edu/URN-3:HUL.INSTREPOS:37375806
  pdf: https://dash.harvard.edu/bitstream/handle/1/37375806/Final_Draft_PhD_Dissertation_Thierry_Tambe.pdf
  publisher: HarwardLibrary
  pub: Harvard University Graduate School of Arts and Sciences
  pubshort: 
  ignore: no
  silicon: yes
