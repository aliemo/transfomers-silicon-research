1:
  title: "A 28nm 27.5TOPS/W Approximate-Computing-Based Transformer Processor with Asymptotic Sparsity Speculating and Out-of-Order Computing"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/ISSCC42614.2022.9731686
  url: https://doi.org/10.1109/ISSCC42614.2022.9731686
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE International Solid- State Circuits Conference (ISSCC)"
  reserved: DEADBEEF

2:
  title: "A 40nm 5.6TOPS/W 239GOPS/mm2 Self-Attention Processor with Sign Random Projection-based Approximation"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/ESSCIRC55480.2022.9911343
  url: https://doi.org/10.1109/ESSCIRC55480.2022.9911343
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "ESSCIRC 2022- IEEE 48th European Solid State Circuits Conference (ESSCIRC)"
  reserved: DEADBEEF

3:
  title: "A Dual-Mode Similarity Search Accelerator based on Embedding Compression for Online Cross-Modal Image-Text Retrieval"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/FCCM53951.2022.9786159
  url: https://doi.org/10.1109/FCCM53951.2022.9786159
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on Field-Programmable Custom Computing Machines (FCCM)"
  reserved: DEADBEEF

4:
  title: "A Fast and Flexible FPGA-based Accelerator for Natural Language Processing Neural Networks"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3564606
  url: https://doi.org/10.1145/3564606
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "ACM Transactions on Architecture and Code Optimization"
  reserved: DEADBEEF

5:
  title: "A Fast Post-Training Pruning Framework for Transformers"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2204.09656
  url: https://doi.org/10.48550/arXiv.2204.09656
  pdf: False
  ignore: check
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

6:
  title: "A Framework for Accelerating Transformer-Based Language Model on ReRAM-Based Architecture"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/TCAD.2021.3121264
  url: https://doi.org/10.1109/TCAD.2021.3121264
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems"
  reserved: DEADBEEF

7:
  title: "A Framework for Area-efficient Multi-task BERT Execution on ReRAM-based Accelerators"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/ICCAD51958.2021.9643471
  url: https://doi.org/10.1109/ICCAD51958.2021.9643471
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE/ACM
  pubkey: ""
  pubname: "IEEE/ACM International Conference On Computer Aided Design (ICCAD)"
  reserved: DEADBEEF

8:
  title: "A Full-Stack Search Technique for Domain Optimized Deep Learning Accelerators"
  year: 2021
  type: article
  doi: https://doi.org/10.1145/3503222.3507767
  url: https://doi.org/10.1145/3503222.3507767
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

9:
  title: "A length adaptive algorithm-hardware co-design of transformer on FPGA through sparse attention and dynamic pipelining"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3489517.3530585
  url: https://doi.org/10.1145/3489517.3530585
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM/IEEE
  pubkey: ""
  pubname: "ACM/IEEE Design Automation Conference"
  reserved: DEADBEEF

10:
  title: "A Lite Romanian BERT: ALR-BERT"
  year: 2022
  type: article
  doi: https://doi.org/10.3390/computers11040057
  url: https://doi.org/10.3390/computers11040057
  pdf: False
  ignore: check
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: MDPI
  pubkey: ""
  pubname: "Computers"
  reserved: DEADBEEF

11:
  title: "A Low-Cost Reconfigurable Nonlinear Core for Embedded DNN Applications"
  year: 2020
  type: article
  doi: https://doi.org/10.1109/ICFPT51103.2020.00014
  url: https://doi.org/10.1109/ICFPT51103.2020.00014
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Conference on Field-Programmable Technology (ICFPT)"
  reserved: DEADBEEF

12:
  title: "A Microcontroller is All You Need: Enabling Transformer Execution on Low-Power IoT Endnodes"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/COINS51742.2021.9524173
  url: https://doi.org/10.1109/COINS51742.2021.9524173
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE International Conference on Omni-Layer Intelligent Systems (COINS)"
  reserved: DEADBEEF

13:
  title: "A Multi-Neural Network Acceleration Architecture"
  year: 2020
  type: article
  doi: https://doi.org/10.1109/ISCA45697.2020.00081
  url: https://doi.org/10.1109/ISCA45697.2020.00081
  pdf: False
  ignore: check
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM/IEEE
  pubkey: ""
  pubname: "Annual International Symposium on Computer Architecture (ISCA)"
  reserved: DEADBEEF

14:
  title: "A Power Efficient Neural Network Implementation on Heterogeneous FPGA and GPU Devices"
  year: 2019
  type: article
  doi: https://doi.org/10.1109/IRI.2019.00040
  url: https://doi.org/10.1109/IRI.2019.00040
  pdf: False
  ignore: check
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Conference on Information Reuse and Integration for Data Science (IRI)"
  reserved: DEADBEEF

15:
  title: "A Primer in BERTology: What We Know About How BERT Works"
  year: 2020
  type: article
  doi: https://doi.org/10.1162/tacl_a_00349
  url: https://doi.org/10.1162/tacl_a_00349
  pdf: False
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: MIt%20Press
  pubkey: ""
  pubname: "Transactions of the Association for Computational Linguistics"
  reserved: DEADBEEF

16:
  title: "A Quantitative Survey of Communication Optimizations in Distributed Deep Learning"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/MNET.011.2000530
  url: https://doi.org/10.1109/MNET.011.2000530
  pdf: False
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Network"
  reserved: DEADBEEF

17:
  title: "A Reconfigurable DNN Training Accelerator on FPGA"
  year: 2020
  type: article
  doi: https://doi.org/10.1109/SiPS50750.2020.9195234
  url: https://doi.org/10.1109/SiPS50750.2020.9195234
  pdf: False
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Workshop on Signal Processing Systems (SiPS)"
  reserved: DEADBEEF

18:
  title: "A Resource-Saving Energy-Efficient Reconfigurable Hardware Accelerator for BERT-based Deep Neural Network Language Models using FFT Multiplication"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/ISCAS48785.2022.9937531
  url: https://doi.org/10.1109/ISCAS48785.2022.9937531
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on Circuits and Systems (ISCAS)"
  reserved: DEADBEEF

19:
  title: "A Self-Attention Network for Deep JSCCM: The Design and FPGA Implementation"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/GLOBECOM48099.2022.10001518
  url: https://doi.org/10.1109/GLOBECOM48099.2022.10001518
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Global Communications Conference"
  reserved: DEADBEEF

20:
  title: "A Simple and Effective Approach to Automatic Post-Editing with Transfer Learning"
  year: 2019
  type: article
  doi: https://doi.org/10.48550/arXiv.1906.06253
  url: https://doi.org/10.48550/arXiv.1906.06253
  pdf: False
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

21:
  title: "A Study on Token Pruning for ColBERT"
  year: 2021
  type: article
  doi: https://doi.org/10.48550/arXiv.2112.06540
  url: https://doi.org/10.48550/arXiv.2112.06540
  pdf: False
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Information Retrieval"
  reserved: DEADBEEF

22:
  title: "A White Paper on Neural Network Quantization"
  year: 2021
  type: article
  doi: https://doi.org/10.48550/arXiv.2106.08295
  url: https://doi.org/10.48550/arXiv.2106.08295
  pdf: False
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

23:
  title: "A^3: Accelerating Attention Mechanisms in Neural Networks with Approximation"
  year: 2020
  type: article
  doi: https://doi.org/10.1109/HPCA47549.2020.00035
  url: https://doi.org/10.1109/HPCA47549.2020.00035
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on High Performance Computer Architecture (HPCA)"
  reserved: DEADBEEF

24:
  title: "Emerging Neural Workloads and Their Impact on Hardware"
  year: 2020
  type: article
  doi: https://doi.org/10.23919/DATE48585.2020.9116435
  url: https://doi.org/10.23919/DATE48585.2020.9116435
  pdf: False
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "Design, Automation & Test in Europe Conference & Exhibition (DATE)"
  reserved: DEADBEEF

25:
  title: "Accelerated Device Placement Optimization with Contrastive Learning"
  year: 2021
  type: article
  doi: https://doi.org/10.1145/3472456.3472523
  url: https://doi.org/10.1145/3472456.3472523
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "International Conference on Parallel Processing"
  reserved: DEADBEEF

26:
  title: "Accelerating attention mechanism on fpgas based on efficient reconfigurable systolic array"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3549937
  url: https://doi.org/10.1145/3549937
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "ACM Transactions on Embedded Computing Systems"
  reserved: DEADBEEF

27:
  title: "Accelerating attention through gradient-based learned runtime pruning"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3470496.3527423
  url: https://doi.org/10.1145/3470496.3527423
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "International Symposium on Computer Architecture"
  reserved: DEADBEEF

28:
  title: "Accelerating bandwidth-bound deep learning inference with main-memory accelerators"
  year: 2021
  type: article
  doi: https://doi.org/10.1145/3458817.3476146
  url: https://doi.org/10.1145/3458817.3476146
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "International Conference for High Performance Computing, Networking, Storage and Analysis"
  reserved: DEADBEEF

29:
  title: "Accelerating Emerging Neural Workloads"
  year: 2021
  type: article
  doi: https://doi.org/10.25394/pgs.17139038.v1
  url: https://doi.org/10.25394/pgs.17139038.v1
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Purdue%20University
  pubkey: ""
  pubname: "Open Access Theses and Dissertations"
  reserved: DEADBEEF

30:
  title: "Accelerating event detection with DGCNN and FPGAS"
  year: 2020
  type: article
  doi: https://doi.org/10.3390/electronics9101666
  url: https://doi.org/10.3390/electronics9101666
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: MDPI
  pubkey: ""
  pubname: "Electronics"
  reserved: DEADBEEF

31:
  title: "Accelerating Framework of Transformer by Hardware Design and Model Compression Co-Optimization"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/ICCAD51958.2021.9643586
  url: https://doi.org/10.1109/ICCAD51958.2021.9643586
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE/ACM
  pubkey: ""
  pubname: "International Conference On Computer Aided Design (ICCAD)"
  reserved: DEADBEEF

32:
  title: "Accelerating NLP Tasks on FPGA with Compressed BERT and a Hardware-Oriented Early Exit Method"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/ISVLSI54635.2022.00092
  url: https://doi.org/10.1109/ISVLSI54635.2022.00092
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Computer Society Annual Symposium on VLSI (ISVLSI)"
  reserved: DEADBEEF

33:
  title: "Accelerating Transformer Networks through Recomposing Softmax Layers"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/IISWC55918.2022.00018
  url: https://doi.org/10.1109/IISWC55918.2022.00018
  pdf: http://scale.snu.ac.kr/papers/2022-11-Conference-IISWC-Softmax-recomposition.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on Workload Characterization (IISWC)"
  reserved: DEADBEEF

34:
  title: "Accelerating Transformer-based Deep Learning Models on FPGAs using Column Balanced Block Pruning"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/ISQED51717.2021.9424344
  url: https://doi.org/10.1109/ISQED51717.2021.9424344
  pdf: https://wangshusen.github.io/papers/ISQED2021.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on Quality Electronic Design (ISQED)"
  reserved: DEADBEEF

35:
  title: "Accommodating Transformer onto FPGA: Coupling the Balanced Model Compression and FPGA-Implementation Optimization"
  year: 2021
  type: article
  doi: https://doi.org/10.1145/3453688.3461739
  url: https://doi.org/10.1145/3453688.3461739
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "Proceedings of the 2021 on Great Lakes Symposium on VLSI"
  reserved: DEADBEEF

36:
  title: "Achieving the Performance of All-Bank In-DRAM PIM With Standard Memory Interface: Memory-Computation Decoupling"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/ACCESS.2022.3203051
  url: https://doi.org/10.1109/ACCESS.2022.3203051
  pdf: https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9870805
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Access"
  reserved: DEADBEEF

37:
  title: "Adaptable Butterfly Accelerator for Attention-based NNs via Hardware and Algorithm Co-design"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/MICRO56248.2022.00050
  url: https://doi.org/10.1109/MICRO56248.2022.00050
  pdf: https://arxiv.org/pdf/2209.09570.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE/ACM International Symposium on Microarchitecture (MICRO)"
  reserved: DEADBEEF

38:
  title: "Adapting by pruning: A case study on BERT"
  year: 2021
  type: article
  doi: https://doi.org/10.48550/arXiv.2105.03343
  url: https://doi.org/10.48550/arXiv.2105.03343
  pdf: https://arxiv.org/pdf/2105.03343.pdf
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

39:
  title: "Adaptive Inference through Early-Exit Networks: Design, Challenges and Directions"
  year: 2021
  type: article
  doi: https://doi.org/10.1145/3469116.3470012
  url: https://doi.org/10.1145/3469116.3470012
  pdf: False
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "International Workshop on Embedded and Mobile Deep Learning"
  reserved: DEADBEEF

40:
  title: "Adaptive Spatio-Temporal Graph Enhanced Vision-Language Representation for Video QA"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/TIP.2021.3076556
  url: https://doi.org/10.1109/TIP.2021.3076556
  pdf: False
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Transactions on Image Processing"
  reserved: DEADBEEF

41:
  title: "Algorithm-hardware Co-design of Attention Mechanism on FPGA Devices"
  year: 2021
  type: article
  doi: https://doi.org/10.1145/3477002
  url: https://doi.org/10.1145/3477002
  pdf: False
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "Transactions on Embedded Computing System"
  reserved: DEADBEEF

42:
  title: "Algorithm-Hardware Co-Design of Single Shot Detector for Fast Object Detection on FPGAs"
  year: 2018
  type: article
  doi: https://doi.org/10.1145/3240765.3240775
  url: https://doi.org/10.1145/3240765.3240775
  pdf: False
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE/ACM
  pubkey: ""
  pubname: "International Conference on Computer-Aided Design (ICCAD)"
  reserved: DEADBEEF

43:
  title: "AlphaTuning: Quantization-Aware Parameter-Efficient Adaptation of Large-Scale Pre-Trained Language Models"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2210.03858
  url: https://doi.org/10.48550/arXiv.2210.03858
  pdf: False
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

44:
  title: "Alternative non-BERT model choices for the textual classification in low-resource languages and environments"
  year: 2022
  type: article
  doi: http://dx.doi.org/10.18653/v1/2022.deeplo--1.20
  url: http://dx.doi.org/10.18653/v1/2022.deeplo--1.20
  pdf: False
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACL
  pubkey: ""
  pubname: "Proceedings of the Third Workshop on Deep Learning for Low-Resource Natural Language Processing"
  reserved: DEADBEEF

45:
  title: "An Algorithm-Hardware Co-Optimized Framework for Accelerating N:M Sparse Transformers"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/TVLSI.2022.3197282
  url: https://doi.org/10.1109/TVLSI.2022.3197282
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Transactions on Very Large Scale Integration (VLSI) Systems ("
  reserved: DEADBEEF

46:
  title: "An Automatic and Efficient BERT Pruning for Edge AI Systems"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/ISQED54688.2022.9806197
  url: https://doi.org/10.1109/ISQED54688.2022.9806197
  pdf: False
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on Quality Electronic Design (ISQED)"
  reserved: DEADBEEF

47:
  title: "An Efficient Hardware Accelerator for Sparse Transformer Neural Networks"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/ISCAS48785.2022.9937659
  url: https://doi.org/10.1109/ISCAS48785.2022.9937659
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on Circuits and Systems (ISCAS)"
  reserved: DEADBEEF

48:
  title: "An Efficient Transformer Inference Engine on DSP"
  year: 2023
  type: article
  doi: https://doi.org/10.1007/978--3--031--22677--9_29
  url: https://doi.org/10.1007/978-3-031-22677-9_29
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "International Conference on Algorithms and Architectures for Parallel Processing"
  reserved: DEADBEEF

49:
  title: "An Empirical Analysis of BERT Embedding for Automated Essay Scoring"
  year: 2020
  type: article
  doi: https://doi.org/10.14569/ijacsa.2020.0111027
  url: https://doi.org/10.14569/ijacsa.2020.0111027
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: TheSAI
  pubkey: ""
  pubname: "International Journal of Advanced Computer Science and Applications"
  reserved: DEADBEEF

50:
  title: "An Energy-Efficient Transformer Processor Exploiting Dynamic Weak Relevances in Global Attention"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/JSSC.2022.3213521
  url: https://doi.org/10.1109/JSSC.2022.3213521
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "Journal of Solid-State Circuits"
  reserved: DEADBEEF

51:
  title: "An Evaluation of Transfer Learning for Classifying Sales Engagement Emails at Large Scale"
  year: 2019
  type: article
  doi: https://doi.org/10.1109/CCGRID.2019.00069
  url: https://doi.org/10.1109/CCGRID.2019.00069
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)"
  reserved: DEADBEEF

52:
  title: "An FPGA-Based Transformer Accelerator Using Output Block Stationary Dataflow for Object Recognition Applications"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/TCSII.2022.3196055
  url: https://doi.org/10.1109/TCSII.2022.3196055
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "Transactions on Circuits and Systems II: Express Briefs"
  reserved: DEADBEEF

53:
  title: "An investigation on different underlying quantization schemes for pre-trained language models"
  year: 2020
  type: article
  doi: https://doi.org/10.1007/978--3--030--60450--9_29
  url: https://doi.org/10.1007/978-3-030-60450-9_29
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "International Conference on Natural Language Processing and Chinese Computing"
  reserved: DEADBEEF

54:
  title: "Analog-memory-based 14nm Hardware Accelerator for Dense Deep Neural Networks including Transformers"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/ISCAS48785.2022.9937292
  url: https://doi.org/10.1109/ISCAS48785.2022.9937292
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on Circuits and Systems (ISCAS)"
  reserved: DEADBEEF

55:
  title: "Answer Fast: Accelerating BERT on the Tensor Streaming Processor"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/ASAP54787.2022.00022
  url: https://doi.org/10.1109/ASAP54787.2022.00022
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Conference on Application-specific Systems, Architectures and Processors (ASAP)"
  reserved: DEADBEEF

56:
  title: "ANT: Exploiting Adaptive Numerical Data Type for Low-bit Deep Neural Network Quantization"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/MICRO56248.2022.00095
  url: https://doi.org/10.1109/MICRO56248.2022.00095
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE/ACM International Symposium on Microarchitecture (MICRO)"
  reserved: DEADBEEF

57:
  title: "APT: The master-copy-free training method for quantised neural network on edge devices"
  year: 2022
  type: article
  doi: https://doi.org/10.1016/j.jpdc.2022.04.005
  url: https://doi.org/10.1016/j.jpdc.2022.04.005
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Elsevier
  pubkey: ""
  pubname: "Journal of Parallel and Distributed Computing"
  reserved: DEADBEEF

58:
  title: "Aquabolt-XL: Samsung HBM2-PIM with in-memory processing for ML accelerators and beyond"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/HCS52781.2021.9567191
  url: https://doi.org/10.1109/HCS52781.2021.9567191
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Hot Chips 33 Symposium (HCS)"
  reserved: DEADBEEF

59:
  title: "ATT: A Fault-Tolerant ReRAM Accelerator for Attention-based Neural Networks"
  year: 2020
  type: article
  doi: https://doi.org/10.1109/ICCD50377.2020.00047
  url: https://doi.org/10.1109/ICCD50377.2020.00047
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Conference on Computer Design (ICCD)"
  reserved: DEADBEEF

60:
  title: "AUBER: Automated BERT regularization"
  year: 2021
  type: article
  doi: https://doi.org/10.1371/journal.pone.0253241
  url: https://doi.org/10.1371/journal.pone.0253241
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: PlosOne
  pubkey: ""
  pubname: "Plos one"
  reserved: DEADBEEF

61:
  title: "Auto-ViT-Acc: An FPGA-Aware Automatic Acceleration Framework for Vision Transformer with Mixed-Scheme Quantization"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2208.05163
  url: https://doi.org/10.48550/arXiv.2208.05163
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computer Vision and Pattern Recognition"
  reserved: DEADBEEF

62:
  title: "Automatic Mixed-Precision Quantization Search of BERT"
  year: 2021
  type: article
  doi: https://doi.org/10.24963/ijcai.2021/472
  url: https://doi.org/10.24963/ijcai.2021/472
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

63:
  title: "Balance Multi-Head Attention based on Software and Hardware Co-design"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/CSCloud--EdgeCom54986.2022.00018
  url: https://doi.org/10.1109/CSCloud-EdgeCom54986.2022.00018
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Conference on Edge Computing and Scalable Cloud (EdgeCom)"
  reserved: DEADBEEF

64:
  title: "BEBERT: Efficient and robust binary ensemble BERT"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2210.15976
  url: https://doi.org/10.48550/arXiv.2210.15976
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

65:
  title: "BERMo: What can BERT learn from ELMo?"
  year: 2021
  type: article
  doi: https://doi.org/10.48550/arXiv.2110.15802
  url: https://doi.org/10.48550/arXiv.2110.15802
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

66:
  title: "BERT Model for Classification of Fake News using the Cloud Processing Capacity"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/R10--HTC53172.2021.9641632
  url: https://doi.org/10.1109/R10-HTC53172.2021.9641632
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE 9th Region 10 Humanitarian Technology Conference (R10-HTC)"
  reserved: DEADBEEF

67:
  title: "BERT model optimization methods for inference: a comparative study of five alternative BERT-model implementations"
  year: 2022
  type: article
  doi: https://urn.fi/URN:NBN:fi--fe2022121270782
  url: https://urn.fi/URN:NBN:fi-fe2022121270782
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: LUT%20University
  pubkey: ""
  pubname: "School of Engineering Science, Tuotantotalous"
  reserved: DEADBEEF

68:
  title: "BERT on a Data Diet: Finding Important Examples by Gradient-Based Pruning"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2211.05610
  url: https://doi.org/10.48550/arXiv.2211.05610
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

69:
  title: "Bertinho: Galician BERT representations"
  year: 2021
  type: article
  doi: https://doi.org/10.48550/arXiv.2103.13799
  url: https://doi.org/10.48550/arXiv.2103.13799
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

70:
  title: "BERTPerf: Inference Latency Predictor for BERT on ARM big.LITTLE Multi-Core Processors"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/SiPS55645.2022.9919203
  url: https://doi.org/10.1109/SiPS55645.2022.9919203
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Workshop on Signal Processing Systems (SiPS)"
  reserved: DEADBEEF

71:
  title: "BERxiT: Early exiting for BERT with better fine-tuning and extension to regression"
  year: 2021
  type: article
  doi: http://dx.doi.org/10.18653/v1/2021.--eacl--main.8
  url: http://dx.doi.org/10.18653/v1/2021.eacl-main.8
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACL
  pubkey: ""
  pubname: "Association%20for%20Computational%20Linguistics"
  reserved: DEADBEEF

72:
  title: "Beyond preserved accuracy: Evaluating loyalty and robustness of BERT compression"
  year: 2021
  type: article
  doi: https://doi.org/10.48550/arXiv.2109.03228
  url: https://doi.org/10.48550/arXiv.2109.03228
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

73:
  title: "BiBERT: Accurate Fully Binarized BERT"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2203.06390
  url: https://doi.org/10.48550/arXiv.2203.06390
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

74:
  title: "Bigger&Faster: Two-stage Neural Architecture Search for Quantized Transformer Models"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2209.12127
  url: https://doi.org/10.48550/arXiv.2209.12127
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

75:
  title: "Binary Complex Neural Network Acceleration on FPGA : (Invited Paper)"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/ASAP52443.2021.00021
  url: https://doi.org/10.1109/ASAP52443.2021.00021
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Conference on Application-specific Systems, Architectures and Processors (ASAP)"
  reserved: DEADBEEF

76:
  title: "Binarybert: Pushing the limit of bert quantization"
  year: 2020
  type: article
  doi: https://doi.org/10.48550/arXiv.2012.15701
  url: https://doi.org/10.48550/arXiv.2012.15701
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

77:
  title: "Biomedical Named Entity Recognition at Scale"
  year: 2021
  type: article
  doi: https://doi.org/10.1007/978--3--030--68763--2_48
  url: https://doi.org/10.1007/978-3-030-68763-2_48
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "International Conference on Pattern Recognition"
  reserved: DEADBEEF

78:
  title: "BiT: Robustly Binarized Multi-distilled Transformer"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2205.13016
  url: https://doi.org/10.48550/arXiv.2205.13016
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

79:
  title: "Block pruning for faster transformers"
  year: 2021
  type: article
  doi: https://doi.org/10.48550/arXiv.2109.04838
  url: https://doi.org/10.48550/arXiv.2109.04838
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

80:
  title: "Boosting Distributed Training Performance of the Unpadded BERT Model"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2208.08124
  url: https://doi.org/10.48550/arXiv.2208.08124
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Distributed, Parallel, and Cluster Computing"
  reserved: DEADBEEF

81:
  title: "Capuchin: Tensor-based GPU Memory Management for Deep Learning"
  year: 2020
  type: article
  doi: https://doi.org/10.1145/3373376.3378505
  url: https://doi.org/10.1145/3373376.3378505
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "International Conference on Architectural Support for Programming Languages and Operating Systems"
  reserved: DEADBEEF

82:
  title: "CATBERT: Context-Aware Tiny BERT for Detecting Social Engineering Emails"
  year: 2020
  type: article
  doi: https://doi.org/10.48550/arXiv.2010.03484
  url: https://doi.org/10.48550/arXiv.2010.03484
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Cryptography and Security"
  reserved: DEADBEEF

83:
  title: "CatBERT: Context-Aware Tiny BERT for Detecting Targeted Social Engineering Emails"
  year: 2020
  type: article
  doi: https://doi.org/10.48550/arXiv.2010.03484
  url: https://doi.org/10.48550/arXiv.2010.03484
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Cryptography and Security"
  reserved: DEADBEEF

84:
  title: "CHARM: Composing Heterogeneous Accelerators for Matrix Multiply on Versal ACAP Architecture"
  year: 2023
  type: article
  doi: https://doi.org/10.48550/arXiv.2301.02359
  url: https://doi.org/10.48550/arXiv.2301.02359
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

85:
  title: "ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT"
  year: 2020
  type: article
  doi: https://doi.org/10.1145/3397271.3401075
  url: https://doi.org/10.1145/3397271.3401075
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "International ACM SIGIR Conference on Research and Development in Information Retrieval"
  reserved: DEADBEEF

86:
  title: "Combining Feature Selection Methods with BERT: An In-depth Experimental Study of Long Text Classification"
  year: 2020
  type: article
  doi: https://doi.org/10.1007/978--3--030--67537--0_34
  url: https://doi.org/10.1007/978-3-030-67537-0_34
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "International Conference on Collaborative Computing: Networking, Applications and Worksharing"
  reserved: DEADBEEF

87:
  title: "Compact Token Representations with Contextual Quantization for Efficient Document Re-ranking"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2203.15328
  url: https://doi.org/10.48550/arXiv.2203.15328
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Information Retrieval"
  reserved: DEADBEEF

88:
  title: "Comparison of Deep Learning Models and Various Text Pre-Processing Techniques for the Toxic Comments Classification"
  year: 2020
  type: article
  doi: https://doi.org/10.3390/app10238631
  url: https://doi.org/10.3390/app10238631
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: MDPI
  pubkey: ""
  pubname: "Natural Language Processing: Emerging Neural Approaches and Applications"
  reserved: DEADBEEF

89:
  title: "Compressing BERT: Studying the Effects of Weight Pruning on Transfer Learning"
  year: 2020
  type: article
  doi: https://doi.org/10.48550/arXiv.2002.08307
  url: https://doi.org/10.48550/arXiv.2002.08307
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

90:
  title: "Compressing Large-Scale Transformer-Based Models: A Case Study on BERT"
  year: 2021
  type: article
  doi: https://doi.org/10.1162/tacl_a_00413
  url: https://doi.org/10.1162/tacl_a_00413
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: MIT%20Press
  pubkey: ""
  pubname: "Transactions of the Association for Computational Linguistics"
  reserved: DEADBEEF

91:
  title: "Compressing Pre-trained Transformers via Low-Bit NxM Sparsity for Natural Language Understanding"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2206.15014
  url: https://doi.org/10.48550/arXiv.2206.15014
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

92:
  title: "Compression of deep learning models for NLP"
  year: 2020
  type: article
  doi: https://doi.org/10.1145/3340531.3412171
  url: https://doi.org/10.1145/3340531.3412171
  pdf: False
  ignore: True
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "ACM International Conference on Information & Knowledge Managemen"
  reserved: DEADBEEF

93:
  title: "Compression of Generative Pre-trained Language Models via Quantization"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2203.10705
  url: https://doi.org/10.48550/arXiv.2203.10705
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

94:
  title: "CONNA: Configurable Matrix Multiplication Engine for Neural Network Acceleration"
  year: 2022
  type: article
  doi: https://doi.org/10.3390/electronics11152373
  url: https://doi.org/10.3390/electronics11152373
  pdf: False
  ignore: True
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: MDPI
  pubkey: ""
  pubname: "Electronics"
  reserved: DEADBEEF

95:
  title: "CPSAA: Accelerating Sparse Attention using Crossbar-based Processing-In-Memory Architecture"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2210.06696
  url: https://doi.org/10.48550/arXiv.2210.06696
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

96:
  title: "DAP-BERT: Differentiable Architecture Pruning of BERT"
  year: 2021
  type: article
  doi: https://doi.org/10.1007/978--3--030--92185--9_30
  url: https://doi.org/10.1007/978-3-030-92185-9_30
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "International Conference on Neural Information Processing"
  reserved: DEADBEEF

97:
  title: "Deep Learning Acceleration with Neuron-to-Memory Transformation"
  year: 2020
  type: article
  doi: https://doi.org/10.1109/HPCA47549.2020.00011
  url: https://doi.org/10.1109/HPCA47549.2020.00011
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on High Performance Computer Architecture (HPCA)"
  reserved: DEADBEEF

98:
  title: "Demystifying BERT: Implications for Accelerator Design"
  year: 2021
  type: article
  doi: https://doi.org/10.48550/arXiv.2104.08335
  url: https://doi.org/10.48550/arXiv.2104.08335
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

99:
  title: "Demystifying BERT: System Design Implications"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/IISWC55918.2022.00033
  url: https://doi.org/10.1109/IISWC55918.2022.00033
  pdf: False
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on Workload Characterization (IISWC)"
  reserved: DEADBEEF

100:
  title: "DFX: A Low-latency Multi-FPGA Appliance for Accelerating Transformer-based Text Generation"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/MICRO56248.2022.00051
  url: https://doi.org/10.1109/MICRO56248.2022.00051
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on Microarchitecture (MICRO)"
  reserved: DEADBEEF

101:
  title: "DiVIT: Algorithm and architecture co-design of differential attention in vision transformer"
  year: 2022
  type: article
  doi: https://doi.org/10.1016/j.sysarc.2022.102520
  url: https://doi.org/10.1016/j.sysarc.2022.102520
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Elsevier
  pubkey: ""
  pubname: "Journal of Systems Architecture"
  reserved: DEADBEEF

102:
  title: "DOTA: Detect and Omit Weak Attentions for Scalable Transformer Acceleration"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3503222.3507738
  url: https://doi.org/10.1145/3503222.3507738
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)"
  reserved: DEADBEEF

103:
  title: "DQ-BART: Efficient Sequence-to-Sequence Model via Joint Distillation and Quantization"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2203.11239
  url: https://doi.org/10.48550/arXiv.2203.11239
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

104:
  title: "DTATrans: Leveraging Dynamic Token-Based Quantization With Accuracy Compensation Mechanism for Efficient Transformer Architecture"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/TCAD.2022.3181541
  url: https://doi.org/10.1109/TCAD.2022.3181541
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems"
  reserved: DEADBEEF

105:
  title: "DTQAtten: Leveraging Dynamic Token-based Quantization for Efficient Attention Architecture"
  year: 2022
  type: article
  doi: https://doi.org/10.23919/DATE54114.2022.9774692
  url: https://doi.org/10.23919/DATE54114.2022.9774692
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "Design, Automation & Test in Europe Conference & Exhibition (DATE)"
  reserved: DEADBEEF

106:
  title: "Dynamic Precision Analog Computing for Neural Networks"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/JSTQE.2022.3218019
  url: https://doi.org/10.1109/JSTQE.2022.3218019
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Journal of Selected Topics in Quantum Electronics"
  reserved: DEADBEEF

107:
  title: "Dynamic-TinyBERT: Boost TinyBERT's Inference Efficiency by Dynamic Sequence Length"
  year: 2021
  type: article
  doi: https://doi.org/10.48550/arXiv.2111.09645
  url: https://doi.org/10.48550/arXiv.2111.09645
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

108:
  title: "EAGLE: Expedited Device Placement with Automatic Grouping for Large Models"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/IPDPS49936.2021.00068
  url: https://doi.org/10.1109/IPDPS49936.2021.00068
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Parallel and Distributed Processing Symposium (IPDPS)"
  reserved: DEADBEEF

109:
  title: "Earlybert: Efficient bert training via early-bird lottery tickets"
  year: 2020
  type: article
  doi: https://doi.org/10.48550/arXiv.2101.00063
  url: https://doi.org/10.48550/arXiv.2101.00063
  pdf: False
  ignore: True
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

110:
  title: "EBERT: Efficient BERT Inference with Dynamic Structured Pruning"
  year: 2021
  type: article
  doi: http://dx.doi.org/10.18653/v1/2021.findings--acl.425
  url: http://dx.doi.org/10.18653/v1/2021.findings-acl.425
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACL
  pubkey: ""
  pubname: "ACL Findings"
  reserved: DEADBEEF

111:
  title: "EdgeBERT: Sentence-Level Energy Optimizations for Latency-Aware Multi-Task NLP Inference"
  year: 2021
  type: article
  doi: https://doi.org/10.1145/3466752.3480095
  url: https://doi.org/10.1145/3466752.3480095
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE/ACM
  pubkey: ""
  pubname: "IEEE/ACM International Symposium on Microarchitecture"
  reserved: DEADBEEF

112:
  title: "EFA-Trans: An Efficient and Flexible Acceleration Architecture for Transformers"
  year: 2022
  type: article
  doi: https://doi.org/10.3390/electronics11213550
  url: https://doi.org/10.3390/electronics11213550
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: MDPI
  pubkey: ""
  pubname: "Electronics"
  reserved: DEADBEEF

113:
  title: "Efficient algorithms and hardware for natural language processing"
  year: 2020
  type: article
  doi: https://hdl.handle.net/1721.1/127440
  url: https://hdl.handle.net/1721.1/127440
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: MIT
  pubkey: ""
  pubname: "MIT Master's Thesis"
  reserved: DEADBEEF

114:
  title: "Efficient Document Retrieval by End-to-End Refining and Quantizing BERT Embedding with Contrastive Product Quantization"
  year: 2022
  type: article
  doi: https://arxiv.org/abs/2210.17170v1
  url: https://arxiv.org/abs/2210.17170v1
  pdf: False
  ignore: True
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Information Retrieval"
  reserved: DEADBEEF

115:
  title: "Efficient transformer-based large scale language representations using hardware-friendly block structured pruning"
  year: 2020
  type: article
  doi: https://doi.org/10.48550/arXiv.2009.08065
  url: https://doi.org/10.48550/arXiv.2009.08065
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

116:
  title: "Elastic Processing and Hardware Architectures for Machine Learning"
  year: 2022
  type: article
  doi: 3e9f91ca96ba3320587da2bbec561a2b/
  url: https://www.proquest.com/openview/3e9f91ca96ba3320587da2bbec561a2b/
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ProQuest
  pubkey: ""
  pubname: "UC Santa Barbara Ph.D. Dissertation"
  reserved: DEADBEEF

117:
  title: "ELSA: Hardware-Software co-design for efficient, lightweight self-attention mechanism in neural networks"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/ISCA52012.2021.00060
  url: https://doi.org/10.1109/ISCA52012.2021.00060
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on Computer Architecture (ISCA)"
  reserved: DEADBEEF

118:
  title: "Empirical Evaluation of Post-Training Quantization Methods for Language Tasks"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2210.16621
  url: https://doi.org/10.48550/arXiv.2210.16621
  pdf: False
  ignore: True
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

119:
  title: "Enabling and Accelerating Dynamic Vision Transformer Inference for Real-Time Applications"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2212.02687
  url: https://doi.org/10.48550/arXiv.2212.02687
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computer Vision and Pattern Recognition"
  reserved: DEADBEEF

120:
  title: "Enabling Efficient Large-Scale Deep Learning Training with Cache Coherent Disaggregated Memory Systems"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/HPCA53966.2022.00018
  url: https://doi.org/10.1109/HPCA53966.2022.00018
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on High-Performance Computer Architecture (HPCA)"
  reserved: DEADBEEF

121:
  title: "Enabling energy-efficient DNN training on hybrid GPU-FPGA accelerators"
  year: 2021
  type: article
  doi: https://doi.org/10.1145/3447818.3460371
  url: https://doi.org/10.1145/3447818.3460371
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "Proceedings of the ACM International Conference on Supercomputing"
  reserved: DEADBEEF

122:
  title: "Enabling Energy-Efficient Inference for Self-Attention Mechanisms in Neural Networks"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/AICAS54282.2022.9869924
  url: https://doi.org/10.1109/AICAS54282.2022.9869924
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Conference on Artificial Intelligence Circuits and Systems (AICAS)"
  reserved: DEADBEEF

123:
  title: "Enabling fast uncertainty estimation: accelerating bayesian transformers via algorithmic and hardware optimizations"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3489517.3530451
  url: https://doi.org/10.1145/3489517.3530451
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "ACM/IEEE Design Automation Conference (DAC)"
  reserved: DEADBEEF

124:
  title: "Enabling Fast Uncertainty Estimation: Exploiting Structured Sparsity in Bayesian Transformers"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3489517.3530451
  url: https://spiral.imperial.ac.uk/bitstream/10044/1/96226/2/dac22hf3_final_bayesatt.pdf
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "ACM/IEEE Design Automation Conference (DAC)"
  reserved: DEADBEEF

125:
  title: "Enabling One-Size-Fits-All Compilation Optimization for Inference Across Machine Learning Computers"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/TC.2021.3128266
  url: https://doi.org/10.1109/TC.2021.3128266
  pdf: False
  ignore: check
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Transactions on Computers"
  reserved: DEADBEEF

126:
  title: "Energy efficiency boost in the AI-infused POWER10 processor"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/ISCA52012.2021.00012
  url: https://doi.org/10.1109/ISCA52012.2021.00012
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on Computer Architecture (ISCA)"
  reserved: DEADBEEF

127:
  title: "ENEX-FP: A BERT-Based Address Recognition Model"
  year: 2023
  type: article
  doi: https://doi.org/10.3390/electronics12010209
  url: https://doi.org/10.3390/electronics12010209
  pdf: False
  ignore: True
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: MDPI
  pubkey: ""
  pubname: "Electronics"
  reserved: DEADBEEF

128:
  title: "Ensemble Model Compression for Fast and Energy-Efficient Ranking on FPGAs"
  year: 2022
  type: article
  doi: https://doi.org/10.1007/978--3--030--99736--6_18
  url: https://doi.org/10.1007/978-3-030-99736-6_18
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "European Conference on Information Retrieval (ECIR)"
  reserved: DEADBEEF

129:
  title: "Extending the ONNX Runtime Framework for the Processing-in-Memory Execution"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/ICEIC54506.2022.9748444
  url: https://doi.org/10.1109/ICEIC54506.2022.9748444
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Conference on Electronics, Information, and Communication (ICEIC)"
  reserved: DEADBEEF

130:
  title: "Extreme Compression for Pre-trained Transformers Made Simple and Efficient"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2206.01859
  url: https://doi.org/10.48550/arXiv.2206.01859
  pdf: False
  ignore: check
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

131:
  title: "FARM: A flexible accelerator for recurrent and memory augmented neural networks"
  year: 2020
  type: article
  doi: https://doi.org/10.1007/s11265--020--01555--w
  url: https://doi.org/10.1007/s11265-020-01555-w
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "Journal of Signal Processing Systems"
  reserved: DEADBEEF

132:
  title: "Fast Heterogeneous Task Mapping for Reducing Edge DNN Latency"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/ASAP54787.2022.00020
  url: https://doi.org/10.1109/ASAP54787.2022.00020
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: None
  pubkey: ""
  pubname: "International Conference on Application-specific Systems, Architectures and Processors (ASAP)"
  reserved: DEADBEEF

133:
  title: "Fastformers: Highly efficient transformer models for natural language understanding"
  year: 2020
  type: article
  doi: https://doi.org/10.48550/arXiv.2010.13382
  url: https://doi.org/10.48550/arXiv.2010.13382
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

134:
  title: "FILM-QNN: Efficient FPGA Acceleration of Deep Neural Networks with Intra-Layer, Mixed-Precision Quantization"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3490422.3502364
  url: https://doi.org/10.1145/3490422.3502364
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM/SIGDA
  pubkey: ""
  pubname: "International Symposium on Field-Programmable Gate Arrays"
  reserved: DEADBEEF

135:
  title: "Fine-and Coarse-Granularity Hybrid Self-Attention for Efficient BERT"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2203.09055
  url: https://doi.org/10.48550/arXiv.2203.09055
  pdf: False
  ignore: check
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

136:
  title: "Fixed-point Quantization for Vision Transformer"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/CAC53003.2021.9728246
  url: https://doi.org/10.1109/CAC53003.2021.9728246
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "China Automation Congress (CAC)"
  reserved: DEADBEEF

137:
  title: "FlexACC: A Programmable Accelerator with Application-Specific ISA for Flexible Deep Neural Network Inference"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/ASAP52443.2021.00046
  url: https://doi.org/10.1109/ASAP52443.2021.00046
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Conference on Application-specific Systems, Architectures and Processors (ASAP)"
  reserved: DEADBEEF

138:
  title: "FPGA-aware automatic acceleration framework for vision transformer with mixed-scheme quantization: late breaking results"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3489517.3530618
  url: https://doi.org/10.1145/3489517.3530618
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM/IEEE
  pubkey: ""
  pubname: "ACM/IEEE Design Automation Conference"
  reserved: DEADBEEF

139:
  title: "FPGA-based design and implementation of the location attention mechanism in neural networks"
  year: 2022
  type: article
  doi: https://doi.org/10.3233/JIFS--212273
  url: https://doi.org/10.3233/JIFS-212273
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IOS%20Press
  pubkey: ""
  pubname: "Journal of Intelligent & Fuzzy Systems"
  reserved: DEADBEEF

140:
  title: "From dense to sparse: Contrastive pruning for better pre-trained language model compression"
  year: 2022
  type: article
  doi: https://doi.org/10.1609/aaai.v36i10.21408
  url: https://doi.org/10.1609/aaai.v36i10.21408
  pdf: False
  ignore: check
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: AAAI
  pubkey: ""
  pubname: "AAAI Technical Track on Speech and Natural Language Processing"
  reserved: DEADBEEF

141:
  title: "FTRANS: energy-efficient acceleration of transformers using FPGA"
  year: 2020
  type: article
  doi: https://doi.org/10.1145/3370748.3406567
  url: https://doi.org/10.1145/3370748.3406567
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM/IEEE
  pubkey: ""
  pubname: "ACM/IEEE International Symposium on Low Power Electronics and Design"
  reserved: DEADBEEF

142:
  title: "Future Scaling of Memory Hierarchy for Tensor Cores and Eliminating Redundant Shared Memory Traffic Using Inter-Warp Multicastin"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/TC.2022.3207134
  url: https://doi.org/10.1109/TC.2022.3207134
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Transactions on Computers"
  reserved: DEADBEEF

143:
  title: "Gemmini: Enabling systematic deep-learning architecture evaluation via full-stack integration"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/DAC18074.2021.9586216
  url: https://doi.org/10.1109/DAC18074.2021.9586216
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "ACM/IEEE Design Automation Conference (DAC)"
  reserved: DEADBEEF

144:
  title: "Gobo: Quantizing attention-based nlp models for low latency and energy efficient inference"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/MICRO50266.2020.00071
  url: https://doi.org/10.1109/MICRO50266.2020.00071
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE/ACM
  pubkey: ""
  pubname: "IEEE/ACM International Symposium on Microarchitecture (MICRO)"
  reserved: DEADBEEF

145:
  title: "Greedy-layer pruning: Speeding up transformer models for natural language processing"
  year: 2022
  type: article
  doi: https://doi.org/10.1016/j.patrec.2022.03.023
  url: https://doi.org/10.1016/j.patrec.2022.03.023
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Elsevier
  pubkey: ""
  pubname: "Pattern Recognition Letters"
  reserved: DEADBEEF

146:
  title: "GuardNN: secure accelerator architecture for privacy-preserving deep learning"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3489517.3530439
  url: https://doi.org/10.1145/3489517.3530439
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM/IEEE
  pubkey: ""
  pubname: "ACM/IEEE Design Automation Conference"
  reserved: DEADBEEF

147:
  title: "HAMMER: Hardware-friendly Approximate Computing for Self-attention with Mean-redistribution and Linearization"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/LCA.2022.3233832
  url: https://doi.org/10.1109/LCA.2022.3233832
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Computer Architecture Letters"
  reserved: DEADBEEF

148:
  title: "Handling heavy-tailed input of transformer inference on GPUs"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3524059.3532372
  url: https://doi.org/10.1145/3524059.3532372
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "ACM International Conference on Supercomputing (ICS)"
  reserved: DEADBEEF

149:
  title: "Hardware Acceleration of Fully Quantized BERT for Efficient Natural Language Processing"
  year: 2021
  type: article
  doi: https://doi.org/10.23919/DATE51398.2021.9474043
  url: https://doi.org/10.23919/DATE51398.2021.9474043
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "Design, Automation & Test in Europe Conference & Exhibition (DATE)"
  reserved: DEADBEEF

150:
  title: "Hardware acceleration of sparse and irregular tensor computations of ml models: A survey and insights"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/JPROC.2021.3098483
  url: https://doi.org/10.1109/JPROC.2021.3098483
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "Proceedings of the IEEE"
  reserved: DEADBEEF

151:
  title: "Hardware Acceleration of Transformer Networks using FPGAs"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/PACET56979.2022.9976354
  url: https://doi.org/10.1109/PACET56979.2022.9976354
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "Panhellenic Conference on Electronics & Telecommunications (PACET)"
  reserved: DEADBEEF

152:
  title: "Hardware accelerator for multi-head attention and position-wise feed-forward in the transformer"
  year: 2020
  type: article
  doi: https://doi.org/10.1109/SOCC49529.2020.9524802
  url: https://doi.org/10.1109/SOCC49529.2020.9524802
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International System-on-Chip Conference (SOCC)"
  reserved: DEADBEEF

153:
  title: "Hardware and Software Co-design for Soft Switch in ViT Variants Processing Unit"
  year: 2022
  type: article
  doi: https://doi.org/10.1007/978--3--031--10989--8_55
  url: https://doi.org/10.1007/978-3-031-10989-8_55
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "International Conference on Knowledge Science, Engineering and Management"
  reserved: DEADBEEF

154:
  title: "Hardware and Software Co-optimization for Windows Attention"
  year: 2022
  type: article
  doi: https://doi.org/10.1007/978--3--031--10989--8_52
  url: https://doi.org/10.1007/978-3-031-10989-8_52
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: None
  pubkey: ""
  pubname: "International Conference on Knowledge Science, Engineering and Management"
  reserved: DEADBEEF

155:
  title: "HMC-TRAN: A Tensor-core Inspired Hierarchical Model Compression for Transformer-based DNNs on GPU"
  year: 2021
  type: article
  doi: https://doi.org/10.1145/3453688.3461740
  url: https://doi.org/10.1145/3453688.3461740
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "Great Lakes Symposium on VLSI"
  reserved: DEADBEEF

156:
  title: "HoloFormer: Deep Compression of Pre-Trained Transforms via Unified Optimization of N: M Sparsity and Integer Quantization"
  year: 2021
  type: article
  doi: None
  url: None
  pdf: https://openreview.net/pdf?id=eAEcdRkcMHh
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: None
  pubkey: ""
  pubname: "None"
  reserved: DEADBEEF

157:
  title: "How Deep Learning Model Architecture and Software Stack Impacts Training Performance in the Cloud"
  year: 2021
  type: article
  doi: https://doi.org/978--3--030--89385--9
  url: https://doi.org/978-3-030-89385-9
  pdf: False
  ignore: check
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "Engineering Artificially Intelligent Systems"
  reserved: DEADBEEF

158:
  title: "How to Train BERT with an Academic Budget"
  year: 2021
  type: article
  doi: https://doi.org/10.48550/arXiv.2104.07705
  url: https://doi.org/10.48550/arXiv.2104.07705
  pdf: https://arxiv.org/pdf/2104.07705.pdf
  ignore: True
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

159:
  title: "I-BERT: Integer-only BERT Quantization"
  year: 2021
  type: article
  doi: https://doi.org/10.48550/arXiv.2101.01321
  url: https://proceedings.mlr.press/v139/kim21d.html
  pdf: http://proceedings.mlr.press/v139/kim21d/kim21d.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: PMLR
  pubkey: ""
  pubname: "Proceedings of Machine Learning Research"
  reserved: DEADBEEF

160:
  title: "Improving Accuracy and Speeding Up Document Image Classification Through Parallel Systems"
  year: 2020
  type: article
  doi: https://doi.org/10.1007/978--3--030--50417--5_29
  url: https://doi.org/10.1007/978-3-030-50417-5_29
  pdf: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7302855/pdf/978-3-030-50417-5_Chapter_29.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "International Conference on Computational Science"
  reserved: DEADBEEF

161:
  title: "Improving Oversubscribed GPU Memory Performance in the PyTorch Framework"
  year: 2022
  type: article
  doi: https://doi.org/10.1007/s10586--022--03805--x
  url: https://doi.org/10.1007/s10586-022-03805-x
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "Cluster Computing"
  reserved: DEADBEEF

162:
  title: "Improving post training neural quantization: Layer-wise calibration and integer programming"
  year: 2020
  type: article
  doi: https://arxiv.org/abs/2006.10518
  url: https://arxiv.org/abs/2006.10518
  pdf: https://arxiv.org/pdf/2006.10518.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

163:
  title: "Improving the efficiency of transformers for resource-constrained devices"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/DSD53832.2021.00074
  url: https://doi.org/10.1109/DSD53832.2021.00074
  pdf: https://arxiv.org/pdf/2106.16006.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "Euromicro Conference on Digital System Design (DSD)"
  reserved: DEADBEEF

164:
  title: "Integer Fine-tuning of Transformer-based Models"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2209.09815
  url: https://doi.org/10.48550/arXiv.2209.09815
  pdf: https://arxiv.org/pdf/2209.09815.pdf
  ignore: check
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

165:
  title: "Integer quantization for deep learning inference: Principles and empirical evaluation"
  year: 2020
  type: article
  doi: https://doi.org/10.48550/arXiv.2004.09602
  url: https://doi.org/10.48550/arXiv.2004.09602
  pdf: https://arxiv.org/pdf/2004.09602.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

166:
  title: "KAISA: An adaptive second-order optimizer framework for deep neural networks"
  year: 2021
  type: article
  doi: https://doi.org/10.1145/3458817.3476152
  url: https://doi.org/10.1145/3458817.3476152
  pdf: https://arxiv.org/pdf/2107.01739.pdf
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "International Conference for High Performance Computing, Networking, Storage and Analysis"
  reserved: DEADBEEF

167:
  title: "KDLSQ-BERT: A Quantized Bert Combining Knowledge Distillation with Learned Step Size Quantization"
  year: 2021
  type: article
  doi: https://doi.org/10.48550/arXiv.2101.05938
  url: https://doi.org/10.48550/arXiv.2101.05938
  pdf: https://arxiv.org/pdf/2101.05938.pdf
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

168:
  title: "Kunlun: A 14nm High-Performance AI Processor for Diversified Workloads"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/ISSCC42613.2021.9366056
  url: https://doi.org/10.1109/ISSCC42613.2021.9366056
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE International Solid- State Circuits Conference (ISSCC)"
  reserved: DEADBEEF

169:
  title: "Ladabert: Lightweight adaptation of bert through hybrid model compression"
  year: 2020
  type: article
  doi: https://doi.org/10.48550/arXiv.2004.04124
  url: https://doi.org/10.48550/arXiv.2004.04124
  pdf: https://arxiv.org/pdf/2004.04124.pdf
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

170:
  title: "Layerweaver: Maximizing Resource Utilization of Neural Processing Units via Layer-Wise Scheduling"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/HPCA51647.2021.00056
  url: https://doi.org/10.1109/HPCA51647.2021.00056
  pdf: https://taejunham.github.io/data/layerweaver_hpca21.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on High-Performance Computer Architecture (HPCA)"
  reserved: DEADBEEF

171:
  title: "Learned Token Pruning in Contextualized Late Interaction over BERT (ColBERT)"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3477495.3531835
  url: https://doi.org/10.1145/3477495.3531835
  pdf: https://web.Arxiv.org/web/20220713100651id_/https://dl.acm.org/doi/pdf/10.1145/3477495.3531835
  ignore: True
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "ACM SIGIR Conference on Research and Development in Information Retrieval"
  reserved: DEADBEEF

172:
  title: "Learning Light-Weight Translation Models from Deep Transformer"
  year: 2021
  type: article
  doi: https://doi.org/10.1609/aaai.v35i15.17561
  url: https://doi.org/10.1609/aaai.v35i15.17561
  pdf: https://ojs.aaai.org/index.php/AAAI/article/view/17561/17368
  ignore: check
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: AAAI
  pubkey: ""
  pubname: "AAAI Technical Track on Speech and Natural Language Processing II"
  reserved: DEADBEEF

173:
  title: "Lightweight Composite Re-Ranking for Efficient Keyword Search with BERT"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3488560.3498495
  url: https://doi.org/10.1145/3488560.3498495
  pdf: https://dl.acm.org/doi/pdf/10.1145/3488560.3498495
  ignore: check
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "ACM International Conference on Web Search and Data Mining"
  reserved: DEADBEEF

174:
  title: "Lightweight Transformers for Conversational AI"
  year: 2022
  type: article
  doi: http://dx.doi.org/10.18653/v1/2022.naacl--industry.25
  url: http://dx.doi.org/10.18653/v1/2022.naacl-industry.25
  pdf: https://aclanthology.org/2022.naacl-industry.25.pdf
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACL
  pubkey: ""
  pubname: "Conference of the North American Chapter of the Association for Computational Linguistics"
  reserved: DEADBEEF

175:
  title: "LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2208.07339
  url: https://doi.org/10.48550/arXiv.2208.07339
  pdf: https://arxiv.org/pdf/2208.07339
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

176:
  title: "Load What You Need: Smaller Versions of Multilingual BERT"
  year: 2020
  type: article
  doi: https://doi.org/10.48550/arXiv.2010.05609
  url: https://doi.org/10.48550/arXiv.2010.05609
  pdf: https://arxiv.org/pdf/2010.05609.pdf
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

177:
  title: "Look-Up Table based Energy Efficient Processing in Cache Support for Neural Network Acceleration"
  year: 2020
  type: article
  doi: https://doi.org/10.1109/MICRO50266.2020.00020
  url: https://doi.org/10.1109/MICRO50266.2020.00020
  pdf: https://www.microarch.org/micro53/papers/738300a088.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE/ACM
  pubkey: ""
  pubname: "IEEE/ACM International Symposium on Microarchitecture (MICRO)"
  reserved: DEADBEEF

178:
  title: "Low-Bit Quantization of Transformer for Audio Speech Recognition"
  year: 2022
  type: article
  doi: https://doi.org/10.1007/978--3--031--19032--2_12
  url: https://doi.org/10.1007/978-3-031-19032-2_12
  pdf: False
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "None"
  reserved: DEADBEEF

179:
  title: "Low-Precision Quantization Techniques for Hardware-Implementation-Friendly BERT Models"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/ISQED54688.2022.9806238
  url: https://doi.org/10.1109/ISQED54688.2022.9806238
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on Quality Electronic Design (ISQED)"
  reserved: DEADBEEF

180:
  title: "M2M: Learning to Enhance Low-Light Image from Model to Mobile FPGA"
  year: 2021
  type: article
  doi: https://doi.org/10.1007/978--3--030--89029--2_22
  url: https://doi.org/10.1007/978-3-030-89029-2_22
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "Computer Graphics International Conference"
  reserved: DEADBEEF

181:
  title: "MAGNet: A Modular Accelerator Generator for Neural Networks"
  year: 2019
  type: article
  doi: https://doi.org/10.1109/ICCAD45719.2019.8942127
  url: https://doi.org/10.1109/ICCAD45719.2019.8942127
  pdf: https://people.eecs.berkeley.edu/~ysshao/assets/papers/magnet2019-iccad.pdf
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE/ACM International Conference on Computer-Aided Design (ICCAD)"
  reserved: DEADBEEF

182:
  title: "MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers"
  year: 2020
  type: article
  doi: https://dl.acm.org/doi/abs/10.5555/3495724.3496209
  url: https://dl.acm.org/doi/abs/10.5555/3495724.3496209
  pdf: https://dl.acm.org/doi/pdf/10.5555/3495724.3496209
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "International Conference on Neural Information Processing Systems"
  reserved: DEADBEEF

183:
  title: "MKQ-BERT: Quantized BERT with 4-bits Weights and Activations"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2203.13483
  url: https://doi.org/10.48550/arXiv.2203.13483
  pdf: https://arxiv.org/pdf/2203.13483.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

184:
  title: "Mokey: enabling narrow fixed-point inference for out-of-the-box floating-point transformer models"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3470496.3527438
  url: https://doi.org/10.1145/3470496.3527438
  pdf: https://arxiv.org/pdf/2203.12758.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on Computer Architecture"
  reserved: DEADBEEF

185:
  title: "Movement Pruning: Adaptive Sparsity by Fine-Tuning"
  year: 2020
  type: article
  doi: https://doi.org/10.48550/arXiv.2005.07683
  url: https://doi.org/10.48550/arXiv.2005.07683
  pdf: https://proceedings.neurips.cc/paper/2020/file/eae15aabaa768ae4a5993a8a4f4fa6e4-Paper.pdf
  ignore: check
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: NeurIPS
  pubkey: ""
  pubname: "Advances in Neural Information Processing Systems"
  reserved: DEADBEEF

186:
  title: "Mr. BiQ: Post-Training Non-Uniform Quantization Based on Minimizing the Reconstruction Error"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/CVPR52688.2022.01201
  url: https://doi.org/10.1109/CVPR52688.2022.01201
  pdf: https://openaccess.thecvf.com/content/CVPR2022/papers/Jeon_Mr.BiQ_Post-Training_Non-Uniform_Quantization_Based_on_Minimizing_the_Reconstruction_Error_CVPR_2022_paper.pdf
  ignore: no
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE/CVF
  pubkey: "CVPR"
  pubname: "IEEE/CVF Conference on Computer Vision and Pattern Recognition"
  reserved: DEADBEEF

187:
  title: "mRNA: Enabling Efficient Mapping Space Exploration for a Reconfiguration Neural Accelerator"
  year: 2019
  type: article
  doi: https://doi.org/10.1109/ISPASS.2019.00040
  url: https://doi.org/10.1109/ISPASS.2019.00040
  pdf: https://bpb-us-w2.wpmucdn.com/sites.gatech.edu/dist/c/332/files/2019/02/mrna_ispass2019.pdf
  ignore: check
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)"
  reserved: DEADBEEF

188:
  title: "MSP: an FPGA-specific mixed-scheme, multi-precision deep neural network quantization framework"
  year: 2020
  type: article
  doi: https://doi.org/10.48550/arXiv.2009.07460
  url: https://doi.org/10.48550/arXiv.2009.07460
  pdf: https://arxiv.org/pdf/2009.07460.pdf
  ignore: check
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: arXiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

189:
  title: "NAS-BERT: Task-Agnostic and Adaptive-Size BERT Compression with Neural Architecture Search"
  year: 2021
  type: article
  doi: https://doi.org/10.1145/3447548.3467262
  url: https://doi.org/10.1145/3447548.3467262
  pdf: https://arxiv.org/pdf/2105.14444.pdf
  ignore: check
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "ACM SIGKDD Conference on Knowledge Discovery & Data Mining"
  reserved: DEADBEEF

190:
  title: "Near-Optimal Sparse Allreduce for Distributed Deep Learning"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3503221.3508399
  url: https://doi.org/10.1145/3503221.3508399
  pdf: https://arxiv.org/pdf/2201.07598.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming"
  reserved: DEADBEEF

191:
  title: "Nebula: A Scalable and Flexible Accelerator for DNN Multi-Branch Blocks on Embedded Systems"
  year: 2022
  type: article
  doi: https://doi.org/10.3390/electronics11040505
  url: https://doi.org/10.3390/electronics11040505
  pdf: https://www.mdpi.com/2079-9292/11/4/505/pdf
  ignore: True
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: MDPI
  pubkey: ""
  pubname: "Electronics"
  reserved: DEADBEEF

192:
  title: "NEEBS: Nonexpert large-scale environment building system for deep neural network"
  year: 2022
  type: article
  doi: https://doi.org/10.1002/cpe.7499
  url: https://doi.org/10.1002/cpe.7499
  pdf: False
  ignore: check
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Wiley
  pubkey: ""
  pubname: "Concurrency and Computation Practice and Experience"
  reserved: DEADBEEF

193:
  title: "NeuralScale: A RISC-V Based Neural Processor Boosting AI Inference in Clouds"
  year: 2021
  type: article
  doi: https://carrv.github.io/2021/
  url: https://carrv.github.io/2021/
  pdf: https://carrv.github.io/2021/papers/CARRV2021_paper_67_Zhan.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: CARRV
  pubkey: ""
  pubname: "Computer Architecture Research with RISC-V"
  reserved: DEADBEEF

194:
  title: "NLP-Fast: A Fast, Scalable, and Flexible System to Accelerate Large-Scale Heterogeneous NLP Models"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/PACT52795.2021.00013
  url: https://doi.org/10.1109/PACT52795.2021.00013
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Conference on Parallel Architectures and Compilation Techniques (PACT)"
  reserved: DEADBEEF

195:
  title: "NPE: An FPGA-based Overlay Processor for Natural Language Processing"
  year: 2021
  type: article
  doi: https://doi.org/10.1145/3431920.3439477
  url: https://doi.org/10.1145/3431920.3439477
  pdf: https://arxiv.org/pdf/2104.06535.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM/SIGDA
  pubkey: ""
  pubname: "ACM/SIGDA International Symposium on Field-Programmable Gate Arrays"
  reserved: DEADBEEF

196:
  title: "Optimal Brain Compression: A framework for accurate post-training quantization and pruning"
  year: 2022
  type: article
  doi: https://doi.org/10.48550/arXiv.2208.11580
  url: https://doi.org/10.48550/arXiv.2208.11580
  pdf: https://arxiv.org/pdf/2208.11580.pdf
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: NeurIPS
  pubkey: ""
  pubname: "Conference on Neural Information Processing Systems"
  reserved: DEADBEEF

197:
  title: "PipeBERT: High-throughput BERT Inference for ARM Big.LITTLE Multi-core Processors"
  year: 2022
  type: article
  doi: https://doi.org/10.1007/s11265--022--01814--y
  url: https://doi.org/10.1007/s11265-022-01814-y
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "Journal of Signal Processing Systems"
  reserved: DEADBEEF

198:
  title: "Poor Man's BERT: Smaller and Faster Transformer Models"
  year: 2020
  type: article
  doi: https://doi.org/10.48550/arXiv.2004.03844
  url: https://doi.org/10.48550/arXiv.2004.03844
  pdf: https://arxiv.org/pdf/2004.03844v1
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

199:
  title: "Post-Training Quantization for Longformer with Chunkwise Quantization Granularity and Optimized Percentile"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/ICCCS55155.2022.9846198
  url: https://doi.org/10.1109/ICCCS55155.2022.9846198
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Conference on Computer and Communication Systems (ICCCS)"
  reserved: DEADBEEF

200:
  title: "PoWER-BERT: Accelerating BERT Inference via Progressive Word-vector Elimination"
  year: 2020
  type: article
  doi: https://proceedings.mlr.press/v119/goyal20a.html
  url: https://proceedings.mlr.press/v119/goyal20a.html
  pdf: http://proceedings.mlr.press/v119/goyal20a/goyal20a.pdf
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: PMLR
  pubkey: ""
  pubname: "Proceedings of Machine Learning Research"
  reserved: DEADBEEF

201:
  title: "Pre-trained bert-gru model for relation extraction"
  year: 2019
  type: article
  doi: https://doi.org/10.1145/3373509.3373533
  url: https://doi.org/10.1145/3373509.3373533
  pdf: False
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "International Conference on Computing and Pattern Recognition"
  reserved: DEADBEEF

202:
  title: "Pre-trained Language Model with Feature Reduction and No Fine-Tuning"
  year: 2022
  type: article
  doi: https://doi.org/10.1007/978--981--19--3923--5_59
  url: https://doi.org/10.1007/978-981-19-3923-5_59
  pdf: False
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "Control, Instrumentation and Mechatronics: Theory and Practice"
  reserved: DEADBEEF

203:
  title: "Predicting Efficiency/Effectiveness Trade-offs for Dense vs. Sparse Retrieval Strategy Selection"
  year: 2021
  type: article
  doi: https://doi.org/10.1145/3459637.3482159
  url: https://doi.org/10.1145/3459637.3482159
  pdf: False
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "ACM International Conference on Information & Knowledge Management"
  reserved: DEADBEEF

204:
  title: "Privacy-Preserving Text Classification on BERT Embeddings with Homomorphic Encryption"
  year: 2022
  type: article
  doi: https://arxiv.org/abs/2210.02574
  url: https://arxiv.org/abs/2210.02574
  pdf: https://arxiv.org/pdf/2210.02574.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computation and Language"
  reserved: DEADBEEF

205:
  title: "ProSE: the architecture and design of a protein discovery engine"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3503222.3507722
  url: https://doi.org/10.1145/3503222.3507722
  pdf: https://par.nsf.gov/servlets/purl/10394954
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "ACM International Conference on Architectural Support for Programming Languages and Operating Systems"
  reserved: DEADBEEF

206:
  title: "Pruning Redundant Mappings in Transformer Models via Spectral-Normalized Identity Prior"
  year: 2020
  type: article
  doi: https://arxiv.org/abs/2010.01791
  url: https://arxiv.org/abs/2010.01791
  pdf: https://arxiv.org/pdf/2010.01791.pdf
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

207:
  title: "PTQ4ViT: Post-Training Quantization Framework for Vision Transformers with Twin Uniform Quantization"
  year: 2021
  type: article
  doi: https://arxiv.org/abs/2111.12293
  url: https://arxiv.org/abs/2111.12293
  pdf: https://arxiv.org/pdf/2111.12293
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computer Vision and Pattern Recognition"
  reserved: DEADBEEF

208:
  title: "Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT"
  year: 2020
  type: article
  doi: https://doi.org/10.1609/aaai.v34i05.6409
  url: https://doi.org/10.1609/aaai.v34i05.6409
  pdf: https://ojs.aaai.org/index.php/AAAI/article/view/6409/6265
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: AAAI
  pubkey: ""
  pubname: "AAAI Technical Track: Natural Language Processing"
  reserved: DEADBEEF

209:
  title: "Q8BERT: Quantized 8Bit BERT"
  year: 2019
  type: article
  doi: https://doi.org/10.1109/EMC2--NIPS53020.2019.00016
  url: https://doi.org/10.1109/EMC2-NIPS53020.2019.00016
  pdf: https://arxiv.org/pdf/1910.06188.pdf
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "Workshop on Energy Efficient Machine Learning and Cognitive Computing - NeurIPS Edition (EMC2-NIPS)"
  reserved: DEADBEEF

210:
  title: "QDrop: Randomly Dropping Quantization for Extremely Low-bit Post-Training Quantization"
  year: 2022
  type: article
  doi: https://arxiv.org/abs/2203.05740
  url: https://arxiv.org/abs/2203.05740
  pdf: https://arxiv.org/pdf/2203.05740
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computer Vision and Pattern Recognition"
  reserved: DEADBEEF

211:
  title: "QuaLA-MiniLM: a Quantized Length Adaptive MiniLM"
  year: 2022
  type: article
  doi: https://arxiv.org/abs/2210.17114
  url: https://arxiv.org/abs/2210.17114
  pdf: https://arxiv.org/pdf/2210.17114
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

212:
  title: "Randomly Wired Network Based on RoBERTa and Dialog History Attention for Response Selection"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/TASLP.2021.3077119
  url: https://doi.org/10.1109/TASLP.2021.3077119
  pdf: False
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE/ACM Transactions on Audio, Speech, and Language Processing"
  reserved: DEADBEEF

213:
  title: "RCT: Resource Constrained Training for Edge AI"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/TNNLS.2022.3190451
  url: https://doi.org/10.1109/TNNLS.2022.3190451
  pdf: https://arxiv.org/pdf/2103.14493.pdf
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Transactions on Neural Networks and Learning Systems"
  reserved: DEADBEEF

214:
  title: "Re2PIM: A Reconfigurable ReRAM-Based PIM Design for Variable-Sized Vector-Matrix Multiplication"
  year: 2021
  type: article
  doi: https://doi.org/10.1145/3453688.3461494
  url: https://doi.org/10.1145/3453688.3461494
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "Proceedings on Great Lakes Symposium on VLSI"
  reserved: DEADBEEF

215:
  title: "ReAAP: A Reconfigurable and Algorithm-Oriented Array Processor With Compiler-Architecture Co-Design"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/TC.2022.3213177
  url: https://doi.org/10.1109/TC.2022.3213177
  pdf: https://ieeexplore.ieee.org/iel7/12/4358213/09914609.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Transactions on Computers"
  reserved: DEADBEEF

216:
  title: "ReTransformer: ReRAM-based processing-in-memory architecture for transformer acceleration"
  year: 2020
  type: article
  doi: https://doi.org/10.1145/3400302.3415640
  url: https://doi.org/10.1145/3400302.3415640
  pdf: https://dl.acm.org/doi/pdf/10.1145/3400302.3415640
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "International Conference on Computer-Aided Design"
  reserved: DEADBEEF

217:
  title: "RISC-VTF: RISC-V Based Extended Instruction Set for Transformer"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/SMC52423.2021.9658643
  url: https://doi.org/10.1109/SMC52423.2021.9658643
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE International Conference on Systems, Man, and Cybernetics"
  reserved: DEADBEEF

218:
  title: "RMSMP: A Novel Deep Neural Network Quantization Framework with Row-wise Mixed Schemes and Multiple Precisions"
  year: 2021
  type: article
  doi: xx
  url: None
  pdf: https://openaccess.thecvf.com/content/ICCV2021/papers/Chang_RMSMP_A_Novel_Deep_Neural_Network_Quantization_Framework_With_Row-Wise_ICCV_2021_paper.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: None
  pubkey: ""
  pubname: "IEEE/CVF International Conference on Computer Vision"
  reserved: DEADBEEF

219:
  title: "Row-wise Accelerator for Vision Transformer"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/AICAS54282.2022.9869928
  url: https://doi.org/10.1109/AICAS54282.2022.9869928
  pdf: https://arxiv.org/pdf/2205.03998.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Conference on Artificial Intelligence Circuits and Systems"
  reserved: DEADBEEF

220:
  title: "S4: a High-sparsity, High-performance AI Accelerator"
  year: 2022
  type: article
  doi: https://arxiv.org/abs/2207.08006
  url: https://arxiv.org/abs/2207.08006
  pdf: https://arxiv.org/pdf/2207.08006
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxive
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

221:
  title: "SALO: an efficient spatial accelerator enabling hybrid sparse attention mechanisms for long sequences"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3489517.3530504
  url: https://doi.org/10.1145/3489517.3530504
  pdf: https://arxiv.org/pdf/2206.14550.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "ACM/IEEE Design Automation Conference"
  reserved: DEADBEEF

222:
  title: "Sanger: A Co-Design Framework for Enabling Sparse Attention using Reconfigurable Architecture"
  year: 2021
  type: article
  doi: https://doi.org/10.1145/3466752.3480125
  url: https://doi.org/10.1145/3466752.3480125
  pdf: https://dl.acm.org/doi/pdf/10.1145/3466752.3480125
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE/ACM
  pubkey: ""
  pubname: "IEEE/ACM International Symposium on Microarchitecture"
  reserved: DEADBEEF

223:
  title: "Searching for memory-lighter architectures for OCR-augmented image captioning"
  year: 2022
  type: article
  doi: https://doi.org/10.3233/JIFS--219230
  url: https://doi.org/10.3233/JIFS-219230
  pdf: False
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: None
  pubkey: ""
  pubname: "Journal of Intelligent & Fuzzy Systems"
  reserved: DEADBEEF

224:
  title: "SECDA-TFLite: A toolkit for efficient development of FPGA-based DNN accelerators for edge inference"
  year: 2023
  type: article
  doi: https://doi.org/10.1016/j.jpdc.2022.11.005
  url: https://doi.org/10.1016/j.jpdc.2022.11.005
  pdf: https://www.sciencedirect.com/science/article/pii/S0743731522002301/pdfft?md5=444fdc7e73724f5d9881d162bed2a735&pid=1-s2.0-S0743731522002301-main.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Elsevier
  pubkey: ""
  pubname: "Journal of Parallel and Distributed Computing"
  reserved: DEADBEEF

225:
  title: "SensiMix: Sensitivity-Aware 8-bit index & 1-bit value mixed precision quantization for BERT compression"
  year: 2022
  type: article
  doi: https://doi.org/10.1371/journal.pone.0265621
  url: https://doi.org/10.1371/journal.pone.0265621
  pdf: https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0265621&type=printable
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: PLOSONE
  pubkey: ""
  pubname: "None"
  reserved: DEADBEEF

226:
  title: "Sentiment Analysis Using Pre-Trained Language Model With No Fine-Tuning and Less Resource"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/ACCESS.2022.3212367
  url: https://doi.org/10.1109/ACCESS.2022.3212367
  pdf: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9912410
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Access"
  reserved: DEADBEEF

227:
  title: "Simplified TinyBERT: Knowledge Distillation for Document Retrieval"
  year: 2021
  type: article
  doi: https://doi.org/10.1007/978--3--030--72240--1_21
  url: https://doi.org/10.1007/978-3-030-72240-1_21
  pdf: https://arxiv.org/pdf/2009.07531.pdf
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "Advances in Information Retrieval"
  reserved: DEADBEEF

228:
  title: "SmaQ: Smart Quantization for DNN Training by Exploiting Value Clustering"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/LCA.2021.3108505
  url: https://doi.org/10.1109/LCA.2021.3108505
  pdf: https://hparch.gatech.edu/papers/nima_2021_cal.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Computer Architecture Letters"
  reserved: DEADBEEF

229:
  title: "SmoothQuant: Accurate and Efficient Post-Training Quantization for Large Language Models"
  year: 2023
  type: article
  doi: https://arxiv.org/abs/2211.10438
  url: https://arxiv.org/abs/2211.10438
  pdf: https://arxiv.org/pdf/2211.10438.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language'"
  reserved: DEADBEEF

230:
  title: "Softermax: Hardware/Software Co-Design of an Efficient Softmax for Transformers"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/DAC18074.2021.9586134
  url: https://doi.org/10.1109/DAC18074.2021.9586134
  pdf: https://arxiv.org/pdf/2103.09301.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM/IEEE
  pubkey: ""
  pubname: "ACM/IEEE Design Automation Conference"
  reserved: DEADBEEF

231:
  title: "Software and Hardware Fusion Multi-Head Attention"
  year: 2022
  type: article
  doi: http://dx.doi.org/10.1007/978--3--031--10989--8_51
  url: http://dx.doi.org/10.1007/978-3-031-10989-8_51
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Springer
  pubkey: ""
  pubname: "International Conference on Knowledge Science, Engineering and Management"
  reserved: DEADBEEF

232:
  title: "Sparse Attention Acceleration with Synergistic In-Memory Pruning and On-Chip Recomputation"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/MICRO56248.2022.00059
  url: https://doi.org/10.1109/MICRO56248.2022.00059
  pdf: https://arxiv.org/pdf/2209.00606.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE/ACM International Symposium on Microarchitecture"
  reserved: DEADBEEF

233:
  title: "Sparse*BERT: Sparse Models Generalize To New tasks and Domains"
  year: 2023
  type: article
  doi: https://arxiv.org/abs/2205.12452
  url: https://arxiv.org/abs/2205.12452
  pdf: https://arxiv.org/pdf/2205.12452
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

234:
  title: "SparseNN: An energy-efficient neural network accelerator exploiting input and output sparsity"
  year: 2018
  type: article
  doi: https://doi.org/10.23919/DATE.2018.8342010
  url: https://doi.org/10.23919/DATE.2018.8342010
  pdf: https://doi.org/10.23919/DATE.2018.8342010
  ignore: True
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: None
  pubkey: ""
  pubname: "Design, Automation & Test in Europe Conference & Exhibition"
  reserved: DEADBEEF

235:
  title: "SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/HPCA51647.2021.00018
  url: https://doi.org/10.1109/HPCA51647.2021.00018
  pdf: https://arxiv.org/pdf/2012.09852.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on High-Performance Computer Architecture"
  reserved: DEADBEEF

236:
  title: "SQuAT: Sharpness- and Quantization-Aware Training for BERT"
  year: 2021
  type: article
  doi: https://arxiv.org/abs/2210.07171
  url: https://arxiv.org/abs/2210.07171
  pdf: https://arxiv.org/pdf/2210.07171.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

237:
  title: "SqueezeBERT: What can computer vision teach NLP about efficient neural networks?"
  year: 2020
  type: article
  doi: https://arxiv.org/abs/2006.11316
  url: https://arxiv.org/abs/2006.11316
  pdf: https://arxiv.org/pdf/2006.11316.pdf
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

238:
  title: "Stochastic precision ensemble: self-knowledge distillation for quantized deep neural networks"
  year: 2021
  type: article
  doi: https://doi.org/10.1609/aaai.v35i8.16839
  url: https://doi.org/10.1609/aaai.v35i8.16839
  pdf: https://ojs.aaai.org/index.php/AAAI/article/view/16839/16646
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: AAAI
  pubkey: ""
  pubname: "AAAI Technical Track on Machine Learning I"
  reserved: DEADBEEF

239:
  title: "Structured pruning of a BERT-based question answering model"
  year: 2019
  type: article
  doi: https://arxiv.org/abs/1910.06360
  url: https://arxiv.org/abs/1910.06360
  pdf: https://arxiv.org/pdf/1910.06360
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

240:
  title: "Structured pruning of large language models"
  year: 2019
  type: article
  doi: https://arxiv.org/abs/1910.04732
  url: https://arxiv.org/abs/1910.04732
  pdf: https://arxiv.org/pdf/1910.04732
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

241:
  title: "SwiftPruner: Reinforced Evolutionary Pruning for Efficient Ad Relevance"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3511808.3557139
  url: https://doi.org/10.1145/3511808.3557139
  pdf: https://arxiv.org/pdf/2209.00625.pdf
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "ACM International Conference on Information & Knowledge Management"
  reserved: DEADBEEF

242:
  title: "T-OPU: An FPGA-based Overlay Processor for Natural Language Processing"
  year: 2022
  type: article
  doi: https://escholarship.org/uc/item/9r46v693
  url: https://escholarship.org/uc/item/9r46v693
  pdf: https://escholarship.org/content/qt9r46v693/qt9r46v693.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: UCLA
  pubkey: ""
  pubname: "Open Access Publications from the University of California"
  reserved: DEADBEEF

243:
  title: "Talos: A Weighted Speedup-Aware Device Placement of Deep Learning Models"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/ASAP52443.2021.00023
  url: https://doi.org/10.1109/ASAP52443.2021.00023
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Conference on Application-specific Systems, Architectures and Processors"
  reserved: DEADBEEF

244:
  title: "Teacher Intervention: Improving Convergence of Quantization Aware Training for Ultra-Low Precision Transformers"
  year: 2023
  type: article
  doi: https://arxiv.org/abs/2302.11812
  url: https://arxiv.org/abs/2302.11812
  pdf: https://arxiv.org/pdf/2302.11812
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

245:
  title: "TernaryBERT: Distillation-aware Ultra-low Bit BERT"
  year: 2020
  type: article
  doi: https://arxiv.org/abs/2009.12812
  url: https://arxiv.org/abs/2009.12812
  pdf: https://arxiv.org/pdf/2009.12812
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

246:
  title: "The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models"
  year: 2022
  type: article
  doi: https://arxiv.org/abs/2203.07259
  url: https://arxiv.org/abs/2203.07259
  pdf: https://arxiv.org/pdf/2203.07259.pdf
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

247:
  title: "TiC-SAT: Tightly-Coupled Systolic Accelerator for Transformers"
  year: 2023
  type: article
  doi: https://doi.org/10.1145/3566097.3567867
  url: https://doi.org/10.1145/3566097.3567867
  pdf: https://infoscience.epfl.ch/record/298067/files/TiC_SAT_ASPDAC-preprint.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "Asia and South Pacific Design Automation Conference"
  reserved: DEADBEEF

248:
  title: "Tinybert: Distilling bert for natural language understanding"
  year: 2019
  type: article
  doi: https://arxiv.org/abs/1909.10351
  url: https://arxiv.org/abs/1909.10351
  pdf: https://arxiv.org/pdf/1909.10351
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

249:
  title: "Towards efficient post-training quantization of pre-trained language models"
  year: 2022
  type: article
  doi: link
  url: https://proceedings.neurips.cc/paper_files/paper/2022/hash/096347b4efc264ae7f07742fea34af1f-Abstract-Conference.html
  pdf: https://proceedings.neurips.cc/paper_files/paper/2022/file/096347b4efc264ae7f07742fea34af1f-Paper-Conference.pdf
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: NeurIPS
  pubkey: ""
  pubname: "Advances in Neural Information Processing Systems"
  reserved: DEADBEEF

250:
  title: "TR-BERT: Dynamic Token Reduction for Accelerating BERT Inference"
  year: 2021
  type: article
  doi: https://arxiv.org/abs/2105.11618
  url: https://arxiv.org/abs/2105.11618
  pdf: https://arxiv.org/pdf/2105.11618.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

251:
  title: "Train Flat, Then Compress: Sharpness-Aware Minimization Learns More Compressible Models"
  year: 2022
  type: article
  doi: https://arxiv.org/abs/2205.12694
  url: https://arxiv.org/abs/2205.12694
  pdf: https://arxiv.org/pdf/2205.12694.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

252:
  title: "Training Large Neural Networks with Constant Memory using a New Execution Algorithm"
  year: 2020
  type: article
  doi: https://arxiv.org/abs/2002.05645
  url: https://arxiv.org/abs/2002.05645
  pdf: https://arxiv.org/pdf/2002.05645.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

253:
  title: "Training with Quantization Noise for Extreme Model Compression"
  year: 2021
  type: article
  doi: https://arxiv.org/abs/2004.07320
  url: https://arxiv.org/abs/2004.07320
  pdf: https://arxiv.org/pdf/2004.07320.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

254:
  title: "TranCIM: Full-Digital Bitline-Transpose CIM-based Sparse Transformer Accelerator With Pipeline/Parallel Reconfigurable Modes"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/JSSC.2022.3213542
  url: https://doi.org/10.1109/JSSC.2022.3213542
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Journal of Solid-State Circuits"
  reserved: DEADBEEF

255:
  title: "Transformer Acceleration with Dynamic Sparse Attention"
  year: 2021
  type: article
  doi: https://arxiv.org/abs/2110.11299
  url: https://arxiv.org/abs/2110.11299
  pdf: https://arxiv.org/pdf/2110.11299
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

256:
  title: "TransPIM: A Memory-based Acceleration via Software-Hardware Co-Design for Transformer"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/HPCA53966.2022.00082
  url: https://doi.org/10.1109/HPCA53966.2022.00082
  pdf: https://par.nsf.gov/servlets/purl/10345536
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE International Symposium on High-Performance Computer Architecture (HPCA)"
  reserved: DEADBEEF

257:
  title: "Ultron-AutoML: An open-source, distributed, scalable framework for efficient hyper-parameter optimization"
  year: 2020
  type: article
  doi: https://doi.org/10.1109/BigData50022.2020.9378071
  url: https://doi.org/10.1109/BigData50022.2020.9378071
  pdf: https://ashish-gupta03.github.io/files/Ultron.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Conference on Big Data (Big Data)"
  reserved: DEADBEEF

258:
  title: "Understanding and Overcoming the Challenges of Efficient Transformer Quantization"
  year: 2021
  type: article
  doi: https://arxiv.org/abs/2109.12948
  url: https://arxiv.org/abs/2109.12948
  pdf: https://arxiv.org/pdf/2109.12948.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

259:
  title: "VAQF: Fully Automatic Software-Hardware Co-Design Framework for Low-Bit Vision Transformer"
  year: 2022
  type: article
  doi: https://arxiv.org/abs/2201.06618
  url: https://arxiv.org/abs/2201.06618
  pdf: https://arxiv.org/pdf/2201.06618.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

260:
  title: "Varuna: Scalable, Low-cost Training of Massive Deep Learning Models"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3492321.3519584
  url: https://doi.org/10.1145/3492321.3519584
  pdf: False
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "Proceedings of the Seventeenth European Conference on Computer Systems"
  reserved: DEADBEEF

261:
  title: "ViA: A Novel Vision-Transformer Accelerator Based on FPGA"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/TCAD.2022.3197489
  url: https://doi.org/10.1109/TCAD.2022.3197489
  pdf: None
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Transactions on Computer-Aided Design of Integrated Circuits and System[s"
  reserved: DEADBEEF

262:
  title: "Vis-TOP: Visual Transformer Overlay Processor"
  year: 2021
  type: article
  doi: https://arxiv.org/abs/2110.10957
  url: https://arxiv.org/abs/2110.10957
  pdf: https://arxiv.org/pdf/2110.10957.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computer Vision and Pattern Recognition"
  reserved: DEADBEEF

263:
  title: "ViTALiTy: Unifying Low-rank and Sparse Approximation for Vision Transformer Acceleration with a Linear Taylor Attention"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/HPCA56546.2023.10071081
  url: https://doi.org/10.1109/HPCA56546.2023.10071081
  pdf: https://arxiv.org/pdf/2211.05109.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Symposium on High-Performance Computer Architecture (HPCA)"
  reserved: DEADBEEF

264:
  title: "Work-in-Progress: Utilizing latency and accuracy predictors for efficient hardware-aware NAS"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/CODES-ISSS55005.2022.00014
  url: https://doi.org/10.1109/CODES-ISSS55005.2022.00014
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS)"
  reserved: DEADBEEF

265:
  title: "XTC: Extreme Compression for Pre-trained Transformers Made Simple and Efficient"
  year: 2022
  type: article
  doi: None
  url: None
  pdf: https://proceedings.neurips.cc/paper_files/paper/2022/file/1579d5d8edacd85ac1a86aea28bdf32d-Paper-Conference.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: None
  pubkey: ""
  pubname: "None"
  reserved: DEADBEEF

266:
  title: "ZeroQuant: Efficient and Affordable Post-Training Quantization for Large-Scale Transformers"
  year: 2022
  type: article
  doi: None
  url: None
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: None
  pubkey: ""
  pubname: "None"
  reserved: DEADBEEF

267:
  title: "Fully Unsupervised Machine Translation Using Context-Aware Word Translation and Denoising Autoencoder"
  year: 2022
  type: article
  doi: https://doi.org/10.1080/08839514.2022.2031817
  url: https://doi.org/10.1080/08839514.2022.2031817
  pdf: https://www.tandfonline.com/doi/pdf/10.1080/08839514.2022.2031817
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: None
  pubkey: ""
  pubname: "None"
  reserved: DEADBEEF

268:
  title: "DistilHuBERT: Speech representation learning by layer-wise distillation of hidden-unit BERT"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/ICASSP43922.2022.9747490
  url: https://doi.org/10.1109/ICASSP43922.2022.9747490
  pdf: https://arxiv.org/pdf/2110.01900.pdf
  ignore: True
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE International Conference on Acoustics, Speech and Signal Processing"
  reserved: DEADBEEF

269:
  title: "Data Movement Reduction for DNN Accelerators: Enabling Dynamic Quantization Through an eFPGA"
  year: 2022
  type: article
  doi: https://doi.org/10.1109/ISVLSI54635.2022.00082
  url: https://doi.org/10.1109/ISVLSI54635.2022.00082
  pdf: https://scholar.archive.org/work/hd53tmr62rhn3mxplkjzhrnvw4/access/wayback/https://publikationen.bibliothek.kit.edu/1000151937/149523013
  ignore: True
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "Computer Society Annual Symposium on VLSI"
  reserved: DEADBEEF

270:
  title: "Elbert: Fast albert with confidence-window based early exit"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/ICASSP39728.2021.9414572
  url: https://doi.org/10.1109/ICASSP39728.2021.9414572
  pdf: https://arxiv.org/pdf/2107.00175.pdf
  ignore: False
  silicon: False
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE International Conference on Acoustics, Speech and Signal Processing"
  reserved: DEADBEEF

271:
  title: "Ghostbert: Generate more features with cheap operations for BERT"
  year: 2021
  type: article
  doi: http://dx.doi.org/10.18653/v1/2021.acl--long.509
  url: http://dx.doi.org/10.18653/v1/2021.acl-long.509
  pdf: https://aclanthology.org/2021.acl-long.509.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACL
  pubkey: ""
  pubname: "International Joint Conference on Natural Language Processing"
  reserved: DEADBEEF

272:
  title: "Hardware-friendly compression and hardware acceleration for transformer: A survey"
  year: 2022
  type: article
  doi: https://www.aimspress.com/article/doi/10.3934/era.2022192
  url: https://www.aimspress.com/article/doi/10.3934/era.2022192
  pdf: https://www.aimspress.com/aimspress-data/era/2022/10/PDF/era-30-10-192.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: AIMPress
  pubkey: ""
  pubname: "Electronic Research Archive"
  reserved: DEADBEEF

273:
  title: "Hardware/Software Co-Design of Edge DNN Accelerators with TFLite"
  year: 2022
  type: article
  doi: https://doi.org/10.1007/978--3--030--87208--8_5
  url: https://https://eprints.gla.ac.uk/280378/
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: HiPEAC
  pubkey: ""
  pubname: "International Summer School on Advanced Computer Architecture and Compilation for High-Performance and Embedded Systems"
  reserved: DEADBEEF

274:
  title: "Towards Fully 8-bit Integer Inference for the Transformer Model"
  year: 2020
  type: article
  doi: https://arxiv.org/abs/2009.08034
  url: https://arxiv.org/abs/2009.08034
  pdf: https://arxiv.org/pdf/2009.08034.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arixv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

275:
  title: "ViTA: A Vision Transformer Inference Accelerator for Edge Applications"
  year: 2023
  type: article
  doi: https://doi.org/10.48550/arXiv.2302.09108
  url: https://doi.org/10.48550/arXiv.2302.09108
  pdf: https://arxiv.org/pdf/2302.09108.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

276:
  title: "Trends in AI inference energy consumption: Beyond the performance-vs-parameter laws of deep learning"
  year: 2023
  type: article
  doi: https://doi.org/10.1016/j.suscom.2023.100857
  url: https://doi.org/10.1016/j.suscom.2023.100857
  pdf: https://www.sciencedirect.com/science/article/pii/S2210537923000124/pdfft?md5=4bec2735c1586b935287e6afea9e63a2&pid=1-s2.0-S2210537923000124-main.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Elsevier
  pubkey: ""
  pubname: "Sustainable Computing: Informatics and Systems"
  reserved: DEADBEEF

277:
  title: "TRON: Transformer Neural Network Acceleration with Non-Coherent Silicon Photonics"
  year: 2023
  type: article
  doi: https://doi.org/10.48550/arXiv.2303.12914
  url: https://doi.org/10.48550/arXiv.2303.12914
  pdf: https://arxiv.org/pdf/2303.12914.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

278:
  title: "TransCODE: Co-design of Transformers and Accelerators for Efficient Training and Inference"
  year: 2023
  type: article
  doi: https://doi.org/10.48550/arXiv.2303.14882
  url: https://doi.org/10.48550/arXiv.2303.14882
  pdf: https://arxiv.org/pdf/2303.14882
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

279:
  title: "ProtTrans: Toward Understanding the Language of Life Through Self-Supervised Learning"
  year: 2021
  type: article
  doi: https://doi.org/10.1109/TPAMI.2021.3095381
  url: https://doi.org/10.1109/TPAMI.2021.3095381
  pdf: https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9477085
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Transactions on Pattern Analysis and Machine Intelligence"
  reserved: DEADBEEF

280:
  title: "Prune once for all: Sparse pre-trained language models"
  year: 2021
  type: article
  doi: https://arxiv.org/abs/2111.05754
  url: https://arxiv.org/abs/2111.05754
  pdf: https://arxiv.org/pdf/2111.05754.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

281:
  title: "ROSITA: Refined BERT cOmpreSsion with InTegrAted techniques"
  year: 2021
  type: article
  doi: https://doi.org/10.1609/aaai.v35i10.17056
  url: https://doi.org/10.1609/aaai.v35i10.17056
  pdf: https://ojs.aaai.org/index.php/AAAI/article/download/17056/16863
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: None
  pubkey: ""
  pubname: "None"
  reserved: DEADBEEF

282:
  title: "TinyVers: A Tiny Versatile System-on-chip with State-Retentive eMRAM for ML Inference at the Extreme Edge"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/JSSC.2023.3236566
  url: https://doi.org/10.1109/JSSC.2023.3236566
  pdf: https://arxiv.org/pdf/2301.03537.pdf
  ignore: ignore
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Journal of Solid-State Circuits"
  reserved: DEADBEEF

283:
  title: "TopicBERT for energy efficient document classification"
  year: 2020
  type: article
  doi: https://doi.org/10.48550/arXiv.2010.16407
  url: https://doi.org/10.48550/arXiv.2010.16407
  pdf: https://arxiv.org/pdf/2010.16407.pdf
  ignore: False
  silicon: wip
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

284:
  title: "VS-Quant: Per-vector Scaled Quantization for Accurate Low-Precision Neural Network Inference"
  year: 2021
  type: article
  doi: https://proceedings.mlsys.org/paper_files/paper/2021
  url: https://proceedings.mlsys.org/paper_files/paper/2021
  pdf: https://proceedings.mlsys.org/paper_files/paper/2021/file/48a6431f04545e11919887748ec5cb52-Paper.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: MLSys
  pubkey: ""
  pubname: "Proceedings of Machine Learning and Systems"
  reserved: DEADBEEF

285:
  title: "Workload-Balanced Graph Attention Network Accelerator with Top-K Aggregation Candidates"
  year: 2022
  type: article
  doi: https://doi.org/10.1145/3508352.3549343
  url: https://doi.org/10.1145/3508352.3549343
  pdf: False
  ignore: False
  silicon: check
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "International Conference on Computer-Aided Design"
  reserved: DEADBEEF

286:
  title: "Architecting High Performance Silicon Systems for Accurate and Efficient On-Chip Deep Learning"
  year: 2023
  type: article
  doi: https://nrs.harvard.edu/URN--3:HUL.INSTREPOS:37375806
  url: https://nrs.harvard.edu/URN-3:HUL.INSTREPOS:37375806
  pdf: https://dash.harvard.edu/bitstream/handle/1/37375806/Final_Draft_PhD_Dissertation_Thierry_Tambe.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: HarwardLibrary
  pubkey: ""
  pubname: "Harvard University Graduate School of Arts and Sciences"
  reserved: DEADBEEF

287:
  title: "Hardware-efficient Softmax Approximation for Self-Attention Networks"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/ISCAS46773.2023.10181465
  url: https://doi.org/10.1109/ISCAS46773.2023.10181465
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE International Symposium on Circuits and Systems (ISCAS)"
  reserved: DEADBEEF

288:
  title: "Fast Prototyping Next-Generation Accelerators for New ML Models using MASE: ML Accelerator System Exploration"
  year: 2023
  type: article
  doi: https://arxiv.org/abs/2307.15517
  url: https://arxiv.org/abs/2307.15517
  pdf: https://arxiv.org/pdf/2307.15517.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

289:
  title: "Advances in Electromagnetics Empowered by Artificial Intelligence and Deep Learning"
  year: 2023
  type: article
  doi: ISBN:9781119853893
  url: https://books.google.com/books?id=rlPNEAAAQBAJ
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: Wiley
  pubkey: ""
  pubname: "IEEE Press Series on Electromagnetic Wave Theory"
  reserved: DEADBEEF

290:
  title: "A Scalable GPT-2 Inference Hardware Architecture on FPGA"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/IJCNN54540.2023.10191067
  url: https://doi.org/10.1109/IJCNN54540.2023.10191067
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "International Joint Conference on Neural Networks (IJCNN)"
  reserved: DEADBEEF

291:
  title: "BL-PIM: Varying the Burst Length to Realize the All-Bank Performance and Minimize the Multi-Workload Interference for in-DRAM PIM"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/ACCESS.2023.3300893
  url: https://doi.org/10.1109/ACCESS.2023.3300893
  pdf: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10198428
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Access"
  reserved: DEADBEEF

292:
  title: "Integrated Transformers Inference Framework for Multiple Tenants on GPU"
  year: 2023
  type: article
  doi: https://hdl.handle.net/2123/31606
  url: https://hdl.handle.net/2123/31606
  pdf: https://ses.library.usyd.edu.au/bitstream/handle/2123/31606/Thesis__Yuning_Zhang%20%281%29.pdf?sequence=2&isAllowed=y
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: SydneyDigital
  pubkey: ""
  pubname: "Sydney Digital Theses"
  reserved: DEADBEEF

293:
  title: "Embedded Deep Learning Accelerators: A Survey on Recent Advances"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/TAI.2023.3311776
  url: https://doi.org/10.1109/TAI.2023.3311776
  pdf: False
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Transactions on Artificial Intelligence "
  reserved: DEADBEEF

294:
  title: "Collective Communication Enabled Transformer Acceleration on Heterogeneous Clusters"
  year: 2023
  type: article
  doi: https://hdl.handle.net/1807/130585
  url: https://hdl.handle.net/1807/130585
  pdf: https://tspace.library.utoronto.ca/bitstream/1807/130585/3/Gao_Yu_202311_MAS_thesis.pdf
  ignore: False
  silicon: True
  platform: __no_data__
  model: ['BERT']
  method: __no_data__
  publisher: TSpace
  pubkey: "T"
  pubname: "IEEE Transactions on Artificial Intelligence "
  reserved: DEADBEEF

295:
  title: "FET-OPU: A Flexible and Efficient FPGA-Based Overlay Processor for Transformer Networks"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/ICCAD57390.2023.10323752
  url: https://doi.org/10.1109/ICCAD57390.2023.10323752
  pdf: False
  ignore: False
  silicon: True
  platform: FPGA
  model: ['BERT']
  method: __no_data__
  publisher: IEEE
  pubkey: "ICCAD"
  pubname: "IEEE/ACM International Conference on Computer Aided Design (ICCAD)"
  reserved: DEADBEEF

296:
  title: "Racism and Hate Speech Detection on Twitter: A QAHA-Based Hybrid Deep Learning Approach Using LSTM-CNN"
  year: 2023
  type: article
  doi: https://doi.org/10.56578/ijkis010202
  url: https://doi.org/10.56578/ijkis010202
  pdf: https://library.acadlore.com/IJKIS/2023/1/2/IJKIS_01.02_02.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['BERT']
  method: __no_data__
  publisher: ACADLore
  pubkey: ""
  pubname: "International Journal of Knowledge and Innovation Studies"
  reserved: DEADBEEF


297:
  title: "22.9 A 12nm 18.1TFLOPs/W Sparse Transformer Processor with Entropy-Based Early Exit, Mixed-Precision Predication and Fine-Grained Power Management"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/ISSCC42615.2023.10067817
  url: https://doi.org/10.1109/ISSCC42615.2023.10067817
  pdf: no
  ignore: True
  silicon: True
  platform:  asic
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: IEEE
  pubkey: "ISSCC"
  pubname: "IEEE International Solid-State Circuits Conference"
  reserved: DEADBEEF

298:
  title: "P^3 ViT: A CIM-Based High-Utilization Architecture With Dynamic Pruning and Two-Way Ping-Pong Macro for Vision Transformer"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/TCSI.2023.3315060
  url: https://doi.org/10.1109/TCSI.2023.3315060
  pdf: no
  ignore: True
  silicon: True
  platform:  FPGA
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: IEEE
  pubkey: "TCSI"
  pubname: "IEEE Transactions on Circuits and Systems"
  reserved: DEADBEEF

299:
  title: "I-ViT: Integer-only Quantization for Efficient Vision Transformer Inference"
  year: 2023
  type: article
  doi: https://arxiv.org/abs/2207.01405
  url: https://arxiv.org/abs/2207.01405
  pdf: https://arxiv.org/pdf/2207.01405
  ignore: True
  silicon: True
  platform:  algoritm
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: IEEE/CVF
  pubkey: "TCSI"
  pubname: "IEEE/CVF International Conference on Computer Vision"
  reserved: DEADBEEF

300:
  title: "Enabling efficient edge intelligence: a hardware-software codesign approach"
  year: 2023
  type: thesis
  doi: https://dr.ntu.edu.sg/handle/10356/172499
  url: https://dr.ntu.edu.sg/handle/10356/172499
  pdf: https://dr.ntu.edu.sg/bitstream/10356/172499/2/Thesis_Final_HUAISHUO.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: ["in-memory-processing", "pruning"]
  publisher: "NanyangTechnologicalUniversity"
  pubkey: ""
  pubname: "Nanyang Technological University"
  reserved: DEADBEEF

301:
  title: "Automatic Kernel Generation for Large Language Models on Deep Learning Accelerators"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/ICCAD57390.2023.10323944
  url: https://doi.org/10.1109/ICCAD57390.2023.10323944
  pdf: False
  ignore: False
  silicon: True
  platform: FPGA
  model: ['']
  method: __no_data__
  publisher: IEEE
  pubkey: "ICCAD"
  pubname: "IEEE/ACM International Conference on Computer Aided Design (ICCAD)"
  reserved: DEADBEEF

302:
  title: "A Low-Latency and Lightweight FPGA-Based Engine for Softmax and Layer Normalization Acceleration"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/ICCE--Asia59966.2023.10326397
  url: https://doi.org/10.1109/ICCE-Asia59966.2023.10326397
  pdf: False
  ignore: False
  silicon: True
  platform: FPGA
  model: ['']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia)"
  reserved: DEADBEEF

303:
  title: "PP-Transformer: Enable Efficient Deployment of Transformers Through Pattern Pruning"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/ICCAD57390.2023.10323836
  url: https://doi.org/10.1109/ICCAD57390.2023.10323836
  pdf: False
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: IEEE
  pubkey: "ICCAD"
  pubname: "IEEE/ACM International Conference on Computer Aided Design (ICCAD)"
  reserved: DEADBEEF

304:
  title: "DEAP: Design Space Exploration for DNN Accelerator Parallelism"
  year: 2023
  type: arx
  doi: https://arxiv.org/abs/2312.15388
  url: https://arxiv.org/abs/2312.15388
  pdf: https://arxiv.org/pdf/2312.15388.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxive
  pubkey: ""
  pubname: "Computer Science > Distributed, Parallel, and Cluster Computing"
  reserved: DEADBEEF

305:
  title: "Understanding the Potential of FPGA-Based Spatial Acceleration for Large Language Model Inference"
  year: 2023
  type: arx
  doi: https://arxiv.org/abs/2312.15159
  url: https://arxiv.org/abs/2312.15159
  pdf: https://arxiv.org/pdf/2312.15159.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer', 'LLM']
  method: __no_data__
  publisher: Arxive
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF


306:
  title: "An RRAM-Based Computing-in-Memory Architecture and Its Application in Accelerating Transformer Inference"
  year: 2023
  type: article
  doi: https://doi.ieeecomputersociety.org/10.1109/TVLSI.2023.3345651
  url: https://doi.ieeecomputersociety.org/10.1109/TVLSI.2023.3345651
  pdf: False
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: IEEE
  pubkey: "TVLSI"
  pubname: "IEEE Transactions on Very Large Scale Integration (VLSI) Systems"
  reserved: DEADBEEF

307:
  title: "Mobile Transformer Accelerator Exploiting Various Line Sparsity and Tile-Based Dynamic Quantization"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/TCAD.2023.3347291
  url: https://doi.org/10.1109/TCAD.2023.3347291
  pdf: False
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: IEEE
  pubkey: "TCAD"
  pubname: "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems"
  reserved: DEADBEEF

308:
  title: "A Lightweight Transformer Model using Neural ODE for FPGAs"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/IPDPSW59300.2023.00029
  url: https://doi.org/10.1109/IPDPSW59300.2023.00029
  pdf: False
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer', ]
  method: __no_data__
  publisher: IEEE
  pubkey: "IPDPSW"
  pubname: "IEEE International Parallel and Distributed Processing Symposium Workshops"
  reserved: DEADBEEF

309:
  title: "A Cost-Efficient FPGA Implementation of Tiny Transformer Model using Neural ODE"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2401.02721
  url: https://arxiv.org/abs/2401.02721
  pdf: https://arxiv.org/pdf/2401.02721.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxive
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

310:
  title: "FlightLLM: Efficient Large Language Model Inference with a Complete Mapping Flow on FPGAs"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2401.03868
  url: https://arxiv.org/abs/2401.03868
  pdf: https://arxiv.org/pdf/2401.03868.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxive
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

311:
  title: "Accelerating Neural Networks for Large Language Models and Graph Processing with Silicon Photonics"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2401.06885
  url: https://arxiv.org/abs/2401.06885
  pdf: https://arxiv.org/pdf/2401.06885.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer', 'LLM']
  method: __no_data__
  publisher: Arxive
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

312:
  title: "Quantization and Hardware Architecture Co-Design for Matrix-Vector Multiplications of Large Language Models"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/TCSI.2024.3350661
  url: https://doi.org/10.1109/TCSI.2024.3350661
  pdf: False
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer', 'LLM']
  method: __no_data__
  publisher: IEEE
  pubkey: "TCSI"
  pubname: "IEEE Transactions on Circuits and Systems I: Regular Papers"
  reserved: DEADBEEF

313:
  title: "RDCIM: RISC-V Supported Full-Digital Computing-in-Memory Processor With High Energy Efficiency and Low Area Overhead"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/TCSI.2024.3350664
  url: https://doi.org/10.1109/TCSI.2024.3350664
  pdf: False
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer', 'RISC-V', 'PIM', 'Memory']
  method: __no_data__
  publisher: IEEE
  pubkey: "TCSI"
  pubname: "IEEE Transactions on Circuits and Systems I: Regular Papers"
  reserved: DEADBEEF

314:
  title: "A Survey on Hardware Accelerators for Large Language Models"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2401.09890
  url: https://arxiv.org/abs/2401.09890
  pdf: https://arxiv.org/pdf/2401.09890.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxive
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

315:
  title: "BETA: Binarized Energy-Efficient Transformer Accelerator at the Edge"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2401.11851
  url: https://arxiv.org/abs/2401.11851
  pdf: https://arxiv.org/abs/2401.11851.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxive
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

316:
  title: "AttentionLego: An Open-Source Building Block For Spatially-Scalable Large Language Model Accelerator With Processing-In-Memory Technology"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2401.11459
  url: https://arxiv.org/abs/2401.11459
  pdf: https://arxiv.org/abs/2401.11459.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxive
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

317:
  title: "SSR: Spatial Sequential Hybrid Architecture for Latency Throughput Tradeoff in Transformer Acceleration"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2401.10417
  url: https://arxiv.org/abs/2401.10417
  pdf: https://arxiv.org/abs/2401.10417.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxive
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

318:
  title: "CIM-MLC: A Multi-level Compilation Stack for Computing-In-Memory Accelerators"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2401.12428
  url: https://arxiv.org/abs/2401.12428
  pdf: https://arxiv.org/pdf/2401.12428.pdf
  ignore: False
  silicon: True
  platform: PIM
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF


319:
  title: "CIM-MLC: A Multi-level Compilation Stack for Computing-In-Memory Accelerators"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2401.12428
  url: https://arxiv.org/abs/2401.12428
  pdf: https://arxiv.org/pdf/2401.12428.pdf
  ignore: False
  silicon: True
  platform: PIM
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

320:
  title: "The Era of Generative Artificial Intelligence: In-Memory Computing Perspective"
  year: 2024
  type: review
  doi: https://doi.org/10.1109/IEDM45741.2023.10413786
  url: https://doi.org/10.1109/IEDM45741.2023.10413786
  pdf: no
  ignore: False
  silicon: True
  platform: PIM
  model: ['Transformer']
  method: __no_data__
  publisher: IEEE
  pubkey: "IEDM"
  pubname: "International Electron Devices Meeting (IEDM)"
  reserved: DEADBEEF

321:
  title: "Hydragen: High-Throughput LLM Inference with Shared Prefixes"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2402.05099
  url: https://arxiv.org/abs/2402.05099
  pdf: https://arxiv.org/pdf/2402.05099.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

322:
  title: "A Survey on Transformer Compression"
  year: 2024
  type: survey
  doi: https://arxiv.org/abs/2402.05964.pdf
  url: https://arxiv.org/abs/2402.05964.pdf
  pdf: https://arxiv.org/pdf/2402.05964.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF


323:
  title: "SLEB: Streamlining LLMs through Redundancy Verification and Elimination of Transformer Blocks"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2402.09025
  url: https://arxiv.org/abs/2402.09025
  pdf: https://arxiv.org/pdf/2402.09025.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: ""
  reserved: DEADBEEF

324:
  title: "Stochastic Spiking Attention: Accelerating Attention with Stochastic Computing in Spiking Networks"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2402.09109
  url: https://arxiv.org/abs/2402.09109
  pdf: https://arxiv.org/pdf/2402.09109.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

325:
  title: "Reusing Softmax Hardware Unit for GELU Computation in Transformers"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2402.10118
  url: https://arxiv.org/abs/2402.10118
  pdf: https://arxiv.org/abs/2402.10118.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

326:
  title: "ConSmax: Hardware-Friendly Alternative Softmax with Learnable Parameters"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2402.10930
  url: https://arxiv.org/abs/2402.10930
  pdf: https://arxiv.org/pdf/2402.10930.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

327:
  title: "Speculative Streaming: Fast LLM Inference without Auxiliary Models"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2402.11131
  url: https://arxiv.org/abs/2402.11131
  pdf: https://arxiv.org/pdf/2402.11131.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF


328:
  title: "H3D-Transformer: A Heterogeneous 3D (H3D) Computing Platform for Transformer Model Acceleration on Edge Devices"
  year: 2024
  type: article
  doi: https://dl.acm.org/doi/10.1145/3649219
  url: https://dl.acm.org/doi/10.1145/3649219
  pdf: https://dl.acm.org/doi/pdf/10.1145/3649219
  ignore: False
  silicon: True
  platform: 3D
  model: ['Transformer']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "ACM Transactions on Design Automation of Electronic Systems"
  reserved: DEADBEEF

329:
  title: "NeuPIMs: NPU-PIM Heterogeneous Acceleration for Batched LLM Inferencing"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2403.00579
  url: https://arxiv.org/abs/2403.00579
  pdf: https://arxiv.org/pdf/2403.00579.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF


330:
  title: "Cerberus: Triple Mode Acceleration of Sparse Matrix and Vector Multiplication"
  year: 2024
  type: article
  doi: https://doi.org/10.1145/3653020
  url: https://doi.org/10.1145/365302000579
  pdf: https://dl.acm.org/doi/pdf/10.1145/3653020
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "Transactions on Architecture and Code Optimization"
  reserved: DEADBEEF

331:
  title: "DEFA: Efficient Deformable Attention Acceleration via Pruning-Assisted Grid-Sampling and Multi-Scale Parallel Processing"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2403.10913
  url: https://arxiv.org/abs/2403.10913
  pdf: https://arxiv.org/pdf/2403.10913.pdf
  ignore: False
  silicon: True
  platform: GPU
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF


332:
  title: "FastDecode: High-Throughput GPU-Efficient LLM Serving using Heterogeneous Pipelines"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2403.11421
  url: https://arxiv.org/abs/2403.11421
  pdf: https://arxiv.org/pdf/2403.11421.pdf
  ignore: False
  silicon: True
  platform: GPU
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Distributed, Parallel, and Cluster Computing"
  reserved: DEADBEEF


333:
  title: "Accelerating ViT Inference on FPGA through Static and Dynamic Pruning"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2403.14047
  url: https://arxiv.org/abs/2403.14047
  pdf: https://arxiv.org/pdf/2403.14047.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Distributed, Parallel, and Cluster Computing"
  reserved: DEADBEEF

334:
  title: "Allspark: Workload Orchestration for Visual Transformers on Processing In-Memory Systems"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2403.15069
  url: https://arxiv.org/abs/2403.15069
  pdf: https://arxiv.org/pdf/2403.15069.pdf
  ignore: False
  silicon: True
  platform: PIM
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF


335:
  title: "Impact of High-Level-Synthesis on Reliability of Artificial Neural Network Hardware Accelerators"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/TNS.2024.3377596
  url: https://doi.org/10.1109/TNS.2024.3377596
  pdf: https://inria.hal.science/hal-04514579/file/TNS2024_HLS.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: IEEE
  pubkey: ""
  pubname: "IEEE Transactions on Nuclear Science"
  reserved: DEADBEEF

336:
  title: "An FPGA-Based Reconfigurable Accelerator for Convolution-Transformer Hybrid EfficientViT"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2403.20230
  url: https://arxiv.org/abs/2403.20230
  pdf: https://arxiv.org/pdf/2403.20230.pdf
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF



337:
  title: "TransFRU: Efficient Deployment of Transformers on FPGA with Full Resource Utilization"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/ASP--DAC58780.2024.10473976
  url: https://doi.org/10.1109/ASP-DAC58780.2024.10473976
  pdf: False
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: IEEE
  pubkey: "ASP-DAC"
  pubname: "Asia and South Pacific Design Automation Conference (ASP-DAC)"
  reserved: DEADBEEF

338:
  title: "PRIMATE: Processing in Memory Acceleration for Dynamic Token-pruning Transformers"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/ASP--DAC58780.2024.10473968
  url: https://doi.org/10.1109/ASP-DAC58780.2024.10473968
  pdf: False
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: IEEE
  pubkey: "ASP-DAC"
  pubname: "Asia and South Pacific Design Automation Conference (ASP-DAC)"
  reserved: DEADBEEF

339:
  title: "SWAT: An Efficient Swin Transformer Accelerator Based on FPGA"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/ASP--DAC58780.2024.10473931
  url: https://doi.org/10.1109/ASP-DAC58780.2024.10473931
  pdf: False
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: IEEE
  pubkey: "ASP-DAC"
  pubname: "Asia and South Pacific Design Automation Conference (ASP-DAC)"
  reserved: DEADBEEF

340:
  title: "VTR: An Optimized Vision Transformer for SAR ATR Acceleration on FPGA"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2404.04527v1
  url: https://arxiv.org/abs/2404.04527v1
  pdf: https://arxiv.org/pdf/2404.04527v1
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computer Vision and Pattern Recognition"
  reserved: DEADBEEF

341:
  title: "Workload-Aware Hardware Accelerator Mining for Distributed Deep Learning Training"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2404.14632v1
  url: https://arxiv.org/abs/2404.14632v1
  pdf: https://arxiv.org/pdf/2404.14632v1
  ignore: False
  silicon: True
  platform: FPGA
  model: ['Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

342:
  title: "QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2405.04532
  url: https://arxiv.org/abs/2405.04532
  pdf: https://arxiv.org/pdf/2405.04532
  ignore: True
  silicon: True
  platform:  framework|algorithm
  model: ['LLm', 'EDA']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computation and Language"
  reserved: DEADBEEF

343:
  title: "NeuPIMs: NPU-PIM Heterogeneous Acceleration for Batched LLM Inferencing"
  year: 2024
  type: article
  doi: https://dl.acm.org/doi/abs/10.1145/3620666.3651380
  url: https://dl.acm.org/doi/abs/10.1145/3620666.3651380
  pdf: https://dl.acm.org/doi/pdf/10.1145/3620666.3651380
  ignore: False
  silicon: True
  platform: PIM
  model: ['Transformer']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "International Conference on Architectural Support for Programming Languages and Operating Systems"
  reserved: DEADBEEF

344:
  title: "VITA: ViT Acceleration for Efficient 3D Human Mesh Recovery via Hardware-Algorithm Co-Design"
  year: 2024
  type: article
  doi: no
  url: no
  pdf: https://www.crcv.ucf.edu/chenchen/2024_DAC_VITA_Final.pdf
  ignore: True
  silicon: True
  platform: PIMGPU
  model: ['Transformer']
  method: __no_data__
  publisher: ACM
  pubkey: ""
  pubname: "International Conference on Architectural Support for Programming Languages and Operating Systems"
  reserved: DEADBEEF

345:
  title: "HLSTransform: Energy-Efficient Llama 2 Inference on FPGAs Via High Level Synthesis"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2405.00738
  url: https://arxiv.org/abs/2405.00738
  pdf: https://arxiv.org/pdf/2405.00738
  ignore: True
  silicon: True
  platform: FPGA
  model: ['Transformer', 'LLM']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

346:
  title: "SCAR: Scheduling Multi-Model AI Workloads on Heterogeneous Multi-Chiplet Module Accelerators"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2405.00790
  url: https://arxiv.org/abs/2405.00790
  pdf: https://arxiv.org/pdf/2405.00790
  ignore: True
  silicon: True
  platform: ACC
  model: ['AI']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

347:
  title: "Trio-ViT: Post-Training Quantization and Acceleration for Softmax-Free Efficient Vision Transformer"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2405.03882
  url: https://arxiv.org/abs/2405.03882
  pdf: https://arxiv.org/pdf/2405.03882
  ignore: True
  silicon: True
  platform: ACC
  model: ['VIT', 'Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computer Vision and Pattern Recognition"
  reserved: DEADBEEF

348:
  title: "SambaNova SN40L: Scaling the AI Memory Wall with Dataflow and Composition of Experts"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2405.07518
  url: https://arxiv.org/abs/2405.07518
  pdf: https://arxiv.org/pdf/2405.07518
  ignore: True
  silicon: True
  platform:  Memory
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

349:
  title: "TensorMap: A Deep RL-Based Tensor Mapping Framework for Spatial Accelerators"
  year: 2024
  type: article
  doi: https://doi.ieeecomputersociety.org/10.1109/TC.2024.3398424
  url: https://doi.ieeecomputersociety.org/10.1109/TC.2024.3398424
  pdf: no
  ignore: True
  silicon: True
  platform:  EDA
  model: ['LLm', 'EDA']
  method: __no_data__
  publisher: IEEE
  pubkey: "IEEE Transactions on Computers"
  pubname: "TC"
  reserved: DEADBEEF

350:
  title: "JIT-Q: Just-in-time Quantization with Processing-In-Memory for Efficient ML Training"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2311.05034
  url: https://arxiv.org/abs/2311.05034
  pdf: https://proceedings.mlsys.org/paper_files/paper/2024/file/136b9a13861308c8948cd308ccd02658-Paper-Conference.pdf
  ignore: True
  silicon: True
  platform:  EDA
  model: ['LLm', 'EDA']
  method: __no_data__
  publisher: MLSys
  pubkey: "Proceedings of Machine Learning and Systems 6 (MLSys 2024)"
  pubname: "Proceedings of Machine Learning and Systems 6 (MLSys 2024)"
  reserved: DEADBEEF

351:
  title: "DCT-ViT: High-Frequency Pruned Vision Transformer with Discrete Cosine Transform"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/ACCESS.2024.3410231
  url: https://doi.org/10.1109/ACCESS.2024.3410231
  pdf: https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10549904
  ignore: True
  silicon: True
  platform: algorithm
  model: ['LLm', 'ViT']
  method: __no_data__
  publisher: IEEE
  pubkey: "Access"
  pubname: "IEEE Access"
  reserved: DEADBEEF

352:
  title: "TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings"
  year: 2023
  type: article
  doi: https://doi.org/10.1145/3579371.3589350
  url: https://doi.org/10.1145/3579371.3589350
  pdf: https://dl.acm.org/doi/pdf/10.1145/3579371.3589350
  ignore: True
  silicon: True
  platform: TPU
  model: ['LLM']
  method: __no_data__
  publisher: ACM
  pubkey: "ISCA"
  pubname: "ACM International Symposium on Computer Architecture"
  reserved: DEADBEEF

353:
  title: "TransAxx: Efficient Transformers with Approximate Computing"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2402.07545
  url: https://arxiv.org/abs/2402.07545
  pdf: https://arxiv.org/pdf/2402.07545
  ignore: True
  silicon: True
  platform:  framework
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

354:
  title: "FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU"
  year: 2023
  type: article
  doi: https://proceedings.mlr.press/v202/sheng23a
  url: https://proceedings.mlr.press/v202/sheng23a
  pdf: https://proceedings.mlr.press/v202/sheng23a/sheng23a.pdf
  ignore: True
  silicon: True
  platform:  platform
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: PMLR
  pubkey: "PMLR"
  pubname: "Proceedings of Machine Learning Research"
  reserved: DEADBEEF

355:
  title: "ITA: An Energy-Efficient Attention and Softmax Accelerator for Quantized Transformers"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2307.03493
  url: https://arxiv.org/abs/2307.03493
  pdf: https://arxiv.org/pdf/2307.03493
  ignore: True
  silicon: True
  platform:  ASIC
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

356:
  title: "ITA: An Energy-Efficient Attention and Softmax Accelerator for Quantized Transformers"
  year: 2023
  type: article
  doi: https://arxiv.org/abs/2307.03493
  url: https://arxiv.org/abs/2307.03493
  pdf: https://arxiv.org/pdf/2307.03493
  ignore: True
  silicon: True
  platform:  ASIC
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

357:
  title: "X-Former: In-Memory Acceleration of Transformers"
  year: 2023
  type: article
  doi: https://arxiv.org/abs/2303.07470
  url: https://arxiv.org/abs/2303.07470
  pdf: https://arxiv.org/pdf/2303.07470
  ignore: True
  silicon: True
  platform:  PIM
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

358:
  title: "GPT4AIGChip: Towards Next-Generation AI Accelerator Design Automation via Large Language Models"
  year: 2023
  type: article
  doi: https://arxiv.org/abs/2309.10730
  url: https://arxiv.org/abs/2309.10730
  pdf: https://arxiv.org/pdf/2309.10730
  ignore: True
  silicon: True
  platform:  framework
  model: ['LLm', 'EDA']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

359:
  title: "HeatViT: Hardware-Efficient Adaptive Token Pruning for Vision Transformers"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/HPCA56546.2023.10071047
  url: https://doi.org/10.1109/HPCA56546.2023.10071047
  pdf: https://arxiv.org/pdf/2211.08110
  ignore: True
  silicon: True
  platform:  framework
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: IEEE
  pubkey: "HPCA"
  pubname: "International Symposium on High-Performance Computer Architecture"
  reserved: DEADBEEF

360:
  title: "ViTCoD: Vision Transformer Acceleration via Dedicated Algorithm and Accelerator Co-Design"
  year: 2023
  type: article
  doi: https://arxiv.org/abs/2210.09573
  url: https://arxiv.org/abs/2210.09573
  pdf: https://arxiv.org/pdf/2210.09573
  ignore: True
  silicon: True
  platform:  framework
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: IEEE
  pubkey: "HPCA"
  pubname: "International Symposium on High-Performance Computer Architecture"
  reserved: DEADBEEF

361:
  title: "AccelTran: A Sparsity-Aware Accelerator for Dynamic Inference with Transformers"
  year: 2023
  type: article
  doi: https://doi.org/10.1109/TCAD.2023.3273992
  url: https://doi.org/10.1109/TCAD.2023.3273992
  pdf: https://arxiv.org/pdf/2302.14705
  ignore: True
  silicon: True
  platform:  platform
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: IEEE
  pubkey: "TCAD"
  pubname: "Transaction on Computer Aided Design"
  reserved: DEADBEEF


362:
  title: "CGRA4ML: A Framework to Implement Modern Neural Networks for Scientific Edge Computing"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2408.15561
  url: https://arxiv.org/abs/2408.15561
  pdf: https://arxiv.org/pdf/2408.15561
  ignore: False
  silicon: True
  platform: Design
  model: ['VIT', 'Transformer']
  method: __no_data__
  publisher: "Arxiv"
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

363:
  title: "ProTEA: Programmable Transformer Encoder Acceleration on FPGA"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2409.13975
  url: https://arxiv.org/abs/2409.13975
  pdf: https://arxiv.org/pdf/2409.13975
  ignore: False
  silicon: True
  platform: Design
  model: ['FPGA', 'Transformer']
  method: __no_data__
  publisher: "Arxiv"
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF


364:
  title: "CAT: Customized Transformer Accelerator Framework on Versal ACAP"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2409.09689
  url: https://arxiv.org/abs/2409.09689
  pdf: https://arxiv.org/pdf/2409.09689
  ignore: False
  silicon: True
  platform: Design
  model: ['FPGA', 'Transformer']
  method: __no_data__
  publisher: "Arxiv"
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

365:
  title: "Co-design of a TinyLLM using Programmable Logic and Software on an FPGA"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/MWSCAS60917.2024.10658754
  url: https://doi.org/10.1109/MWSCAS60917.2024.10658754
  pdf: no
  ignore: False
  silicon: True
  platform: Design
  model: ['FPGA', 'LLM']
  method: __no_data__
  publisher: "IEEE"
  pubkey: ""
  pubname: " International Midwest Symposium on Circuits and Systems (MWSCAS)"
  reserved: DEADBEEF


366:
  title: "BitShare: An Efficient Precision-Scalable Accelerator with Combining-Like-Terms GEMM"
  year: 2024
  type: article
  doi: RESEARCH_GATE
  url: https://www.researchgate.net/publication/381370829_BitShare_An_Efficient_Precision-Scalable_Accelerator_with_Combining-Like-Terms_GEMM
  pdf: https://www.researchgate.net/profile/Junzhong-Shen/publication/381370829_BitShare_An_Efficient_Precision-Scalable_Accelerator_with_Combining-Like-Terms_GEMM/links/666a46cba54c5f0b94613261/BitShare-An-Efficient-Precision-Scalable-Accelerator-with-Combining-Like-Terms-GEMM.pdf
  ignore: True
  silicon: True
  platform:  Accelerator
  model: ['GEMM', 'Transformer']
  method: __no_data__
  publisher: IEEE
  pubkey: "ASAP"
  pubname: "IEEE Conference Application-Specific Systems, Architectures, and Processors"
  reserved: DEADBEEF

367:
  title: "Streaming Tensor Programs: A Programming Abstraction for Streaming Dataflow Accelerators"
  year: 2023
  type: article
  doi: NO_DATA
  url: false
  pdf: https://cgyurgyik.github.io/files/pubs/step-yarch.pdf
  ignore: True
  silicon: True
  platform:  algoritm
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: "?"
  pubkey: "?"
  pubname: "?"
  reserved: DEADBEEF

368:
  title: "SDA: Low-Bit Stable Diffusion Acceleration on Edge FPGA"
  year: 2024
  type: article
  doi: NO_DATA
  url: https://github.com/Michaela1224/SDA_code
  pdf: https://www.sfu.ca/~zhenman/files/C41-FPL2024-SDA.pdf
  ignore: True
  silicon: True
  platform:  algoritm
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: "IEEE"
  pubkey: "?"
  pubname: "?"
  reserved: DEADBEEF

369:
  title: "Hardware Accelerator for MobileViT Vision Transformer with Reconfigurable Computation"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/ISCAS58744.2024.10558190
  url: https://doi.org/10.1109/ISCAS58744.2024.10558190
  pdf: false
  ignore: True
  silicon: True
  platform:  algoritm
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: "IEEE"
  pubkey: "ISCAS"
  pubname: "IEEE International Symposium on Circuits and Systems"
  reserved: DEADBEEF

370:
  title: "In-Memory Transformer Self-Attention Mechanism Using Passive Memristor Crossbar"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/ISCAS58744.2024.10558182
  url: https://doi.org/10.1109/ISCAS58744.2024.10558182
  pdf: false
  ignore: False
  silicon: True
  platform:  algoritm
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: "IEEE"
  pubkey: "ISCAS"
  pubname: "IEEE International Symposium on Circuits and Systems"
  reserved: DEADBEEF

371:
  title: "A 3.55 mJ/frame Energy-efficient Mixed-Transformer based Semantic Segmentation Accelerator for Mobile Devices"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/ISCAS58744.2024.10558649
  url: https://doi.org/10.1109/ISCAS58744.2024.10558649
  pdf: false
  ignore: False
  silicon: True
  platform:  algoritm
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: "IEEE"
  pubkey: "ISCAS"
  pubname: "IEEE International Symposium on Circuits and Systems"
  reserved: DEADBEEF

372:
  title: "FLAG: Formula-LLM-Based Auto-Generator for Baseband Hardware"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/ISCAS58744.2024.10558482
  url: https://doi.org/10.1109/ISCAS58744.2024.10558482
  pdf: false
  ignore: False
  silicon: True
  platform:  platform
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: "IEEE"
  pubkey: "ISCAS"
  pubname: "IEEE International Symposium on Circuits and Systems"
  reserved: DEADBEEF

373:
  title: "CV-CIM: A Hybrid Domain Xor-Derived Similarity-Aware Computation-in-Memory Supporting Cost–Volume Construction"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/JSSC.2024.3421589
  url: https://doi.org/10.1109/JSSC.2024.3421589
  pdf: false
  ignore: False
  silicon: True
  platform:  platform
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: "IEEE"
  pubkey: "ISCAS"
  pubname: "IEEE Journal of Solid-State Circuits"
  reserved: DEADBEEF

374:
  title: "LPU: A Latency-Optimized and Highly Scalable Processor for Large Language Model Inference"
  year: 2024
  type: article
  doi: https://www.usenix.org/conference/osdi24/presentation/zhuang
  url: https://www.usenix.org/conference/osdi24/presentation/zhuang
  pdf: https://www.usenix.org/system/files/osdi24-zhuang.pdf
  ignore: False
  silicon: True
  platform:  platform
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: "USENIX"
  pubkey: "UOSDI"
  pubname: "USENIX Symposium on Operating Systems Design and Implementation"
  reserved: DEADBEEF

375:
  title: "ARTEMIS: A Mixed Analog-Stochastic In-DRAM Accelerator for Transformer Neural Networks"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2407.12638
  url: https://arxiv.org/abs/2407.12638
  pdf: https://arxiv.org/pdf/2407.12638
  ignore: False
  silicon: True
  platform:  AMS
  model: ['Analog', 'Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF


376:
  title: "CHOSEN: Compilation to Hardware Optimization Stack for Efficient Vision Transformer Inference"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2407.12736
  url: https://arxiv.org/abs/2407.12736
  pdf: https://arxiv.org/pdf/2407.12736
  ignore: False
  silicon: True
  platform:  platform
  model: ['Codesign', 'Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Computer Vision and Pattern Recognition"
  reserved: DEADBEEF

377:
  title: "Co-Designing Binarized Transformer and Hardware Accelerator for Efficient End-to-End Edge Deployment"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2407.12070
  url: https://arxiv.org/abs/2407.12070
  pdf: https://arxiv.org/pdf/2407.12070
  ignore: False
  silicon: True
  platform:  platform
  model: ['', 'Transformer']
  method: __no_data__
  publisher: Arxiv
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF


378:
  title: "SPSA: Exploring Sparse-Packing Computation on Systolic Arrays From Scratch"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/TCAD.2024.3434359
  url: https://doi.org/10.1109/TCAD.2024.3434359
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['DSA', 'LLm', 'Transformer']
  method: __no_data__
  publisher: "IEEE"
  pubkey: "TCAD"
  pubname: "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems ("
  reserved: DEADBEEF

379:
  title: "SPSA: Exploring Sparse-Packing Computation on Systolic Arrays From Scratch"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/TCAD.2024.3434447
  url: https://doi.org/10.1109/TCAD.2024.3434447
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['DSA', 'LLm', 'Transformer']
  method: __no_data__
  publisher: "IEEE"
  pubkey: "TCAD"
  pubname: "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems ("
  reserved: DEADBEEF

380:
  title: "MECLA: Memory-Compute-Efficient LLM Accelerator with Scaling Sub-matrix Partition"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/ISCA59077.2024.00079
  url: https://doi.org/10.1109/ISCA59077.2024.00079
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['DSA', 'LLm', 'Transformer']
  method: __no_data__
  publisher: "IEEE"
  pubkey: "ISCA"
  pubname: "ACM/IEEE 51st Annual International Symposium on Computer Architecture"
  reserved: DEADBEEF

381:
  title: "TCP: A Tensor Contraction Processor for AI Workloads Industrial Product"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/ISCA59077.2024.00069
  url: https://doi.org/10.1109/ISCA59077.2024.00069
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['DSA', 'LLm', 'Transformer']
  method: __no_data__
  publisher: "IEEE"
  pubkey: "ISCA"
  pubname: "ACM/IEEE 51st Annual International Symposium on Computer Architecture"
  reserved: DEADBEEF

382:
  title: "A 109-GOPs/W FPGA-based Vision Transformer Accelerator with Weight-Loop Dataflow Featuring Data Reusing and Resource Saving"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/TCSVT.2024.3439600
  url: https://doi.org/10.1109/TCSVT.2024.3439600
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['VIT', 'Transformer']
  method: __no_data__
  publisher: "IEEE"
  pubkey: ""
  pubname: "IEEE Transactions on Circuits and Systems for Video Technology ( Early Access )"
  reserved: DEADBEEF


383:
  title: "Klotski v2: Improved DNN Model Orchestration Framework for Dataflow Architecture Accelerators"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/TCAD.2024.3446858
  url: https://doi.org/10.1109/TCAD.2024.3446858
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['VIT', 'Transformer']
  method: __no_data__
  publisher: "IEEE"
  pubkey: ""
  pubname: "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems"
  reserved: DEADBEEF

384:
  title: "Quartet: A Holistic Hybrid Parallel Framework for Training Large Language Models"
  year: 2024
  type: article
  doi: https://doi.org/10.1007/978--3--031--69766--1_29
  url: https://doi.org/10.1007/978-3-031-69766-1_29
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['VIT', 'Transformer']
  method: __no_data__
  publisher: "Springer"
  pubkey: ""
  pubname: "European Conference on Parallel and Distributed Processing"
  reserved: DEADBEEF

385:
  title: "Inference with Transformer Encoders on ARM and RISC-V Multicore Processors"
  year: 2024
  type: article
  doi: https://doi.org/10.1007/978--3--031--69766--1_26
  url: https://doi.org/10.1007/978-3-031-69766-1_26
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['VIT', 'Transformer']
  method: __no_data__
  publisher: "Springer"
  pubkey: ""
  pubname: "European Conference on Parallel and Distributed Processing"
  reserved: DEADBEEF

386:
  title: "Mentor: A Memory-Eficient Sparse-dense Matrix Multiplication Accelerator Based on Column-Wise Product"
  year: 2024
  type: article
  doi: https://dl.acm.org/doi/pdf/10.1145/3688612
  url: https://dl.acm.org/doi/pdf/10.1145/3688612
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['VIT', 'Transformer']
  method: __no_data__
  publisher: "ACM"
  pubkey: ""
  pubname: "ACM Transactions on Architecture and Code Optimization"
  reserved: DEADBEEF

387:
  title: "Cost-Effective LLM Accelerator Using Processing in Memory Technology"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/VLSITechnologyandCir46783.2024.10631397
  url: https://doi.org/10.1109/VLSITechnologyandCir46783.2024.10631397
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['VIT', 'Transformer']
  method: __no_data__
  publisher: "IEEE"
  pubkey: ""
  pubname: "IEEE Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits)"
  reserved: DEADBEEF

388:
  title: "A 28nm 4.35TOPS/mm2 Transformer Accelerator with Basis-vector Based Ultra Storage Compression, Decomposed Computation and Unified LUT-Assisted Cores"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/VLSITechnologyandCir46783.2024.10631311
  url: https://doi.org/10.1109/VLSITechnologyandCir46783.2024.10631311
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['VIT', 'Transformer']
  method: __no_data__
  publisher: "IEEE"
  pubkey: ""
  pubname: "IEEE Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits)"
  reserved: DEADBEEF


389:
  title: "FPGA-Based Sparse Matrix Multiplication Accelerators: From State-of-the-art to Future Opportunities"
  year: 2024
  type: article
  doi: https://doi.org/10.1145/3687480
  url: https://doi.org/10.1145/3687480
  pdf: https://dl.acm.org/doi/pdf/10.1145/3687480
  ignore: False
  silicon: True
  platform: Design
  model: ['VIT', 'Transformer']
  method: __no_data__
  publisher: "ACM"
  pubkey: ""
  pubname: "ACM Transactions on Reconfigurable Technology and Systems"
  reserved: DEADBEEF


390:
  title: "LPU: A Latency-Optimized and Highly Scalable Processor for Large Language Model Inference"
  year: 2024
  type: article
  doi: https://doi.ieeecomputersociety.org/10.1109/MM.2024.3420728
  url: https://doi.ieeecomputersociety.org/10.1109/MM.2024.3420728
  pdf: false
  ignore: False
  silicon: True
  platform:  platform
  model: ['LLm', 'Transformer']
  method: __no_data__
  publisher: "IEEE"
  pubkey: "ISCAS"
  pubname: "IEEE Journal of Solid-State Circuits"
  reserved: DEADBEEF

391:
  title: "Efficient Transformer Acceleration via Reconfiguration for Encoder and Decoder Models and Sparsity-Aware Algorithm Mapping"
  year: 2024
  type: article
  doi: https://doi.org/10.1145/3665314.3670798
  url: https://doi.org/10.1145/3665314.3670798
  pdf: https://dl.acm.org/doi/pdf/10.1145/3665314.3670798
  ignore: False
  silicon: True
  platform: Design
  model: ['FPGA', 'LLM']
  method: __no_data__
  publisher: "ACM"
  pubkey: ""
  pubname: "ACM/IEEE International Symposium on Low Power Electronics and Design"
  reserved: DEADBEEF

392:
  title: "VisionAGILE: A Versatile Domain-Specific Accelerator for Computer Vision Tasks"
  year: 2024
  type: article
  doi: https://doi.ieeecomputersociety.org/10.1109/TPDS.2024.3466891
  url: https://doi.ieeecomputersociety.org/10.1109/TPDS.2024.3466891
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['DSA', 'ViT']
  method: __no_data__
  publisher: "ACM"
  pubkey: ""
  pubname: "IEEE Transactions on Parallel and Distributed Systems"
  reserved: DEADBEEF

393:
  title: "Cambricon-LLM: A Chiplet-Based Hybrid Architecture for On-Device Inference of 70B LLM"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2409.15654
  url: https://arxiv.org/abs/2409.15654
  pdf: https://arxiv.org/pdf/2409.15654
  ignore: False
  silicon: True
  platform: Design
  model: ['Chiplet', 'LLM']
  method: __no_data__
  publisher: "Arxive"
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

394:
  title: "FAMOUS: Flexible Accelerator for the Attention Mechanism of Transformer on UltraScale+ FPGAs"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2409.14023
  url: https://arxiv.org/abs/2409.14023
  pdf: https://arxiv.org/pdf/2409.14023
  ignore: False
  silicon: True
  platform: Design
  model: ['FPGA', 'LLM']
  method: __no_data__
  publisher: "Arxive"
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

395:
  title: "Hardware-oriented algorithms for softmax and layer normalization of large language models"
  year: 2024
  type: article
  doi: https://doi.org/10.1007/s11432--024--4137--4
  url: https://doi.org/10.1007/s11432-024-4137-4
  pdf: https://arxiv.org/pdf/2409.14023
  ignore: False
  silicon: True
  platform: Design
  model: ['ASIC', 'LLM']
  method: __no_data__
  publisher: "Arxive"
  pubkey: "SciEngine"
  pubname: "SCIENCE CHINA Information Sciences"
  reserved: DEADBEEF

396:
  title: "Optimizing DNN Inference on Multi-Accelerator SoCs at Training-time"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2409.18566
  url: https://arxiv.org/abs/2409.18566
  pdf: https://arxiv.org/pdf/2409.18566
  ignore: False
  silicon: True
  platform: Design
  model: ['FPGA', 'LLM']
  method: __no_data__
  publisher: "Arxive"
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

397:
  title: "Optimizing DNN Inference on Multi-Accelerator SoCs at Training-time"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2409.18566
  url: https://arxiv.org/abs/2409.18566
  pdf: https://arxiv.org/pdf/2409.18566
  ignore: False
  silicon: True
  platform: Design
  model: ['FPGA', 'LLM']
  method: __no_data__
  publisher: "Arxive"
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

398:
  title: "DSTC: Dual-Side Sparse Tensor Core for DNNs Acceleration on Modern GPU Architectures"
  year: 2024
  type: article
  doi: https://doi.ieeecomputersociety.org/10.1109/TC.2024.3475814
  url: https://doi.ieeecomputersociety.org/10.1109/TC.2024.3475814
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['GPU', 'LLM']
  method: __no_data__
  publisher: "IEEE"
  pubkey: ""
  pubname: "IEEE Transactions on Computers"
  reserved: DEADBEEF

399:
  title: "Power Efficient ASIC Design for Vision Transformer using Systolic Array Matrix Multiplier"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/VDAT63601.2024.10705728
  url: https://doi.org/10.1109/VDAT63601.2024.10705728
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['DSA', 'ViT']
  method: __no_data__
  publisher: "IEEE"
  pubkey: "VDAT"
  pubname: "International Symposium on VLSI Design and Test"
  reserved: DEADBEEF

401:
  title: "M^2-ViT: Accelerating Hybrid Vision Transformers with Two-Level Mixed Quantization"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2410.09113
  url: https://arxiv.org/abs/2410.09113
  pdf: https://arxiv.org/pdf/2410.09113
  ignore: False
  silicon: True
  platform: Design
  model: ['FPGA', 'LLM']
  method: __no_data__
  publisher: "Arxive"
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

402:
  title: "A Cascaded ReRAM-based Crossbar Architecture for Transformer Neural Network Acceleration"
  year: 2024
  type: article
  doi: https://doi.org/10.1145/3701034
  url: https://doi.org/10.1145/3701034
  pdf: https://dl.acm.org/doi/pdf/10.1145/3701034
  ignore: False
  silicon: True
  platform: Design
  model: ['GPU', 'LLM']
  method: __no_data__
  publisher: "ACM"
  pubkey: ""
  pubname: "ACM Transactions on Design Automation of Electronic Systems"
  reserved: DEADBEEF

403:
  title: "OPASCA: Outer Product Based Accelerator With Unified Architecture for Sparse Convolution and Attention"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/TCAD.2024.3483092
  url: https://doi.org/10.1109/TCAD.2024.3483092
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['GPU', 'LLM']
  method: __no_data__
  publisher: "IEEE"
  pubkey: ""
  pubname: "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems"
  reserved: DEADBEEF

404:
  title: "HotaQ: Hardware Oriented Token Adaptive Quantization for Large Language Models"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/TCAD.2024.3487781
  url: https://doi.org/10.1109/TCAD.2024.3487781
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['Algorithm', 'LLM']
  method: __no_data__
  publisher: "IEEE"
  pubkey: ""
  pubname: "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems"
  reserved: DEADBEEF

404:
  title: "HotaQ: Hardware Oriented Token Adaptive Quantization for Large Language Models"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/TCAD.2024.3487781
  url: https://doi.org/10.1109/TCAD.2024.3487781
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['Algorithm', 'LLM']
  method: __no_data__
  publisher: "IEEE"
  pubkey: ""
  pubname: "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems"
  reserved: DEADBEEF

405:
  title: "Analysis Towards Deployment and Acceleration for ViT on a Lightweight RISC- V Processor"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/IAI63275.2024.10730301
  url: https://doi.org/10.1109/IAI63275.2024.10730301
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['RISC-V', 'LLM']
  method: __no_data__
  publisher: "IEEE"
  pubkey: ""
  pubname: "International Conference on Industrial Artificial Intelligence (IAI)  "
  reserved: DEADBEEF

406:
  title: "Improving Transformer Inference Through Optimized Non-Linear Operations With Quantization-Approximation-Based Strategy"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/TCAD.2024.3488572
  url: https://doi.org/10.1109/TCAD.2024.3488572
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['Algorithm', 'LLM']
  method: __no_data__
  publisher: "IEEE"
  pubkey: ""
  pubname: "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems"
  reserved: DEADBEEF

407:
  title: "HyCTor: A Hybrid CNN-Transformer Network Accelerator With Flexible Weight/Output Stationary Dataflow and Multi-Core Extension"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/TCAD.2024.3490173
  url: https://doi.org/10.1109/TCAD.2024.3490173
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['DSA', 'LLM']
  method: __no_data__
  publisher: "IEEE"
  pubkey: ""
  pubname: "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems"
  reserved: DEADBEEF

408:
  title: "Shrinking the Giant : Quasi-Weightless Transformers for Low Energy Inference"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2411.01818
  url: https://arxiv.org/abs/2411.01818
  pdf: https://arxiv.org/pdf/2411.01818
  ignore: False
  silicon: True
  platform: Design
  model: ['FPGA', 'LLM']
  method: __no_data__
  publisher: "Arxive"
  pubkey: ""
  pubname: "Computer Science > Machine Learning"
  reserved: DEADBEEF

409:
  title: "Multilayer Dataflow based Butterfly Sparsity Orchestration to Accelerate Attention Workloads"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2411.00734
  url: https://arxiv.org/abs/2411.00734
  pdf: https://arxiv.org/pdf/2411.00734
  ignore: False
  silicon: True
  platform: Design
  model: ['FPGA', 'LLM']
  method: __no_data__
  publisher: "Arxive"
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

410:
  title: "TATAA: Programmable Mixed-Precision Transformer Acceleration with a Transformable Arithmetic Architecture"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2411.03697
  url: https://arxiv.org/abs/2411.03697
  pdf: https://arxiv.org/pdf/2411.03697
  ignore: False
  silicon: True
  platform: Design
  model: ['FPGA', 'LLM']
  method: __no_data__
  publisher: "Arxive"
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

411:
  title: "Exploring Approximation and Dataflow Co-Optimization for Scalable Transformer Inference Architecture on the Edge"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/SOCC62300.2024.10737793
  url: https://doi.org/10.1109/SOCC62300.2024.10737793
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['DSA', 'LLM']
  method: __no_data__
  publisher: "IEEE"
  pubkey: "SOCC"
  pubname: "International System-on-Chip Conference"
  reserved: DEADBEEF

412:
  title: "PIM-AI: A Novel Architecture for High-Efficiency LLM Inference"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2411.17309
  url: https://arxiv.org/abs/2411.17309
  pdf: https://arxiv.org/pdf/2411.17309
  ignore: False
  silicon: True
  platform: Design
  model: ['PIM', 'LLM']
  method: __no_data__
  publisher: "Arxive"
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

413:
  title: "Addressing Architectural Obstacles for Overlay with Stream Network Abstraction"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2411.17966
  url: https://arxiv.org/abs/2411.17966
  pdf: https://arxiv.org/pdf/2411.17966
  ignore: False
  silicon: True
  platform: Design
  model: ['FPGA', 'LLM']
  method: __no_data__
  publisher: "Arxive"
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

414:
  title: "A Runtime-Adaptive Transformer Neural Network Accelerator on FPGAs"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2411.18148
  url: https://arxiv.org/abs/2411.18148
  pdf: https://arxiv.org/pdf/2411.18148
  ignore: False
  silicon: True
  platform: Design
  model: ['FPGA', 'LLM']
  method: __no_data__
  publisher: "Arxive"
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

415:
  title: "A Dataflow Compiler for Efficient LLM Inference using Custom Microscaling Formats"
  year: 2024
  type: article
  doi: https://arxiv.org/abs/2307.15517
  url: https://arxiv.org/abs/2307.15517
  pdf: https://arxiv.org/pdf/2307.15517
  ignore: False
  silicon: True
  platform: Design
  model: ['FPGA', 'LLM']
  method: __no_data__
  publisher: "Arxive"
  pubkey: ""
  pubname: "Computer Science > Hardware Architecture"
  reserved: DEADBEEF

416:
  title: "MR-Transformer: FPGA Accelerated Deep Learning Attention Model for Modulation Recognition"
  year: 2024
  type: article
  doi: https://doi.org/10.1109/TWC.2024.3506743
  url: https://doi.org/10.1109/TWC.2024.3506743
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['DSA', 'LLM']
  method: __no_data__
  publisher: "IEEE"
  pubkey: "SOCC"
  pubname: "IEEE Transactions on Wireless Communications"
  reserved: DEADBEEF

417:
  title: "ISOAcc: In-situ Shift Operation-based Accelerator For Efficient in-SRAM Multiplication"
  year: 2024
  type: article
  doi: https://doi.org/10.1145/3707205
  url: https://doi.org/10.1145/3707205
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['PIM', 'LLM']
  method: __no_data__
  publisher: "ACM"
  pubkey: ""
  pubname: "ACM Transactions on Design Automation of Electronic Systems"
  reserved: DEADBEEF

418:
  title: "VGA: Hardware Accelerator for Scalable Long Sequence Model Inference"
  year: 2024
  type: article
  doi: https://doi.ieeecomputersociety.org/10.1109/MICRO61859.2024.00106
  url: https://doi.ieeecomputersociety.org/10.1109/MICRO61859.2024.00106
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['PIM', 'LLM']
  method: __no_data__
  publisher: "ACM"
  pubkey: "MICRO"
  pubname: "IEEE/ACM International Symposium on Microarchitecture"
  reserved: DEADBEEF

419:
  title: "Hardware Accelerated Vision Transformer via Heterogeneous Architecture Design and Adaptive Dataflow Mapping"
  year: 2024
  type: article
  doi: https://doi.ieeecomputersociety.org/10.1109/TC.2024.3517751
  url: https://doi.ieeecomputersociety.org/10.1109/TC.2024.3517751
  pdf: false
  ignore: False
  silicon: True
  platform: Design
  model: ['FPGA', 'ViT']
  method: __no_data__
  publisher: "ACM"
  pubkey: "TC"
  pubname: "IEEE Transactions on Computers"
  reserved: DEADBEEF

# 40x:
#   title:
#   year:
#   type:
#   doi:
#   url:
#   pdf: False
#   ignore: False
#   silicon: True
#   platform: FPGA
#   model: ['Transformer']
#   method: __no_data__
#   publisher:
#   pubkey: ""
#   pubname: ""
#   reserved: DEADBEEF
